{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copie de Mehdi - ne pas enregistrer dessus (génération de conflits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import codecs\n",
    "import unidecode\n",
    "#pip install unidecode\n",
    "import mpld3\n",
    "# pip install mpld3\n",
    "import stop_words\n",
    "# pip install stop-words\n",
    "from nltk import SnowballStemmer, pos_tag, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer,TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import *\n",
    "from sklearn.semi_supervised import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lecture des données **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CV:\n",
    "    def __init__(self, filename, title, cv, doc_type):\n",
    "        self.filename = filename\n",
    "        self.title = title\n",
    "        self.cv = cv\n",
    "        self.doc_type = doc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_context_part(ao):\n",
    "    \"\"\"Supprime la partie de l'appel d'offre consacrée au contexte pour ceux qui suivent le pattern SNCF\"\"\"\n",
    "    split_ao = ao.split('DESCRIPTION DE LA MISSION')\n",
    "    if len(split_ao)>1:\n",
    "        ao_light = split_ao[1] \n",
    "    else :\n",
    "        ao_light = split_ao[0]\n",
    "    return ao_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_contact_part(ao):\n",
    "    \"\"\"Supprime la partie de l'appel d'offre consacrée au contact et adresse pour \n",
    "    ceux suivant le même pattern\"\"\"\n",
    "    split_ao = ao.split('CONDITIONS D’EXECUTION')\n",
    "    if len(split_ao)>1:\n",
    "        split_ao_2 = split_ao[1].split('AUTRES POINTS')\n",
    "        if len(split_ao_2)>1:\n",
    "            ao_light = split_ao[0] + \" \" + split_ao_2[1]\n",
    "        else :\n",
    "            ao_light = split_ao[0]\n",
    "    else :\n",
    "        ao_light = split_ao[0]\n",
    "    return ao_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download cv in a list\n",
    "def load_Doc_list(nombre, path, doc_type):\n",
    "    liste_paths = [path+directory for directory in os.listdir(path)]\n",
    "    #print(liste_paths)\n",
    "    liste_cv = []\n",
    "    dico_cv = {}\n",
    "    for path in liste_paths :\n",
    "        cv = CV(0, 0, 0, 0)\n",
    "        cv.filename = os.path.basename(path)\n",
    "        \n",
    "        try:\n",
    "            if doc_type == 'ao':\n",
    "                cv.cv = delete_contact_part(open(path).read())\n",
    "                cv.cv = delete_context_part(cv.cv)\n",
    "            else :\n",
    "                cv.cv = open(path).read()\n",
    "            cv.doc_type = doc_type\n",
    "            liste_cv.append(cv.cv)\n",
    "            dico_cv[cv.filename.split(\".\")[0]] = cv#.\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error !\")\n",
    "            print(path)\n",
    "    return liste_cv, dico_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading titles\")\n",
    "def load_title_list(nombre, path):\n",
    "    path = \"../Maha/data/\"\n",
    "    dico_titles = {}\n",
    "    filenames = sorted(glob(os.path.join(path,\"*.csv\")))\n",
    "    for file in filenames[:nombre]:\n",
    "        with open(file, encoding='latin-1') as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter=';')\n",
    "            for row in readCSV:\n",
    "                dico_titles[row[0]] = row[1]\n",
    "    return dico_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_AO = '../Commun/Data_Talan/txt_ao/'\n",
    "path_CV = '../Commun/Data_Talan/txt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_cv, dico_cv = load_Doc_list(200, path_CV, 'cv')\n",
    "liste_AO, dico_AO = load_Doc_list(200, path_AO, 'ao')\n",
    "\n",
    "# ne fonctionne pas, pas grave\n",
    "#dico_CV_titles = load_title_list(150, path_CV)\n",
    "#dico_AO_titles = load_title_list(150, path_AO)\n",
    "\n",
    "# on concatène tous les éléments dans une même liste :\n",
    "#liste_cv_indeed = liste_cv_indeed0 + liste_AO_indeed\n",
    "dico_global = dict(dico_cv)\n",
    "dico_global.update(dico_AO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2015 Consultation conduite projet et accompagnement projet_V2': <__main__.CV at 0x1192738d0>,\n",
       " '2015 Consultation-GCL-CMDB_Bornéo_V2': <__main__.CV at 0x119273908>,\n",
       " '245_Description_mission_CDPT_3P2Iv2_Consultation_n°245': <__main__.CV at 0x119273860>,\n",
       " '246_DSIRI_-_IVRC_-_MOE_et_intégrateur_BROKER_IV_Consultation_n°246': <__main__.CV at 0x119273550>,\n",
       " '256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONFIRME_MAXIMO_MOBILITE_Consultation n°256': <__main__.CV at 0x1192736d8>,\n",
       " '256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONFIRME_MAXIMO_MOBILITE_Consultation_n°256': <__main__.CV at 0x119273940>,\n",
       " '259_ISIDA_1816_Consultation_Mission_ASTR_QMAQMSI_Décisionnel_Consultation n°259': <__main__.CV at 0x1192736a0>,\n",
       " '259_ISIDA_1816_Consultation_Mission_ASTR_QMAQMSI_Décisionnel_Consultation_n°259': <__main__.CV at 0x119273898>,\n",
       " '262_ISIDA_1813_Consultation_Mission_ASTR_MOA_Consultant_fonct_erp_junior_Maximo_Consultation_n°262': <__main__.CV at 0x119277198>,\n",
       " '304_EB SAS-24-02-2016': <__main__.CV at 0x119273da0>,\n",
       " '304_EB_SAS-24-02-2016': <__main__.CV at 0x1192734e0>,\n",
       " '327_ISIDA_1918_Prestation ASTR MOA Fonctionnel Maximo (1)': <__main__.CV at 0x119273c50>,\n",
       " '329_CDC': <__main__.CV at 0x119273c88>,\n",
       " '341_ISIDA_1940_EMI_SPOT_Outillage_Recrutement-Formateur-2015-2016_V2': <__main__.CV at 0x119273b70>,\n",
       " '343_ISIDA_1948_Prestation CDP_Concepteur_SPOT Outillage_2016': <__main__.CV at 0x1191f88d0>,\n",
       " '343_ISIDA_1948_Prestation_CDP_Concepteur_SPOT_Outillage_2016': <__main__.CV at 0x1192770f0>,\n",
       " '384_Cahier des charges prestataire SIDV 2016 05 30': <__main__.CV at 0x119273f98>,\n",
       " '384_Cahier_des_charges_prestataire_SIDV_2016_05_30': <__main__.CV at 0x119273e10>,\n",
       " '388_ISIDA_1993_Prestation ASTR MOA Fonctionnel Maximo OPTISPOT-v0': <__main__.CV at 0x1192735c0>,\n",
       " '388_ISIDA_1993_Prestation_ASTR_MOA_Fonctionnel_Maximo_OPTISPOT-v0': <__main__.CV at 0x119273dd8>,\n",
       " '390_Cahier des charges _Transilien_chargé d_étude stat': <__main__.CV at 0x119273748>,\n",
       " '390_Cahier_des_charges__Transilien_chargé_d_étude_stat': <__main__.CV at 0x119273e48>,\n",
       " '481_Renouvellement cd STELSIA 32524-0000012774': <__main__.CV at 0x119273c18>,\n",
       " '481_Renouvellement_cd_STELSIA_32524-0000012774': <__main__.CV at 0x119273710>,\n",
       " '596 DESCRIPTION DE MISSION': <__main__.CV at 0x119273a20>,\n",
       " 'ACH': <__main__.CV at 0x119261978>,\n",
       " 'ADD': <__main__.CV at 0x1192374e0>,\n",
       " 'ADECV TALAN': <__main__.CV at 0x119273470>,\n",
       " 'AGNCV TALAN': <__main__.CV at 0x11926b4a8>,\n",
       " 'AIT': <__main__.CV at 0x1192374a8>,\n",
       " 'AKACV TALAN': <__main__.CV at 0x11926b860>,\n",
       " 'AME': <__main__.CV at 0x11926bcc0>,\n",
       " 'ANDA': <__main__.CV at 0x1191f83c8>,\n",
       " 'AO_Consultation_Build_-_909_-_Tableau_Software': <__main__.CV at 0x119277128>,\n",
       " 'APHCV TALAN': <__main__.CV at 0x11920a2b0>,\n",
       " 'APICV TALAN': <__main__.CV at 0x1192504e0>,\n",
       " 'BAR': <__main__.CV at 0x11925a390>,\n",
       " 'BENA': <__main__.CV at 0x119240080>,\n",
       " 'BGHCV TALAN': <__main__.CV at 0x1192505f8>,\n",
       " 'BKICV TALAN': <__main__.CV at 0x119240dd8>,\n",
       " 'BLACV TALAN': <__main__.CV at 0x119261eb8>,\n",
       " 'BLPCV TALAN': <__main__.CV at 0x11921a198>,\n",
       " 'BOA': <__main__.CV at 0x119237780>,\n",
       " 'BOUD': <__main__.CV at 0x119237f98>,\n",
       " 'BOUT': <__main__.CV at 0x119240d30>,\n",
       " 'BPUCV TALAN': <__main__.CV at 0x119261d30>,\n",
       " 'BUDU': <__main__.CV at 0x11925abe0>,\n",
       " 'CAPCV TALAN': <__main__.CV at 0x1192506d8>,\n",
       " 'CC_AST_283_-_Consultation_Build_-_904PAR_-_Chef_de_projet_Décisionnel': <__main__.CV at 0x119273e80>,\n",
       " 'CC_AST_290_-_909_PAR_-_Concepteur_-_développeur_Big_data': <__main__.CV at 0x119273048>,\n",
       " 'CC_AST_3466_-_912_PAR_-_Chef_de_Projet_Big_Data': <__main__.CV at 0x1192737f0>,\n",
       " 'CC_AST_3489_-_Besoin_Socle_-_912_PAR_-_Chef_de_Projet_Exploitation': <__main__.CV at 0x119273f60>,\n",
       " 'CDC SNCF - Consultation AST 2017 N°000012-profil 905 - Data scientific': <__main__.CV at 0x119273978>,\n",
       " 'CHEK': <__main__.CV at 0x119273358>,\n",
       " 'CHER': <__main__.CV at 0x11920fc18>,\n",
       " 'CLSCV TALAN': <__main__.CV at 0x119250908>,\n",
       " 'COUL': <__main__.CV at 0x11920fb38>,\n",
       " 'CV - TalanSolutions - AGU': <__main__.CV at 0x119273320>,\n",
       " 'CV - TalanSolutions - CJD': <__main__.CV at 0x11926b940>,\n",
       " 'CV - TalanSolutions - DPE': <__main__.CV at 0x1192491d0>,\n",
       " 'CV AAU_TS2017': <__main__.CV at 0x11925a278>,\n",
       " 'CV HME_TS2017': <__main__.CV at 0x119261358>,\n",
       " 'CV LKH - TALAN-2017': <__main__.CV at 0x11921af60>,\n",
       " 'CV NPO': <__main__.CV at 0x11925a4e0>,\n",
       " 'CV TalanSolutions ABAH': <__main__.CV at 0x1192500f0>,\n",
       " 'CV TalanSolutions ACH': <__main__.CV at 0x1191f8780>,\n",
       " 'CV TalanSolutions AIQ': <__main__.CV at 0x11925a208>,\n",
       " 'CV TalanSolutions AMO': <__main__.CV at 0x11926bba8>,\n",
       " 'CV TalanSolutions ANDO': <__main__.CV at 0x11926b0f0>,\n",
       " 'CV TalanSolutions ATR': <__main__.CV at 0x11921af28>,\n",
       " 'CV TalanSolutions BILI': <__main__.CV at 0x11925a0f0>,\n",
       " 'CV TalanSolutions CPOU': <__main__.CV at 0x1191f8860>,\n",
       " 'CV TalanSolutions DJE': <__main__.CV at 0x11920add8>,\n",
       " 'CV TalanSolutions DJS': <__main__.CV at 0x11920aa20>,\n",
       " 'CV TalanSolutions FGA': <__main__.CV at 0x11920ac50>,\n",
       " 'CV TalanSolutions ICHO': <__main__.CV at 0x11920fcc0>,\n",
       " 'CV TalanSolutions JBOU': <__main__.CV at 0x119240668>,\n",
       " 'CV TalanSolutions JPL': <__main__.CV at 0x11926b208>,\n",
       " 'CV TalanSolutions LVE': <__main__.CV at 0x119237f60>,\n",
       " 'CV TalanSolutions MCH': <__main__.CV at 0x119273438>,\n",
       " 'CV TalanSolutions MCHI': <__main__.CV at 0x11921aeb8>,\n",
       " 'CV TalanSolutions MSME': <__main__.CV at 0x119250470>,\n",
       " 'CV TalanSolutions NAB': <__main__.CV at 0x119250f28>,\n",
       " 'CV TalanSolutions NPRI': <__main__.CV at 0x119261278>,\n",
       " 'CV TalanSolutions RGO': <__main__.CV at 0x119240e48>,\n",
       " 'CV TalanSolutions RGUI': <__main__.CV at 0x11921a160>,\n",
       " 'CV TalanSolutions RVA': <__main__.CV at 0x11920f940>,\n",
       " 'CV TalanSolutions SEDA': <__main__.CV at 0x11926b828>,\n",
       " 'CV TalanSolutions SJE': <__main__.CV at 0x119261080>,\n",
       " 'CV TalanSolutions XSUN': <__main__.CV at 0x11926bb00>,\n",
       " 'CV TalanSolutions YGO': <__main__.CV at 0x119273240>,\n",
       " 'CV _TalanSolutions_AAG AOUT 2017': <__main__.CV at 0x119261e80>,\n",
       " 'CV collaborateur_IZA': <__main__.CV at 0x119240be0>,\n",
       " 'CV collaborateur_TS2017_JAU_201710': <__main__.CV at 0x1191f8828>,\n",
       " 'CV-TalanSolutions_VGA': <__main__.CV at 0x119249898>,\n",
       " 'CV-Talan_BIB': <__main__.CV at 0x119240ef0>,\n",
       " 'CV5_AAR': <__main__.CV at 0x1192372b0>,\n",
       " 'CV_5_AAR': <__main__.CV at 0x119249748>,\n",
       " 'CV_5_ABDEL': <__main__.CV at 0x119240a20>,\n",
       " 'CV_5_ABO': <__main__.CV at 0x119250a20>,\n",
       " 'CV_5_ABOU': <__main__.CV at 0x11920f9e8>,\n",
       " 'CV_5_ABOUT': <__main__.CV at 0x11925a128>,\n",
       " 'CV_5_ACH': <__main__.CV at 0x11925a6a0>,\n",
       " 'CV_5_ADLE': <__main__.CV at 0x11926bbe0>,\n",
       " 'CV_5_AEIFJAU': <__main__.CV at 0x11925a240>,\n",
       " 'CV_5_AGUE': <__main__.CV at 0x119250978>,\n",
       " 'CV_5_AITE': <__main__.CV at 0x1192490f0>,\n",
       " 'CV_5_AITEL': <__main__.CV at 0x11920a828>,\n",
       " 'CV_5_AITO': <__main__.CV at 0x119250e48>,\n",
       " 'CV_5_ALA': <__main__.CV at 0x119249080>,\n",
       " 'CV_5_ALAO': <__main__.CV at 0x119261550>,\n",
       " 'CV_5_ALIB': <__main__.CV at 0x11925ab00>,\n",
       " 'CV_5_ALIK': <__main__.CV at 0x119240ba8>,\n",
       " 'CV_5_ALLA': <__main__.CV at 0x1191f8a58>,\n",
       " 'CV_5_AMA': <__main__.CV at 0x119250eb8>,\n",
       " 'CV_5_AME': <__main__.CV at 0x119249fd0>,\n",
       " 'CV_5_AMI': <__main__.CV at 0x119240630>,\n",
       " 'CV_5_AML': <__main__.CV at 0x119237be0>,\n",
       " 'CV_5_AMM': <__main__.CV at 0x1192400b8>,\n",
       " 'CV_5_AMO': <__main__.CV at 0x1192371d0>,\n",
       " 'CV_5_AND': <__main__.CV at 0x119240978>,\n",
       " 'CV_5_ANDR': <__main__.CV at 0x119250be0>,\n",
       " 'CV_5_ANS': <__main__.CV at 0x1192409b0>,\n",
       " 'CV_5_ANT': <__main__.CV at 0x119237208>,\n",
       " 'CV_5_ARKH': <__main__.CV at 0x119261518>,\n",
       " 'CV_5_ATT': <__main__.CV at 0x119250e10>,\n",
       " 'CV_5_AUD': <__main__.CV at 0x11925a9e8>,\n",
       " 'CV_5_AUR': <__main__.CV at 0x11925a7f0>,\n",
       " 'CV_5_AYED': <__main__.CV at 0x119240908>,\n",
       " 'CV_5_AYES': <__main__.CV at 0x119240860>,\n",
       " 'CV_5_AZHA': <__main__.CV at 0x11921a358>,\n",
       " 'CV_5_AZZ': <__main__.CV at 0x119250240>,\n",
       " 'CV_5_BADD': <__main__.CV at 0x11925a0b8>,\n",
       " 'CV_5_BAH': <__main__.CV at 0x11920a5f8>,\n",
       " 'CV_5_BAHR': <__main__.CV at 0x11925a080>,\n",
       " 'CV_5_BAJJ': <__main__.CV at 0x1192495c0>,\n",
       " 'CV_5_BARA': <__main__.CV at 0x119249400>,\n",
       " 'CV_5_BARAU': <__main__.CV at 0x119237860>,\n",
       " 'CV_5_BARH': <__main__.CV at 0x11925ada0>,\n",
       " 'CV_5_BASI': <__main__.CV at 0x119249d30>,\n",
       " 'CV_5_BAYA': <__main__.CV at 0x1191f87f0>,\n",
       " 'CV_5_BECH': <__main__.CV at 0x11920feb8>,\n",
       " 'CV_5_BEID': <__main__.CV at 0x119250b38>,\n",
       " 'CV_5_BEKK': <__main__.CV at 0x119249978>,\n",
       " 'CV_5_BELH': <__main__.CV at 0x11926be80>,\n",
       " 'CV_5_BELHA': <__main__.CV at 0x11926b710>,\n",
       " 'CV_5_BELL': <__main__.CV at 0x119261438>,\n",
       " 'CV_5_BENA': <__main__.CV at 0x1192730f0>,\n",
       " 'CV_5_BENAD': <__main__.CV at 0x119240ac8>,\n",
       " 'CV_5_BENC': <__main__.CV at 0x11926b390>,\n",
       " 'CV_5_BENHAD': <__main__.CV at 0x119249588>,\n",
       " 'CV_5_BENHAM': <__main__.CV at 0x119237198>,\n",
       " 'CV_5_BENHAMAPM': <__main__.CV at 0x11926b080>,\n",
       " 'CV_5_BENHE': <__main__.CV at 0x1192616d8>,\n",
       " 'CV_5_BENHM': <__main__.CV at 0x1191f8da0>,\n",
       " 'CV_5_BENJAM': <__main__.CV at 0x119237ef0>,\n",
       " 'CV_5_BENN': <__main__.CV at 0x11920f080>,\n",
       " 'CV_5_BENNA': <__main__.CV at 0x1192507b8>,\n",
       " 'CV_5_BENO': <__main__.CV at 0x11920ffd0>,\n",
       " 'CV_5_BENT': <__main__.CV at 0x11926b4e0>,\n",
       " 'CV_5_BENY': <__main__.CV at 0x11920fe10>,\n",
       " 'CV_5_BENZ': <__main__.CV at 0x1191f8668>,\n",
       " 'CV_5_BENZA': <__main__.CV at 0x119249f60>,\n",
       " 'CV_5_BERR': <__main__.CV at 0x119249198>,\n",
       " 'CV_5_BILL': <__main__.CV at 0x11921a2b0>,\n",
       " 'CV_5_BIM': <__main__.CV at 0x119249cc0>,\n",
       " 'CV_5_BIST': <__main__.CV at 0x119250208>,\n",
       " 'CV_5_BLAN': <__main__.CV at 0x119240898>,\n",
       " 'CV_5_BLANCH': <__main__.CV at 0x11920ad68>,\n",
       " 'CV_5_BOIK': <__main__.CV at 0x119250048>,\n",
       " 'CV_5_BOSC': <__main__.CV at 0x11925acf8>,\n",
       " 'CV_5_BOUH': <__main__.CV at 0x11920a550>,\n",
       " 'CV_5_BOUJ': <__main__.CV at 0x11920a438>,\n",
       " 'CV_5_BOUM': <__main__.CV at 0x1191f8cf8>,\n",
       " 'CV_5_BOUR': <__main__.CV at 0x119261668>,\n",
       " 'CV_5_BOUS': <__main__.CV at 0x11925afd0>,\n",
       " 'CV_5_BOUZ': <__main__.CV at 0x1191f8f60>,\n",
       " 'CV_5_BOUZI': <__main__.CV at 0x1191f8978>,\n",
       " 'CV_5_BRAH': <__main__.CV at 0x11920a588>,\n",
       " 'CV_5_BREQ': <__main__.CV at 0x119237cc0>,\n",
       " 'CV_5_BRETE': <__main__.CV at 0x119237e10>,\n",
       " 'CV_5_BRINI': <__main__.CV at 0x11925a9b0>,\n",
       " 'CV_5_BRINIS': <__main__.CV at 0x119249b70>,\n",
       " 'CV_5_BROSS': <__main__.CV at 0x11926b240>,\n",
       " 'CV_5_BRUG': <__main__.CV at 0x11926bc18>,\n",
       " 'CV_5_BRZU': <__main__.CV at 0x11920a278>,\n",
       " 'CV_5_BSIL': <__main__.CV at 0x11925ae48>,\n",
       " 'CV_5_CAM': <__main__.CV at 0x119237d68>,\n",
       " 'CV_5_CART': <__main__.CV at 0x119273278>,\n",
       " 'CV_5_CATT': <__main__.CV at 0x119250ef0>,\n",
       " 'CV_5_CHAFF': <__main__.CV at 0x11920fa58>,\n",
       " 'CV_5_CHAR': <__main__.CV at 0x11920fe80>,\n",
       " 'CV_5_CHARY': <__main__.CV at 0x11926b2b0>,\n",
       " 'CV_5_CHARZ': <__main__.CV at 0x11926bc50>,\n",
       " 'CV_5_CHAT': <__main__.CV at 0x11921a240>,\n",
       " 'CV_5_CHENA': <__main__.CV at 0x1192495f8>,\n",
       " 'CV_5_CHERK': <__main__.CV at 0x11926b978>,\n",
       " 'CV_5_CHERQ': <__main__.CV at 0x11920fda0>,\n",
       " 'CV_5_CHET': <__main__.CV at 0x119250dd8>,\n",
       " 'CV_5_CHIP': <__main__.CV at 0x1192497f0>,\n",
       " 'CV_5_CHITT': <__main__.CV at 0x119249b00>,\n",
       " 'CV_5_CHOUAK': <__main__.CV at 0x1191f8a20>,\n",
       " 'CV_5_CLICK': <__main__.CV at 0x11926b898>,\n",
       " 'CV_5_COH': <__main__.CV at 0x11925aa20>,\n",
       " 'CV_5_DACU': <__main__.CV at 0x119250cf8>,\n",
       " 'CV_5_DAHBI': <__main__.CV at 0x119250390>,\n",
       " 'CV_5_DALIK': <__main__.CV at 0x11925aef0>,\n",
       " 'CV_5_DAMBL': <__main__.CV at 0x1192612b0>,\n",
       " 'CV_5_DANRO': <__main__.CV at 0x11920aac8>,\n",
       " 'CV_5_DAOUD': <__main__.CV at 0x119261a20>,\n",
       " 'CV_5_DAOUI': <__main__.CV at 0x11920a0b8>,\n",
       " 'CV_5_DAV': <__main__.CV at 0x119261ba8>,\n",
       " 'CV_5_DEC': <__main__.CV at 0x119237c50>,\n",
       " 'CV_5_DEL': <__main__.CV at 0x11925a550>,\n",
       " 'CV_5_DELE': <__main__.CV at 0x119237b00>,\n",
       " 'CV_5_DEM': <__main__.CV at 0x11925a978>,\n",
       " 'CV_5_DEMO': <__main__.CV at 0x11925ac88>,\n",
       " 'CV_5_DER': <__main__.CV at 0x119240e80>,\n",
       " 'CV_5_DESA': <__main__.CV at 0x11920a208>,\n",
       " 'CV_5_DESM': <__main__.CV at 0x1192617b8>,\n",
       " 'CV_5_DIAFAO': <__main__.CV at 0x119250518>,\n",
       " 'CV_5_DIAG': <__main__.CV at 0x119250630>,\n",
       " 'CV_5_DIAGN': <__main__.CV at 0x11926b9b0>,\n",
       " 'CV_5_DIAH': <__main__.CV at 0x119249438>,\n",
       " 'CV_5_DIAIDJ': <__main__.CV at 0x11925aa90>,\n",
       " 'CV_5_DIALL': <__main__.CV at 0x119249c88>,\n",
       " 'CV_5_DILM': <__main__.CV at 0x119240438>,\n",
       " 'CV_5_DING': <__main__.CV at 0x119249320>,\n",
       " 'CV_5_DIO': <__main__.CV at 0x11925a7b8>,\n",
       " 'CV_5_DJA': <__main__.CV at 0x119250da0>,\n",
       " 'CV_5_DOM': <__main__.CV at 0x11926b0b8>,\n",
       " 'CV_5_DOT': <__main__.CV at 0x11920ff28>,\n",
       " 'CV_5_DRA': <__main__.CV at 0x1192496d8>,\n",
       " 'CV_5_DRAM': <__main__.CV at 0x1192376d8>,\n",
       " 'CV_5_DRI': <__main__.CV at 0x119237240>,\n",
       " 'CV_5_DUC': <__main__.CV at 0x119273208>,\n",
       " 'CV_5_EGO': <__main__.CV at 0x11921a668>,\n",
       " 'CV_5_ELB': <__main__.CV at 0x11925ad68>,\n",
       " 'CV_5_ELF': <__main__.CV at 0x1192494a8>,\n",
       " 'CV_5_ELGBO': <__main__.CV at 0x1192507f0>,\n",
       " 'CV_5_ELGE': <__main__.CV at 0x11920a470>,\n",
       " 'CV_5_ELGH': <__main__.CV at 0x119261c50>,\n",
       " 'CV_5_ELHAK': <__main__.CV at 0x119261c88>,\n",
       " 'CV_5_ELMO': <__main__.CV at 0x11925a908>,\n",
       " 'CV_5_ELMOK': <__main__.CV at 0x1192408d0>,\n",
       " 'CV_5_ELR': <__main__.CV at 0x119249e48>,\n",
       " 'CV_5_ELS': <__main__.CV at 0x119250550>,\n",
       " 'CV_5_ELW': <__main__.CV at 0x1192506a0>,\n",
       " 'CV_5_ESS': <__main__.CV at 0x119261898>,\n",
       " 'CV_5_ETA': <__main__.CV at 0x119249c18>,\n",
       " 'CV_5_FAG': <__main__.CV at 0x11926b630>,\n",
       " 'CV_5_FALL': <__main__.CV at 0x119250588>,\n",
       " 'CV_5_FAN': <__main__.CV at 0x11920abe0>,\n",
       " 'CV_5_FERR': <__main__.CV at 0x11920fef0>,\n",
       " 'CV_5_FOUR': <__main__.CV at 0x119250898>,\n",
       " 'CV_5_GAC': <__main__.CV at 0x119249630>,\n",
       " 'CV_5_GAD': <__main__.CV at 0x119250f60>,\n",
       " 'CV_5_GAR': <__main__.CV at 0x1192508d0>,\n",
       " 'CV_5_GARB': <__main__.CV at 0x1192502b0>,\n",
       " 'CV_5_GATT': <__main__.CV at 0x1192610f0>,\n",
       " 'CV_5_GHA': <__main__.CV at 0x11920af98>,\n",
       " 'CV_5_GHAN': <__main__.CV at 0x1192509b0>,\n",
       " 'CV_5_GHAR': <__main__.CV at 0x119249128>,\n",
       " 'CV_5_GHIY': <__main__.CV at 0x11920af60>,\n",
       " 'CV_5_GHOU': <__main__.CV at 0x1192499b0>,\n",
       " 'CV_5_GIR': <__main__.CV at 0x11920a518>,\n",
       " 'CV_5_GIRA': <__main__.CV at 0x119237748>,\n",
       " 'CV_5_GMI': <__main__.CV at 0x119237080>,\n",
       " 'CV_5_GONZ': <__main__.CV at 0x11920a2e8>,\n",
       " 'CV_5_GOUR': <__main__.CV at 0x11921a5f8>,\n",
       " 'CV_5_GRA': <__main__.CV at 0x11925ae80>,\n",
       " 'CV_5_GUED': <__main__.CV at 0x1192616a0>,\n",
       " 'CV_5_GUEDD': <__main__.CV at 0x11925ac50>,\n",
       " 'CV_5_GUEL': <__main__.CV at 0x1191f8f98>,\n",
       " 'CV_5_GUI': <__main__.CV at 0x119240320>,\n",
       " 'CV_5_GUQ': <__main__.CV at 0x1192494e0>,\n",
       " 'CV_5_GUY': <__main__.CV at 0x119237828>,\n",
       " 'CV_5_HAB': <__main__.CV at 0x11921a4e0>,\n",
       " 'CV_5_HAD': <__main__.CV at 0x11920f198>,\n",
       " 'CV_5_HADD': <__main__.CV at 0x11926b8d0>,\n",
       " 'CV_5_HAJ': <__main__.CV at 0x11926bc88>,\n",
       " 'CV_5_HAJJ': <__main__.CV at 0x119261da0>,\n",
       " 'CV_5_HAML': <__main__.CV at 0x119249e80>,\n",
       " 'CV_5_HAR': <__main__.CV at 0x11920fb70>,\n",
       " 'CV_5_HART': <__main__.CV at 0x11921a080>,\n",
       " 'CV_5_HAS': <__main__.CV at 0x11920f4a8>,\n",
       " 'CV_5_HAST': <__main__.CV at 0x1191f8c88>,\n",
       " 'CV_5_HAZ': <__main__.CV at 0x119261dd8>,\n",
       " 'CV_5_HER': <__main__.CV at 0x119249a20>,\n",
       " 'CV_5_HOL': <__main__.CV at 0x11920fac8>,\n",
       " 'CV_5_HURT': <__main__.CV at 0x119249908>,\n",
       " 'CV_5_IBB': <__main__.CV at 0x1192504a8>,\n",
       " 'CV_5_IBOU': <__main__.CV at 0x119240390>,\n",
       " 'CV_5_IQAI': <__main__.CV at 0x119250b00>,\n",
       " 'CV_5_JAAD': <__main__.CV at 0x119240f28>,\n",
       " 'CV_5_JAADD': <__main__.CV at 0x11920ac88>,\n",
       " 'CV_5_JANY': <__main__.CV at 0x1192373c8>,\n",
       " 'CV_5_JAW': <__main__.CV at 0x11921a5c0>,\n",
       " 'CV_5_JEM': <__main__.CV at 0x119237f28>,\n",
       " 'CV_5_JOLL': <__main__.CV at 0x119240f60>,\n",
       " 'CV_5_JOUH': <__main__.CV at 0x119237eb8>,\n",
       " 'CV_5_KAD': <__main__.CV at 0x119237978>,\n",
       " 'CV_5_KADR': <__main__.CV at 0x1192376a0>,\n",
       " 'CV_5_KAMM': <__main__.CV at 0x11921a1d0>,\n",
       " 'CV_5_KAN': <__main__.CV at 0x119249470>,\n",
       " 'CV_5_KAR': <__main__.CV at 0x1192402b0>,\n",
       " 'CV_5_KARO': <__main__.CV at 0x119240400>,\n",
       " 'CV_5_KHA': <__main__.CV at 0x119261860>,\n",
       " 'CV_5_KHAL': <__main__.CV at 0x11925acc0>,\n",
       " 'CV_5_KHAM': <__main__.CV at 0x11925a1d0>,\n",
       " 'CV_5_KHE': <__main__.CV at 0x11926b908>,\n",
       " 'CV_5_KHEL': <__main__.CV at 0x11920ad30>,\n",
       " 'CV_5_KHEM': <__main__.CV at 0x11920a748>,\n",
       " 'CV_5_KHI': <__main__.CV at 0x114de8cf8>,\n",
       " 'CV_5_KHO': <__main__.CV at 0x11921a048>,\n",
       " 'CV_5_KIL': <__main__.CV at 0x11920fdd8>,\n",
       " 'CV_5_KLE': <__main__.CV at 0x119240b00>,\n",
       " 'CV_5_KOM': <__main__.CV at 0x1192377b8>,\n",
       " 'CV_5_KOT': <__main__.CV at 0x119250780>,\n",
       " 'CV_5_KOU': <__main__.CV at 0x11925a2b0>,\n",
       " 'CV_5_KOW': <__main__.CV at 0x11925a4a8>,\n",
       " 'CV_5_KRO': <__main__.CV at 0x1192618d0>,\n",
       " 'CV_5_LAB': <__main__.CV at 0x1191f8d30>,\n",
       " 'CV_5_LAG': <__main__.CV at 0x11920a940>,\n",
       " 'CV_5_LAK': <__main__.CV at 0x11925aeb8>,\n",
       " 'CV_5_LAM': <__main__.CV at 0x11926b160>,\n",
       " 'CV_5_LAN': <__main__.CV at 0x11926bac8>,\n",
       " 'CV_5_LAR': <__main__.CV at 0x11920a908>,\n",
       " 'CV_5_LAS': <__main__.CV at 0x11920ae80>,\n",
       " 'CV_5_LAT': <__main__.CV at 0x11920fbe0>,\n",
       " 'CV_5_LAU': <__main__.CV at 0x1191f8588>,\n",
       " 'CV_5_LAZ': <__main__.CV at 0x11926b128>,\n",
       " 'CV_5_LEF': <__main__.CV at 0x119250748>,\n",
       " 'CV_5_LEK': <__main__.CV at 0x1192402e8>,\n",
       " 'CV_5_LEO': <__main__.CV at 0x1192403c8>,\n",
       " 'CV_5_LEOT': <__main__.CV at 0x11926b5f8>,\n",
       " 'CV_5_LER': <__main__.CV at 0x11925a3c8>,\n",
       " 'CV_5_LESA': <__main__.CV at 0x119237588>,\n",
       " 'CV_5_LEV': <__main__.CV at 0x119249da0>,\n",
       " 'CV_5_LHAL': <__main__.CV at 0x1192492b0>,\n",
       " 'CV_5_LIW': <__main__.CV at 0x119249ac8>,\n",
       " 'CV_5_LOU': <__main__.CV at 0x119261f60>,\n",
       " 'CV_5_LOUR': <__main__.CV at 0x119273400>,\n",
       " 'CV_5_LUG': <__main__.CV at 0x1191f8c50>,\n",
       " 'CV_5_LUI': <__main__.CV at 0x11926b748>,\n",
       " 'CV_5_LWI': <__main__.CV at 0x11920aeb8>,\n",
       " 'CV_5_MAC': <__main__.CV at 0x119237ba8>,\n",
       " 'CV_5_MAD': <__main__.CV at 0x1192400f0>,\n",
       " 'CV_5_MAH': <__main__.CV at 0x119249780>,\n",
       " 'CV_5_MAJ': <__main__.CV at 0x1192502e8>,\n",
       " 'CV_5_MAM': <__main__.CV at 0x11925a828>,\n",
       " 'CV_5_MAMM': <__main__.CV at 0x119240828>,\n",
       " 'CV_5_MAN': <__main__.CV at 0x119250c18>,\n",
       " 'CV_5_MANT': <__main__.CV at 0x119240e10>,\n",
       " 'CV_5_MAR': <__main__.CV at 0x119240da0>,\n",
       " 'CV_5_MARI': <__main__.CV at 0x11920f208>,\n",
       " 'CV_5_MARM': <__main__.CV at 0x11920a240>,\n",
       " 'CV_5_MAY': <__main__.CV at 0x119250ba8>,\n",
       " 'CV_5_MAZ': <__main__.CV at 0x11925a780>,\n",
       " 'CV_5_MEB': <__main__.CV at 0x1192613c8>,\n",
       " 'CV_5_MECH': <__main__.CV at 0x11925aba8>,\n",
       " 'CV_5_MEH': <__main__.CV at 0x11920f358>,\n",
       " 'CV_5_MEHR': <__main__.CV at 0x11921a390>,\n",
       " 'CV_5_MEJ': <__main__.CV at 0x1191f8940>,\n",
       " 'CV_5_MEK': <__main__.CV at 0x1191f8438>,\n",
       " 'CV_5_MEKR': <__main__.CV at 0x1192615f8>,\n",
       " 'CV_5_MEL': <__main__.CV at 0x11920a4a8>,\n",
       " 'CV_5_MEN': <__main__.CV at 0x11921a400>,\n",
       " 'CV_5_MER': <__main__.CV at 0x11926b470>,\n",
       " 'CV_5_MERT': <__main__.CV at 0x11926ba90>,\n",
       " 'CV_5_MES': <__main__.CV at 0x11926b588>,\n",
       " 'CV_5_MIR': <__main__.CV at 0x11926bf28>,\n",
       " 'CV_5_MIS': <__main__.CV at 0x11926bf60>,\n",
       " 'CV_5_MISS': <__main__.CV at 0x11920f278>,\n",
       " 'CV_5_MIT': <__main__.CV at 0x119261ac8>,\n",
       " 'CV_5_MOK': <__main__.CV at 0x119237390>,\n",
       " 'CV_5_MOO': <__main__.CV at 0x119240eb8>,\n",
       " 'CV_5_MOR': <__main__.CV at 0x119250c88>,\n",
       " 'CV_5_MORE': <__main__.CV at 0x11920f4e0>,\n",
       " 'CV_5_MOREI': <__main__.CV at 0x119249710>,\n",
       " 'CV_5_MOU': <__main__.CV at 0x1192498d0>,\n",
       " 'CV_5_MOZEAAZE': <__main__.CV at 0x119237a20>,\n",
       " 'CV_5_MRA': <__main__.CV at 0x11920f0b8>,\n",
       " 'CV_5_MSA': <__main__.CV at 0x11920a320>,\n",
       " 'CV_5_MUR': <__main__.CV at 0x119237470>,\n",
       " 'CV_5_NAP': <__main__.CV at 0x11920afd0>,\n",
       " 'CV_5_NDO': <__main__.CV at 0x11921a0f0>,\n",
       " 'CV_5_NGN': <__main__.CV at 0x11925a8d0>,\n",
       " 'CV_5_NGU': <__main__.CV at 0x119237710>,\n",
       " 'CV_5_NGUE': <__main__.CV at 0x11920fc50>,\n",
       " 'CV_5_NKA': <__main__.CV at 0x119237668>,\n",
       " 'CV_5_NOU': <__main__.CV at 0x119261048>,\n",
       " 'CV_5_NOUW': <__main__.CV at 0x11926bf98>,\n",
       " 'CV_5_NUN': <__main__.CV at 0x119261f98>,\n",
       " 'CV_5_OLE': <__main__.CV at 0x119237400>,\n",
       " 'CV_5_OOUAAEZRA': <__main__.CV at 0x11920a390>,\n",
       " 'CV_5_OUA': <__main__.CV at 0x1192407b8>,\n",
       " 'CV_5_OUARA': <__main__.CV at 0x11920fd30>,\n",
       " 'CV_5_OUB': <__main__.CV at 0x119240fd0>,\n",
       " 'CV_5_OUE': <__main__.CV at 0x119237cf8>,\n",
       " 'CV_5_OUESS': <__main__.CV at 0x11920a358>,\n",
       " 'CV_5_OULD': <__main__.CV at 0x11920ff60>,\n",
       " 'CV_5_OUSSAAEZA': <__main__.CV at 0x11920fd68>,\n",
       " 'CV_5_PAJAAZDEAZ': <__main__.CV at 0x11920f128>,\n",
       " 'CV_5_PAQ': <__main__.CV at 0x119237630>,\n",
       " 'CV_5_PAR': <__main__.CV at 0x119240128>,\n",
       " 'CV_5_PASS': <__main__.CV at 0x11920aa90>,\n",
       " 'CV_5_PAT': <__main__.CV at 0x119249208>,\n",
       " 'CV_5_PAU': <__main__.CV at 0x119240cc0>,\n",
       " 'CV_5_PAUL': <__main__.CV at 0x11925ae10>,\n",
       " 'CV_5_PEK': <__main__.CV at 0x11920ac18>,\n",
       " 'CV_5_PER': <__main__.CV at 0x119261160>,\n",
       " 'CV_5_PERK': <__main__.CV at 0x119261198>,\n",
       " 'CV_5_PHAAZEA': <__main__.CV at 0x119250160>,\n",
       " 'CV_5_PHAN': <__main__.CV at 0x1191f8710>,\n",
       " 'CV_5_POI': <__main__.CV at 0x119240c18>,\n",
       " 'CV_5_PON': <__main__.CV at 0x119240160>,\n",
       " 'CV_5_PRE': <__main__.CV at 0x1191f8cc0>,\n",
       " 'CV_5_PRO': <__main__.CV at 0x1192617f0>,\n",
       " 'CV_5_RADF': <__main__.CV at 0x1192614a8>,\n",
       " 'CV_5_RAF': <__main__.CV at 0x1192379b0>,\n",
       " 'CV_5_RAG': <__main__.CV at 0x119240048>,\n",
       " 'CV_5_RAH': <__main__.CV at 0x11925ad30>,\n",
       " 'CV_5_RAHO': <__main__.CV at 0x11920f160>,\n",
       " 'CV_5_RAI': <__main__.CV at 0x11925a470>,\n",
       " 'CV_5_RAM': <__main__.CV at 0x119249c50>,\n",
       " 'CV_5_RAT': <__main__.CV at 0x119240470>,\n",
       " 'CV_5_REB': <__main__.CV at 0x11926bb38>,\n",
       " 'CV_5_REG': <__main__.CV at 0x11925a748>,\n",
       " 'CV_5_REM': <__main__.CV at 0x11920fcf8>,\n",
       " 'CV_5_REN': <__main__.CV at 0x1191f8e48>,\n",
       " 'CV_5_RIO': <__main__.CV at 0x11920f390>,\n",
       " 'CV_5_RIOD': <__main__.CV at 0x1192409e8>,\n",
       " 'CV_5_RIV': <__main__.CV at 0x11926b6d8>,\n",
       " 'CV_5_RIVO': <__main__.CV at 0x11925a320>,\n",
       " 'CV_5_RMI': <__main__.CV at 0x119250710>,\n",
       " 'CV_5_ROS': <__main__.CV at 0x119249e10>,\n",
       " 'CV_5_ROUE': <__main__.CV at 0x119250d30>,\n",
       " 'CV_5_ROUZ': <__main__.CV at 0x119240748>,\n",
       " 'CV_5_RUE': <__main__.CV at 0x119240c88>,\n",
       " 'CV_5_SAC': <__main__.CV at 0x11921a3c8>,\n",
       " 'CV_5_SAD': <__main__.CV at 0x11920f710>,\n",
       " 'CV_5_SAI': <__main__.CV at 0x11926b518>,\n",
       " 'CV_5_SAID': <__main__.CV at 0x119240358>,\n",
       " 'CV_5_SAJ': <__main__.CV at 0x11926beb8>,\n",
       " 'CV_5_SANC': <__main__.CV at 0x11920acf8>,\n",
       " 'CV_5_SEAM': <__main__.CV at 0x11920ff98>,\n",
       " 'CV_5_SEB': <__main__.CV at 0x119250cc0>,\n",
       " 'CV_5_SEL': <__main__.CV at 0x119237358>,\n",
       " 'CV_5_SHA': <__main__.CV at 0x119250320>,\n",
       " 'CV_5_SHL': <__main__.CV at 0x119240710>,\n",
       " 'CV_5_SID': <__main__.CV at 0x1192500b8>,\n",
       " 'CV_5_SIJ': <__main__.CV at 0x1192405c0>,\n",
       " 'CV_5_SIR': <__main__.CV at 0x119250278>,\n",
       " 'CV_5_SLA': <__main__.CV at 0x1191f8b38>,\n",
       " 'CV_5_SLO': <__main__.CV at 0x11926b5c0>,\n",
       " 'CV_5_SMI': <__main__.CV at 0x11926b400>,\n",
       " 'CV_5_SOU': <__main__.CV at 0x11926b438>,\n",
       " 'CV_5_SOUA': <__main__.CV at 0x11920f668>,\n",
       " 'CV_5_SOUH': <__main__.CV at 0x119261588>,\n",
       " 'CV_5_SOUN': <__main__.CV at 0x11926b7b8>,\n",
       " 'CV_5_SRI': <__main__.CV at 0x11925ab38>,\n",
       " 'CV_5_SYL': <__main__.CV at 0x11926bcf8>,\n",
       " 'CV_5_TAA': <__main__.CV at 0x119237da0>,\n",
       " 'CV_5_TAC': <__main__.CV at 0x119237048>,\n",
       " 'CV_5_TAG': <__main__.CV at 0x119240f98>,\n",
       " 'CV_5_TAK': <__main__.CV at 0x119249860>,\n",
       " 'CV_5_TAL': <__main__.CV at 0x119250c50>,\n",
       " 'CV_5_TCH': <__main__.CV at 0x119237d30>,\n",
       " 'CV_5_TCHO': <__main__.CV at 0x119240198>,\n",
       " 'CV_5_TEB': <__main__.CV at 0x119261b38>,\n",
       " 'CV_5_TECHOO': <__main__.CV at 0x119249828>,\n",
       " 'CV_5_TER': <__main__.CV at 0x11926bd68>,\n",
       " 'CV_5_TEU': <__main__.CV at 0x119261be0>,\n",
       " 'CV_5_TIT': <__main__.CV at 0x119261400>,\n",
       " 'CV_5_TOU': <__main__.CV at 0x119250128>,\n",
       " 'CV_5_TRA': <__main__.CV at 0x1191f8a90>,\n",
       " 'CV_5_TRI': <__main__.CV at 0x1192614e0>,\n",
       " 'CV_5_TRIP': <__main__.CV at 0x119240cf8>,\n",
       " 'CV_5_TROT': <__main__.CV at 0x11920f0f0>,\n",
       " 'CV_5_TUA': <__main__.CV at 0x119240940>,\n",
       " 'CV_5_TUR': <__main__.CV at 0x119237ac8>,\n",
       " 'CV_5_VAL': <__main__.CV at 0x11925aac8>,\n",
       " 'CV_5_VAN': <__main__.CV at 0x119250a58>,\n",
       " 'CV_5_VEY': <__main__.CV at 0x11921a4a8>,\n",
       " 'CV_5_VEYS': <__main__.CV at 0x1191f8c18>,\n",
       " 'CV_5_WAI': <__main__.CV at 0x119261e10>,\n",
       " 'CV_5_WAUT': <__main__.CV at 0x1192505c0>,\n",
       " 'CV_5_WAZE': <__main__.CV at 0x1192401d0>,\n",
       " 'CV_5_XAA': <__main__.CV at 0x119250940>,\n",
       " 'CV_5_YAHH': <__main__.CV at 0x11926bb70>,\n",
       " 'CV_5_YAIZEA': <__main__.CV at 0x119237dd8>,\n",
       " 'CV_5_YAWW': <__main__.CV at 0x119240a90>,\n",
       " 'CV_5_YOUAZ': <__main__.CV at 0x1192405f8>,\n",
       " 'CV_5_ZAA': <__main__.CV at 0x11925aa58>,\n",
       " 'CV_5_ZAR': <__main__.CV at 0x1192497b8>,\n",
       " 'CV_5_ZARZOIU': <__main__.CV at 0x119250b70>,\n",
       " 'CV_5_ZEG': <__main__.CV at 0x1191f8400>,\n",
       " 'CV_5_ZEL': <__main__.CV at 0x119261c18>,\n",
       " 'CV_5_ZELAZOEK': <__main__.CV at 0x11920fc88>,\n",
       " 'CV_5_ZHAIZAI': <__main__.CV at 0x119261908>,\n",
       " 'CV_5_ZHANAZIJ': <__main__.CV at 0x119249dd8>,\n",
       " 'CV_5_ZHANZAEJOI': <__main__.CV at 0x119249d68>,\n",
       " 'CV_5_ZHAOIZKEOK': <__main__.CV at 0x119249f98>,\n",
       " 'CV_5_ZHEAIEIJ': <__main__.CV at 0x119250e80>,\n",
       " 'CV_5_ZIA': <__main__.CV at 0x11921a320>,\n",
       " 'CV_5_ZIT': <__main__.CV at 0x11920a048>,\n",
       " 'CV_5_ZIZ': <__main__.CV at 0x119261320>,\n",
       " 'CV_5_ZOK': <__main__.CV at 0x11925a940>,\n",
       " 'CV_5_ZOUHU': <__main__.CV at 0x1192406d8>,\n",
       " 'CV_BD_1': <__main__.CV at 0x1192404e0>,\n",
       " 'CV_BD_2': <__main__.CV at 0x119240b38>,\n",
       " 'CV_BD_3': <__main__.CV at 0x119249358>,\n",
       " 'CV_BD_4': <__main__.CV at 0x119237a58>,\n",
       " 'CV_BD_5': <__main__.CV at 0x119240208>,\n",
       " 'CV_BD_6': <__main__.CV at 0x119237898>,\n",
       " 'CV_BD_7': <__main__.CV at 0x11921af98>,\n",
       " 'CV_DS_1': <__main__.CV at 0x1192611d0>,\n",
       " 'CV_DS_10': <__main__.CV at 0x119261e48>,\n",
       " 'CV_DS_11': <__main__.CV at 0x119261940>,\n",
       " 'CV_DS_12': <__main__.CV at 0x119261128>,\n",
       " 'CV_DS_13': <__main__.CV at 0x1192615c0>,\n",
       " 'CV_DS_14': <__main__.CV at 0x11926b278>,\n",
       " 'CV_DS_15': <__main__.CV at 0x11926b7f0>,\n",
       " 'CV_DS_16': <__main__.CV at 0x1192732b0>,\n",
       " 'CV_DS_2': <__main__.CV at 0x1192619b0>,\n",
       " 'CV_DS_3': <__main__.CV at 0x119261a90>,\n",
       " 'CV_DS_4': <__main__.CV at 0x11926bda0>,\n",
       " 'CV_DS_5': <__main__.CV at 0x119273160>,\n",
       " 'CV_DS_6': <__main__.CV at 0x11926b668>,\n",
       " 'CV_DS_7': <__main__.CV at 0x11926b320>,\n",
       " 'CV_DS_8': <__main__.CV at 0x1191f8b70>,\n",
       " 'CV_DS_9': <__main__.CV at 0x1191f8be0>,\n",
       " 'CV_ETL_1': <__main__.CV at 0x11920f240>,\n",
       " 'CV_ETL_10': <__main__.CV at 0x1192404a8>,\n",
       " 'CV_ETL_11': <__main__.CV at 0x119240a58>,\n",
       " 'CV_ETL_12': <__main__.CV at 0x1192492e8>,\n",
       " 'CV_ETL_13': <__main__.CV at 0x119240278>,\n",
       " 'CV_ETL_2': <__main__.CV at 0x11920f470>,\n",
       " 'CV_ETL_3': <__main__.CV at 0x1191f8eb8>,\n",
       " 'CV_ETL_4': <__main__.CV at 0x11920a3c8>,\n",
       " 'CV_ETL_5': <__main__.CV at 0x11920aef0>,\n",
       " 'CV_ETL_6': <__main__.CV at 0x11920a710>,\n",
       " 'CV_ETL_7': <__main__.CV at 0x11921a6a0>,\n",
       " 'CV_ETL_8': <__main__.CV at 0x119261fd0>,\n",
       " 'CV_ETL_9': <__main__.CV at 0x119261828>,\n",
       " 'CV_MDM_1': <__main__.CV at 0x1191f87b8>,\n",
       " 'CV_MDM_10': <__main__.CV at 0x119250668>,\n",
       " 'CV_MDM_2': <__main__.CV at 0x11920f8d0>,\n",
       " 'CV_MDM_3': <__main__.CV at 0x11920fe48>,\n",
       " 'CV_MDM_4': <__main__.CV at 0x11921a630>,\n",
       " 'CV_MDM_5': <__main__.CV at 0x11921a588>,\n",
       " 'CV_MDM_6': <__main__.CV at 0x11920a080>,\n",
       " 'CV_MDM_7': <__main__.CV at 0x11920af28>,\n",
       " 'CV_MDM_8': <__main__.CV at 0x119261390>,\n",
       " 'CV_MDM_9': <__main__.CV at 0x1192612e8>,\n",
       " 'CV_TalanSolutions_AJOL': <__main__.CV at 0x11926b780>,\n",
       " 'CV_TalanSolutions_FVAL': <__main__.CV at 0x1192493c8>,\n",
       " 'CV_TalanSolutions_JCLE': <__main__.CV at 0x1192499e8>,\n",
       " 'CV_TalanSolutions_JLAG': <__main__.CV at 0x11920fa20>,\n",
       " 'CV_TalanSolutions_MDEB': <__main__.CV at 0x119250ac8>,\n",
       " 'CV_TalanSolutions_WZHA': <__main__.CV at 0x119261630>,\n",
       " 'CV_YWA_TS2017': <__main__.CV at 0x11920a160>,\n",
       " 'Cahier_des_charges_forfait_expertise_technique_A_S_domaine_Décisionnel': <__main__.CV at 0x119273d68>,\n",
       " 'Consultation - Mission Progiciels-v4': <__main__.CV at 0x119273630>,\n",
       " 'Consultation N° 200 CC AST Informatique - profils 502 ou 902 province': <__main__.CV at 0x119273fd0>,\n",
       " 'Consultation n°136 - LYON - SIRH - Concepteur fonctionnel confirmé Déclaratif': <__main__.CV at 0x1192737b8>,\n",
       " 'Consultation n°196- PARIS - ISI - Pôle Données ARMEN- MOA1- 20151019_V2 (2)': <__main__.CV at 0x119273f28>,\n",
       " 'Consultation_ELAN_': <__main__.CV at 0x119273d30>,\n",
       " 'Consultation_HCC_AST_310_-_Contract_Manager_Centre_de_Service': <__main__.CV at 0x119277160>,\n",
       " 'Consultation_HCC_AST_3467-_Chef_de_projet_Décisionnel': <__main__.CV at 0x119273eb8>,\n",
       " 'Consultation_HCC_AST_3484_-_Fiche_expression_de_besoin_-_Chef_de_Projet': <__main__.CV at 0x1192739b0>,\n",
       " 'Consultation_HCC_AST_3485-_Fiche_expression_de_besoin_-_Chef_de_Projet': <__main__.CV at 0x119273588>,\n",
       " 'Consultation_HCC_AST_3486_-_Chef_de_Projet-_Besoin_Socle': <__main__.CV at 0x1192739e8>,\n",
       " 'Consultation_HCC_AST_3496_-_Consultant_confirmé_TM1': <__main__.CV at 0x119273a58>,\n",
       " 'Consultation_HCC_AST_3515_-_Gestionnaire_de_patrimoine_DEC_-_Accès_Réseau': <__main__.CV at 0x119273668>,\n",
       " 'Consultation_Portail__Stocks_ELAN_15-10-2015': <__main__.CV at 0x119273780>,\n",
       " 'DELCV TALAN': <__main__.CV at 0x11920ae48>,\n",
       " 'DELH': <__main__.CV at 0x11921a2e8>,\n",
       " 'DESNO': <__main__.CV at 0x11926bfd0>,\n",
       " 'EBACV TALAN': <__main__.CV at 0x1192379e8>,\n",
       " 'EDIC': <__main__.CV at 0x119249668>,\n",
       " 'EJI_CV_20171201': <__main__.CV at 0x119237438>,\n",
       " 'ELCCV TALAN': <__main__.CV at 0x11920ada0>,\n",
       " 'ELMAA': <__main__.CV at 0x119237550>,\n",
       " 'EXL Group_CV EXL AFI': <__main__.CV at 0x11921aef0>,\n",
       " 'EXL Group_CV EXL_ECH': <__main__.CV at 0x119237940>,\n",
       " 'EXL Group_CV EXL_NIT 2017': <__main__.CV at 0x119250a90>,\n",
       " 'Expression de besoin AST Informatique_PMO': <__main__.CV at 0x1192731d0>,\n",
       " 'FGECV TALAN': <__main__.CV at 0x11920f908>,\n",
       " 'FGICV TALAN': <__main__.CV at 0x11920aa58>,\n",
       " 'FGU_CV Talan': <__main__.CV at 0x1192406a0>,\n",
       " 'FQUCV TALAN': <__main__.CV at 0x119273128>,\n",
       " 'FRANC': <__main__.CV at 0x119237e48>,\n",
       " 'Fiche Expression de Besoin- 909 - Developpeur Tableau Software': <__main__.CV at 0x119273518>,\n",
       " 'Fiche_expression_de_besoin_-_912_-_Chef_de_Projet_Big_Data': <__main__.CV at 0x119273ba8>,\n",
       " 'Fiche_expression_de_besoin_-_Consultant_Technique_Decisionnel_Flume,_Sqoop': <__main__.CV at 0x119273be0>,\n",
       " 'Fiche_expression_de_besoin_-_HCC_AST_271_Tableau_Software_20170908': <__main__.CV at 0x119273b00>,\n",
       " 'GATO': <__main__.CV at 0x11925a160>,\n",
       " 'GCHCV TALAN': <__main__.CV at 0x11925a668>,\n",
       " 'GENT': <__main__.CV at 0x119249a58>,\n",
       " 'GLACV TALAN': <__main__.CV at 0x11921a470>,\n",
       " 'GMAO_SPOT_Outillage_CdC_-_Métier_Fiche_de_Poste_TEMMAR_Cahier_des_charges_R3_': <__main__.CV at 0x119273cf8>,\n",
       " 'GUILB': <__main__.CV at 0x119250438>,\n",
       " 'HABCV TALAN': <__main__.CV at 0x119250860>,\n",
       " 'HALM': <__main__.CV at 0x11921a208>,\n",
       " 'HCC_AST_288_Datastage_confirmé-_CSI_DEC': <__main__.CV at 0x1192735f8>,\n",
       " 'HCC_AST_293-_AMOA_Gestionnaire_Réclamations-_SEO_MIS': <__main__.CV at 0x119273ac8>,\n",
       " 'HCC_AST_3468-_Chef_de_projet_Décisionnel': <__main__.CV at 0x119273ef0>,\n",
       " 'HDUCV Talan': <__main__.CV at 0x11926b550>,\n",
       " 'HGZCV TALAN': <__main__.CV at 0x119240c50>,\n",
       " 'HHACV TALAN': <__main__.CV at 0x1192407f0>,\n",
       " 'HILAL': <__main__.CV at 0x119261cc0>,\n",
       " 'HITI': <__main__.CV at 0x11926b198>,\n",
       " 'HMECV TALAN': <__main__.CV at 0x1191f8f28>,\n",
       " 'HNOCV TALAN': <__main__.CV at 0x119250828>,\n",
       " 'HYVER': <__main__.CV at 0x11925a860>,\n",
       " 'IBNCV Talan': <__main__.CV at 0x1192509e8>,\n",
       " 'IDD': <__main__.CV at 0x119249b38>,\n",
       " 'IMAH': <__main__.CV at 0x11921ae80>,\n",
       " 'JBACV TALAN': <__main__.CV at 0x119261240>,\n",
       " 'JBECV TALAN': <__main__.CV at 0x119237160>,\n",
       " 'JCOCV TALAN': <__main__.CV at 0x1191f8ac8>,\n",
       " 'JJUCV TALAN': <__main__.CV at 0x119249cf8>,\n",
       " 'KADI': <__main__.CV at 0x11920a400>,\n",
       " 'KAHT': <__main__.CV at 0x11926b048>,\n",
       " 'KMACV TALAN': <__main__.CV at 0x11925add8>,\n",
       " 'KOZ': <__main__.CV at 0x11920a198>,\n",
       " 'LARI': <__main__.CV at 0x11920f1d0>,\n",
       " 'LARO': <__main__.CV at 0x11921a518>,\n",
       " 'LEBO': <__main__.CV at 0x119250f98>,\n",
       " 'LEPR': <__main__.CV at 0x11920f6d8>,\n",
       " 'LNTCV TALAN': <__main__.CV at 0x11920acc0>,\n",
       " 'LOUCV TALAN': <__main__.CV at 0x11925ab70>,\n",
       " 'MARI': <__main__.CV at 0x119249518>,\n",
       " 'MBECV TALAN': <__main__.CV at 0x119249160>,\n",
       " 'MHMCV TALAN': <__main__.CV at 0x119250d68>,\n",
       " 'MIFO': <__main__.CV at 0x119237b38>,\n",
       " 'MRICV TALAN': <__main__.CV at 0x119261b70>,\n",
       " 'MYOD': <__main__.CV at 0x11925a6d8>,\n",
       " 'Mission_AMO_Planification_PSNext': <__main__.CV at 0x1192771d0>,\n",
       " 'NAJCV ALJANE': <__main__.CV at 0x119240550>,\n",
       " 'NGACV TALAN': <__main__.CV at 0x11920ae10>,\n",
       " 'NGUCV Talan': <__main__.CV at 0x119273080>,\n",
       " 'NGUE': <__main__.CV at 0x119249f28>,\n",
       " 'NSACV TALAN': <__main__.CV at 0x119240780>,\n",
       " 'ORICV TALAN': <__main__.CV at 0x11920f5c0>,\n",
       " 'OUAA': <__main__.CV at 0x119249eb8>,\n",
       " 'OUEG': <__main__.CV at 0x11920a6d8>,\n",
       " 'PIERM': <__main__.CV at 0x11925a438>,\n",
       " 'PLAM': <__main__.CV at 0x11925a588>,\n",
       " 'PVNCV TALAN': <__main__.CV at 0x119237c88>,\n",
       " 'Prestation ASTR MOA Consultant fonct  erp  Maximo-v0 8-2015-9 (1)': <__main__.CV at 0x1192733c8>,\n",
       " 'Prestation ASTR MOA Fonctionnel Maximo-v0 4(Profil opérationnel)': <__main__.CV at 0x119273a90>,\n",
       " 'Prestation ASTR MOA Fonctionnel Maximo-v0 4(Profil étude)': <__main__.CV at 0x119273b38>,\n",
       " 'RAVA': <__main__.CV at 0x11920f2b0>,\n",
       " 'RHICV TALAN': <__main__.CV at 0x119237278>,\n",
       " 'ROUS': <__main__.CV at 0x11921a128>,\n",
       " 'RPICV TALAN': <__main__.CV at 0x119237908>,\n",
       " 'SADO': <__main__.CV at 0x11920f400>,\n",
       " 'SALM': <__main__.CV at 0x1192503c8>,\n",
       " 'SBECV TALAN': <__main__.CV at 0x11926bef0>,\n",
       " 'SBOU': <__main__.CV at 0x11925af28>,\n",
       " 'SBRCV TALAN': <__main__.CV at 0x119237c18>,\n",
       " 'SDECV TALAN': <__main__.CV at 0x119261f28>,\n",
       " 'SDZCV TALAN': <__main__.CV at 0x119261b00>,\n",
       " 'SFRCV TALAN': <__main__.CV at 0x119250198>,\n",
       " 'SMACV TALAN': <__main__.CV at 0x11926b2e8>,\n",
       " 'SNCF-Consultation-STELSIA n°176 - mission progiciels DEC V4 - réponse technique EXL Group': <__main__.CV at 0x119273828>,\n",
       " 'SPECV TALAN': <__main__.CV at 0x1192501d0>,\n",
       " 'TJACV TALAN': <__main__.CV at 0x1192610b8>,\n",
       " 'Talan - CV ABEN': <__main__.CV at 0x11925a358>,\n",
       " 'Talan - CV AFAB': <__main__.CV at 0x1192730b8>,\n",
       " 'Talan - CV AGIR': <__main__.CV at 0x11920f7f0>,\n",
       " 'Talan - CV ALJN': <__main__.CV at 0x11925a2e8>,\n",
       " 'Talan - CV CLEV': <__main__.CV at 0x119250358>,\n",
       " 'Talan - CV COUA': <__main__.CV at 0x119249048>,\n",
       " 'Talan - CV EGTA': <__main__.CV at 0x119261ef0>,\n",
       " 'Talan - CV IARK': <__main__.CV at 0x119249240>,\n",
       " 'Talan - CV MPRO': <__main__.CV at 0x11926be48>,\n",
       " 'Talan - CV RDJE': <__main__.CV at 0x119249278>,\n",
       " 'Talan - CV SBES': <__main__.CV at 0x11920a4e0>,\n",
       " 'Talan - CV SSOW': <__main__.CV at 0x119249940>,\n",
       " 'Talans solutions_CV Talans_MTR juillet 2017': <__main__.CV at 0x11925a630>,\n",
       " 'UZUN': <__main__.CV at 0x119261710>,\n",
       " 'VCACV TALAN': <__main__.CV at 0x11925a5f8>,\n",
       " 'VLOCV TALAN': <__main__.CV at 0x119261470>,\n",
       " 'WANK': <__main__.CV at 0x11920f320>,\n",
       " 'WBECV TALAN': <__main__.CV at 0x1192732e8>,\n",
       " 'ZEKR': <__main__.CV at 0x11926b9e8>,\n",
       " 'file': <__main__.CV at 0x1191f89b0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dico_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des sauts de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[%s]' % '(\\\\n)*(\\\\x0c)*')\n",
    "def del_line_feed(s):  \n",
    "    \"\"\"Delete \\n in the text\"\"\"\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, cv in dico_global.items():\n",
    "    cv.cv = del_line_feed(cv.cv).lower()\n",
    "    dico_global[key] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultant junior amoa  formation  1 janvier 2011 - 1 novembre 2011 master 2 entrepreneuriat: stratégie marketing et commerciale, elaboration du business plan, gestion financière sup'career, paris  1 octobre 2007 - 1 décembre 2008 master 1 entrepreneuriat: conception et evaluation de projets, management des organisations, contrôle de gestion  université paris 12,  créteil  compétences  savoir-faire: gestion de la relation client - conseil - gestion de portefeuille de clients professionnels - techniques de planification - gestion de projets - marketing informatique logiciels de gestion: erp: crm  bureautique: pack office  word, excel, access, powerpoint   expérience professionnelle  27 novembre 2015 - 29 septembre 2016 téléconseillère, qualigaz, aubervilliers 8 septembre 2014 - 9 mai 2015 conseillère clientèle, comearth, orsay 11 novembre 2013 - 29 août 2014 assistante maternelle, particulier, paris 1 février 2012 - 15 mai 2012 conseillère clientèle, olympus france, rungis 1 décembre 2010 - 30 mars 2011 assistante administrative, mtpro services, pierrelaye 1 juin 2009 - 14 mars 2010 chargée d'assistance automobile, axa assistance, chatillon 1 avril 2008 - 30 septembre 2008 stage assistant chef de projet, smartbox, levallois  langues  anglais conversationnel   formation encours: anglais professionnel   centres d'intérêt  chant, lecture, couture, coiffure   \n"
     ]
    }
   ],
   "source": [
    "for key, value in dico_global.items():\n",
    "    print(value.cv)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#le maintient de la ponctuation pertube le stop words, apostrophe gérée dans text_treatment\n",
    "regex = re.compile('[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_{|}~')) \n",
    "\n",
    "def del_punct(s):  \n",
    "    \"\"\"Delete punctuation in the text\"\"\"\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test \n",
    "#liste_cv_no_punc = [del_punct(text) for text in liste_cv]\n",
    "for key, cv in dico_global.items():\n",
    "    cv.cv = del_punct(cv.cv)\n",
    "    dico_global[key] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultant junior amoa  formation  1 janvier 2011   1 novembre 2011 master 2 entrepreneuriat  stratégie marketing et commerciale  elaboration du business plan  gestion financière sup'career  paris  1 octobre 2007   1 décembre 2008 master 1 entrepreneuriat  conception et evaluation de projets  management des organisations  contrôle de gestion  université paris 12   créteil  compétences  savoir faire  gestion de la relation client   conseil   gestion de portefeuille de clients professionnels   techniques de planification   gestion de projets   marketing informatique logiciels de gestion  erp  crm  bureautique  pack office  word  excel  access  powerpoint   expérience professionnelle  27 novembre 2015   29 septembre 2016 téléconseillère  qualigaz  aubervilliers 8 septembre 2014   9 mai 2015 conseillère clientèle  comearth  orsay 11 novembre 2013   29 août 2014 assistante maternelle  particulier  paris 1 février 2012   15 mai 2012 conseillère clientèle  olympus france  rungis 1 décembre 2010   30 mars 2011 assistante administrative  mtpro services  pierrelaye 1 juin 2009   14 mars 2010 chargée d'assistance automobile  axa assistance  chatillon 1 avril 2008   30 septembre 2008 stage assistant chef de projet  smartbox  levallois  langues  anglais conversationnel   formation encours  anglais professionnel   centres d'intérêt  chant  lecture  couture  coiffure   \n"
     ]
    }
   ],
   "source": [
    "#liste_cv_no_punc[0]\n",
    "for key, value in dico_global.items():\n",
    "    print(value.cv)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reconnaissance du langage du CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_languages_ratios(text):\n",
    "    \"\"\"\n",
    "    Calculate probability of given text to be written in several languages and\n",
    "    return a dictionary that looks like {'french': 2, 'spanish': 4, 'english': 0}\n",
    "    \"\"\"\n",
    "\n",
    "    languages_ratios = {}\n",
    "\n",
    "    '''\n",
    "    nltk.wordpunct_tokenize() splits all punctuations into separate tokens\n",
    "    \n",
    "    >>> wordpunct_tokenize(\"That's thirty minutes away. I'll be there in ten.\")\n",
    "    ['That', \"'\", 's', 'thirty', 'minutes', 'away', '.', 'I', \"'\", 'll', 'be', 'there', 'in', 'ten', '.']\n",
    "    '''\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens] #from text get list of word in minuscule\n",
    "\n",
    "    \n",
    "    for language in stopwords.fileids(): # pour chaque langue\n",
    "        stopwords_set = set(stopwords.words(language)) #je mets les stop words du langage dans un set\n",
    "        words_set = set(words) #je mets les mots de mon texte dans un set\n",
    "        #je prends l'intersection entre les mots de mon texte et les mots du stopwords dans le langage donné\n",
    "        common_elements = words_set & stopwords_set\n",
    "        \n",
    "        #je compute mon score comme le nombre d'éléments en communs dictionnaire [langage : score]\n",
    "        languages_ratios[language] = len(common_elements) # language \"score\"\n",
    "\n",
    "    return languages_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mehdiregina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cv_langue(liste_cv, language) :\n",
    "    \"\"\"Return resume witten in the specified language in parameter\"\"\"\n",
    "    liste_2 = []\n",
    "    for cv in liste_cv:\n",
    "        if max(_calculate_languages_ratios(cv),key =_calculate_languages_ratios(cv).get)=='french':\n",
    "            liste_2.append(cv)\n",
    "    return liste_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, cv in dico_global.items():\n",
    "    calc = _calculate_languages_ratios(cv.cv)\n",
    "    if max(calc, key=calc.get)!='french':\n",
    "        ##del dico_cv[key]\n",
    "        cv.cv = \"\"\n",
    "        dico_global[k] = cv\n",
    "\n",
    "dico_global = {key:dico_global[key] for key in dico_global.keys() if dico_global[key].cv != \"\"}        \n",
    "len(dico_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultant junior amoa  formation  1 janvier 2011   1 novembre 2011 master 2 entrepreneuriat  stratégie marketing et commerciale  elaboration du business plan  gestion financière sup'career  paris  1 octobre 2007   1 décembre 2008 master 1 entrepreneuriat  conception et evaluation de projets  management des organisations  contrôle de gestion  université paris 12   créteil  compétences  savoir faire  gestion de la relation client   conseil   gestion de portefeuille de clients professionnels   techniques de planification   gestion de projets   marketing informatique logiciels de gestion  erp  crm  bureautique  pack office  word  excel  access  powerpoint   expérience professionnelle  27 novembre 2015   29 septembre 2016 téléconseillère  qualigaz  aubervilliers 8 septembre 2014   9 mai 2015 conseillère clientèle  comearth  orsay 11 novembre 2013   29 août 2014 assistante maternelle  particulier  paris 1 février 2012   15 mai 2012 conseillère clientèle  olympus france  rungis 1 décembre 2010   30 mars 2011 assistante administrative  mtpro services  pierrelaye 1 juin 2009   14 mars 2010 chargée d'assistance automobile  axa assistance  chatillon 1 avril 2008   30 septembre 2008 stage assistant chef de projet  smartbox  levallois  langues  anglais conversationnel   formation encours  anglais professionnel   centres d'intérêt  chant  lecture  couture  coiffure   \n"
     ]
    }
   ],
   "source": [
    "for key, value in dico_global.items():\n",
    "    print(value.cv)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocessing du text **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_treatment (text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\x00\", '').replace(\"\\x01\", '').replace(\"\\x02\", '').replace(\"\\x03\", '') \\\n",
    "    .replace(\"\\x04\", '').replace(\"\\x05\", '').replace(\"\\x06\", '').replace(\"\\x07\", '').replace(\"\\x08\", '') \\\n",
    "    .replace(\"\\x0e\", '').replace(\"\\x11\", '').replace(\"\\x12\", '').replace(\"\\x10\", '').replace(\"\\x19\", '') \\\n",
    "    .replace(\"\\x1b\", '').replace(\"\\x14\", '').replace(\"\\x15\", '').replace('/', '').replace('=', '').replace(\"〓\", \"\") \\\n",
    "    .replace(\"»\", \"\").replace(\"«\", \"\").replace(\"¬\", \"\").replace('`', '').replace (\" -\", \"\").replace(\"•\", \"\")\\\n",
    "    .replace(\"l'\", \"\").replace(\"l’\", \"\").replace(\"l´\", \"\").replace(\"d’\", \"\").replace(\"d'\", \"\").replace(\"d´\",\"\")\\\n",
    "    .replace(\"j’\", \"\").replace(\"j'\", \"\").replace(\"j´\",\"\").replace(\"n’\", \"\").replace(\"n'\", \"\").replace(\"n´\",\"\")\\\n",
    "    .replace(\"”\", \"\").replace(\"~\", \"\").replace(\"§\", \"\").replace(\"¨\", \"\").replace(\"©\", \"\").replace(\"›\", \"\")\\\n",
    "    .replace(\"₋\", \"\").replace(\"→\", \"\").replace(\"⇨\", \"\").replace(\"∎\", \"\").replace(\"√\", \"\").replace(\"□\", \"\")\\\n",
    "    .replace(\"*\", \"\").replace(\"&\", \"\").replace(\"►\", \"\").replace(\"◊\", \"\").replace(\"☞\", \"\").replace(\"#\", \"\")\\\n",
    "    .replace(\"%\", \"\").replace(\"❖\", \"\").replace(\"➠\", \"\").replace(\"➢\", \"\").replace(\"\", \"\").replace(\"✓\", \"\") \\\n",
    "    .replace(\"√\", \"\").replace(\"✔\", \"\").replace(\"♦\", \"\").replace(\"◦\", \"\").replace(\"●\", \"\").replace(\"▫\", \"\")\\\n",
    "    .replace(\"▪\", \"\").replace(\"…\", \"\").replace(\"þ\", \"\").replace(\"®\", \"\").replace('', '').replace(\"...\", \"\")\\\n",
    "    .replace(\" o \", \"\")\n",
    "    text = unidecode.unidecode(text) # remove accent\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On supprime les caractères étranges et accents\n",
    "#liste_cv_treated = [text_treatment(text) for text in liste_cv_fr]\n",
    "for key, cv in dico_global.items():\n",
    "    cv.cv = text_treatment(cv.cv)\n",
    "    dico_global[key] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultant junior amoa  formation  1 janvier 2011   1 novembre 2011 master 2 entrepreneuriat  strategie marketing et commerciale  elaboration du business plan  gestion financiere sup'career  paris  1 octobre 2007   1 decembre 2008 master 1 entrepreneuriat  conception et evaluation de projets  management des organisations  controle de gestion  universite paris 12   creteil  competences  savoir faire  gestion de la relation client   conseil   gestion de portefeuille de clients professionnels   techniques de planification   gestion de projets   marketing informatique logiciels de gestion  erp  crm  bureautique  pack office  word  excel  access  powerpoint   experience professionnelle  27 novembre 2015   29 septembre 2016 teleconseillere  qualigaz  aubervilliers 8 septembre 2014   9 mai 2015 conseillere clientele  comearth  orsay 11 novembre 2013   29 aout 2014 assistante maternelle  particulier  paris 1 fevrier 2012   15 mai 2012 conseillere clientele  olympus france  rungis 1 decembre 2010   30 mars 2011 assistante administrative  mtpro services  pierrelaye 1 juin 2009   14 mars 2010 chargee assistance automobile  axa assistance  chatillon 1 avril 2008   30 septembre 2008 stage assistant chef de projet  smartbox  levallois  langues  anglais conversationnel   formation encours  anglais professionnel   centres interet  chant  lecture  couture  coiffure   \n"
     ]
    }
   ],
   "source": [
    "#liste_cv_treated[0]\n",
    "for key, value in dico_global.items():\n",
    "    print(value.cv)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gestion des stop words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille stop words liste :  416\n"
     ]
    }
   ],
   "source": [
    "#generate stopwords\n",
    "stop_words_py = set(stop_words.get_stop_words('french'))\n",
    "\n",
    "# attention certains stop words pourraient être utiles par la suite\n",
    "stopwords_set_manuel = set([\"an\", \"ans\", 'les', 'moins', 'd\\'un','janvier', 'fevrier', 'février', 'mars', 'avril', \\\n",
    "                 'mai', 'juin', 'juillet', 'aout', 'août', 'septembre', 'octobre', 'novembre', 'décembre', \\\n",
    "                  'decembre', 'moins', 'mise', 'universit\\xc3\\xa9', 'université', 'universite', 'ion','sage', \\\n",
    "                  'o', 'rac', 'vers', 'via', 'p\\xc3\\xa9rim\\xc3\\xa8tre', 'périmètre','et','paris','x',\"\\x00\",\\\n",
    "                          \"\\x01\",\"\\x02\", \"\\x03\",\"\\x04\",\"\\x05\",\"\\x06\",\"\\x07\",\"\\x08\",\"\\x09\",\"\\x0e\",\"\\x0e\",\"\\x11\",\\\n",
    "                           \"\\x12\",\"\\x13\",\"\\x14\",\"\\x15\",\"\\x16\",\"\\x17\",\"\\x18\",\"\\x19\",\"transport\",\"puis\",\"lieu\",\\\n",
    "                           \"adresse\",\"entre\",'dun','dune','chez','boulognebillancourt','bt','etc','recrutement','main',\\\n",
    "                           'and', 'paie','paiement','environ','place','france','paris','mois','mobile','mobiles',\\\n",
    "                           'nanterre','source','sources','concerne','concernant','of','non','notes','rh','minimum',\\\n",
    "                           'maximum','bac','site','sites','actuellement','telephone','telephonique','telephoniques','ca','demenager',\\\n",
    "                           'demenagement','participer','participation','lycee','baccalaureat','lien','liens','in',\\\n",
    "                           'indeed','email','indeedcomrd7e8913ed00d0384','aujourhui','afin','toujours','enterprise',\\\n",
    "                           \"guide\",\"10g\",\"11g\",\"9i\",'ad','v10','v2','v3','v5','v6','v8','v9','pablo','neruda',\\\n",
    "                           'dec','stelsia','cid1','sens','va','24h24', '7j7', 'levalloisperret','louis', 'armand', 'ermont',\\\n",
    "                            'localisation','anne', 'perot',' s ','mission', 'date', 'debut','fin','avenue', 'val', 'oise',\\\n",
    "                           'echeant','bout','division','prestations', 'intellectuelles', 'contexte','descroix','24h', '7j',\\\n",
    "                           'disposition','places','moyens', 'sncf', 'mis','rue','levallois','perret','scnf','ainsi',\\\n",
    "                           \"jusqu'au\",\"jusqu'a\",'ast','exercant','souhaitee'])\n",
    "stop_words_main = stop_words_py | stopwords_set_manuel\n",
    "stop_words_main = list(stop_words_main)\n",
    "print(\"taille stop words liste : \", len(stop_words_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cela',\n",
       " 'afin',\n",
       " 'serez',\n",
       " 'sommes',\n",
       " 'lycee',\n",
       " 'v9',\n",
       " 'sans',\n",
       " 'neruda',\n",
       " 'sujet',\n",
       " 'juin',\n",
       " 'n',\n",
       " 'octobre',\n",
       " 'decembre',\n",
       " 'début',\n",
       " 'eux',\n",
       " 'auras',\n",
       " 'eussiez',\n",
       " 'du',\n",
       " 'nous',\n",
       " 'ainsi',\n",
       " 'nommés',\n",
       " 'levallois',\n",
       " 'fus',\n",
       " 'eus',\n",
       " 'bon',\n",
       " 'va',\n",
       " 'bac',\n",
       " 'de',\n",
       " 'maximum',\n",
       " '7j7',\n",
       " 'levalloisperret',\n",
       " 'tout',\n",
       " 'quelles',\n",
       " 'contexte',\n",
       " 'environ',\n",
       " 'localisation',\n",
       " 'aurai',\n",
       " 'nom',\n",
       " 'enterprise',\n",
       " 'vous',\n",
       " 'te',\n",
       " 'telephone',\n",
       " 'devriez',\n",
       " 'seras',\n",
       " 'mis',\n",
       " 'vers',\n",
       " 'personne',\n",
       " '\\t',\n",
       " 'aient',\n",
       " 'ai',\n",
       " 'devoir',\n",
       " 'sur',\n",
       " 'perret',\n",
       " 'avec',\n",
       " 'l',\n",
       " 'étés',\n",
       " \"jusqu'au\",\n",
       " 'ast',\n",
       " 'soyez',\n",
       " 'seront',\n",
       " 'actuellement',\n",
       " 'ad',\n",
       " 'mot',\n",
       " 'nos',\n",
       " 'cet',\n",
       " '\\x12',\n",
       " 'lien',\n",
       " 'août',\n",
       " 'telephoniques',\n",
       " 'lui',\n",
       " 'cette',\n",
       " 'eue',\n",
       " 'an',\n",
       " 'dois',\n",
       " 'pas',\n",
       " '10g',\n",
       " 'étions',\n",
       " 'ils',\n",
       " 'dù',\n",
       " 'fin',\n",
       " 'faire',\n",
       " 'me',\n",
       " 'où',\n",
       " 'juillet',\n",
       " 'étiez',\n",
       " 'se',\n",
       " '\\x13',\n",
       " 'anne',\n",
       " 'x',\n",
       " '\\x05',\n",
       " 'un',\n",
       " 'avenue',\n",
       " 'seraient',\n",
       " 'transport',\n",
       " ' s ',\n",
       " \"d'un\",\n",
       " 'droite',\n",
       " '\\x17',\n",
       " 'mission',\n",
       " 'dos',\n",
       " 'fussions',\n",
       " 'à',\n",
       " 'v8',\n",
       " 'état',\n",
       " 'décembre',\n",
       " 'avions',\n",
       " 'ca',\n",
       " 'es',\n",
       " 'recrutement',\n",
       " 'o',\n",
       " 'depuis',\n",
       " 'très',\n",
       " 'v10',\n",
       " 'stelsia',\n",
       " 'debut',\n",
       " 'moyens',\n",
       " 'mai',\n",
       " 'moi',\n",
       " 'v6',\n",
       " 'soyons',\n",
       " 'avais',\n",
       " 'aux',\n",
       " 'ceci',\n",
       " 'pablo',\n",
       " 'fusses',\n",
       " 'v3',\n",
       " 'une',\n",
       " 'demenagement',\n",
       " 'dec',\n",
       " 'par',\n",
       " 'novembre',\n",
       " 'fussiez',\n",
       " 'nouveaux',\n",
       " 'j',\n",
       " 'universitÃ©',\n",
       " 'v5',\n",
       " 'eues',\n",
       " 'ma',\n",
       " 'source',\n",
       " 'indeedcomrd7e8913ed00d0384',\n",
       " 'in',\n",
       " 'haut',\n",
       " 'sncf',\n",
       " 'adresse',\n",
       " 'fut',\n",
       " 'personnes',\n",
       " 'eu',\n",
       " 'avant',\n",
       " 'indeed',\n",
       " '\\x04',\n",
       " 'que',\n",
       " 'souhaitee',\n",
       " 'avaient',\n",
       " 'ne',\n",
       " 'tu',\n",
       " 'aucun',\n",
       " 'demenager',\n",
       " '9i',\n",
       " 'avoir',\n",
       " 'aurez',\n",
       " 'devront',\n",
       " 'hors',\n",
       " 'aurons',\n",
       " 'ermont',\n",
       " 'être',\n",
       " 'mars',\n",
       " 'eusse',\n",
       " 'tellement',\n",
       " 'etc',\n",
       " 'janvier',\n",
       " '24h',\n",
       " 'paiement',\n",
       " 'auraient',\n",
       " '\\x19',\n",
       " 'notre',\n",
       " 'sont',\n",
       " 'bout',\n",
       " 'voit',\n",
       " 'mais',\n",
       " '\\x02',\n",
       " 'parole',\n",
       " 'devrait',\n",
       " 'fûmes',\n",
       " 'serions',\n",
       " '\\x03',\n",
       " '\\x06',\n",
       " 'main',\n",
       " '\\x00',\n",
       " 'baccalaureat',\n",
       " 'places',\n",
       " 'eût',\n",
       " 'boulognebillancourt',\n",
       " 'aies',\n",
       " 'leurs',\n",
       " 'avons',\n",
       " 'participation',\n",
       " 'a',\n",
       " 'quand',\n",
       " 'eusses',\n",
       " 'prestations',\n",
       " 't',\n",
       " 'avril',\n",
       " 'intellectuelles',\n",
       " 'doit',\n",
       " 'rac',\n",
       " 'sens',\n",
       " 'ceux',\n",
       " 'sien',\n",
       " 'of',\n",
       " 'chez',\n",
       " 'date',\n",
       " 'tous',\n",
       " 'mes',\n",
       " 'rue',\n",
       " 'aout',\n",
       " 'bt',\n",
       " '11g',\n",
       " 'universite',\n",
       " 'aurions',\n",
       " 'devrions',\n",
       " 'parce',\n",
       " 'même',\n",
       " 'ton',\n",
       " 'là',\n",
       " 'eûmes',\n",
       " 'paris',\n",
       " 'via',\n",
       " 'puis',\n",
       " 'aviez',\n",
       " 'force',\n",
       " '\\x01',\n",
       " 'lieu',\n",
       " 'ans',\n",
       " '\\x14',\n",
       " 'dedans',\n",
       " 'disposition',\n",
       " 'serons',\n",
       " 'septembre',\n",
       " 'université',\n",
       " 'plupart',\n",
       " '7j',\n",
       " 'peut',\n",
       " 'elle',\n",
       " 'aurait',\n",
       " 'vos',\n",
       " 'ça',\n",
       " 'sois',\n",
       " 'étais',\n",
       " 'comment',\n",
       " 'les',\n",
       " 'm',\n",
       " 'elles',\n",
       " 'vois',\n",
       " 'aussi',\n",
       " 'ayez',\n",
       " 'v2',\n",
       " 'alors',\n",
       " 'si',\n",
       " 'as',\n",
       " 'auriez',\n",
       " 'scnf',\n",
       " 'eûtes',\n",
       " 'font',\n",
       " '\\x18',\n",
       " 'division',\n",
       " 'fait',\n",
       " 'exercant',\n",
       " 'devrons',\n",
       " 'tels',\n",
       " 'peu',\n",
       " 'ce',\n",
       " 'participer',\n",
       " 'concerne',\n",
       " 'france',\n",
       " 'furent',\n",
       " 'au',\n",
       " 'faisez',\n",
       " 'fois',\n",
       " 'mise',\n",
       " 'ou',\n",
       " 'auront',\n",
       " 'ont',\n",
       " 'toujours',\n",
       " 'soient',\n",
       " 'serais',\n",
       " 'encore',\n",
       " 'minimum',\n",
       " 'sites',\n",
       " 'paie',\n",
       " '\\x08',\n",
       " 'ses',\n",
       " 'ci',\n",
       " 'toi',\n",
       " 'perot',\n",
       " 'ait',\n",
       " 'email',\n",
       " 'and',\n",
       " 'maintenant',\n",
       " 'concernant',\n",
       " 'dehors',\n",
       " 'et',\n",
       " 'ion',\n",
       " 'autre',\n",
       " 'aujourhui',\n",
       " 'louis',\n",
       " 'nommé',\n",
       " 'ni',\n",
       " 'février',\n",
       " 'serai',\n",
       " '\\x15',\n",
       " 'fevrier',\n",
       " 'armand',\n",
       " 'on',\n",
       " 'des',\n",
       " 'oise',\n",
       " 'telephonique',\n",
       " 'ces',\n",
       " 'liens',\n",
       " 'donc',\n",
       " 'descroix',\n",
       " 'avait',\n",
       " 'car',\n",
       " 'cid1',\n",
       " 'fussent',\n",
       " 'juste',\n",
       " 'été',\n",
       " 'périmètre',\n",
       " 'site',\n",
       " 'vu',\n",
       " 'faites',\n",
       " 'eut',\n",
       " 'nanterre',\n",
       " 'aura',\n",
       " 'êtes',\n",
       " 'dans',\n",
       " 'mon',\n",
       " 'dun',\n",
       " 'deux',\n",
       " 'pÃ©rimÃ¨tre',\n",
       " 'aie',\n",
       " 'étaient',\n",
       " 'la',\n",
       " 'dès',\n",
       " 'en',\n",
       " 'guide',\n",
       " 'suis',\n",
       " 'ta',\n",
       " 'y',\n",
       " 'qui',\n",
       " '24h24',\n",
       " 'fût',\n",
       " '\\x0e',\n",
       " 'pourquoi',\n",
       " 'soi',\n",
       " 'son',\n",
       " 'était',\n",
       " 'le',\n",
       " '\\x11',\n",
       " 'vont',\n",
       " 'sera',\n",
       " 'quels',\n",
       " 'valeur',\n",
       " 'comme',\n",
       " 'voient',\n",
       " 'avez',\n",
       " 'fais',\n",
       " '\\x16',\n",
       " 'quel',\n",
       " 'sources',\n",
       " '\\x07',\n",
       " 'il',\n",
       " 'pour',\n",
       " 'tandis',\n",
       " 'sous',\n",
       " 'eussions',\n",
       " 'rh',\n",
       " 'eurent',\n",
       " 'd',\n",
       " 'ici',\n",
       " 'soit',\n",
       " 'entre',\n",
       " 'est',\n",
       " 'devrez',\n",
       " 'mobile',\n",
       " 'sage',\n",
       " 'dune',\n",
       " 'mobiles',\n",
       " \"jusqu'a\",\n",
       " 'ayant',\n",
       " 'non',\n",
       " 'fûtes',\n",
       " 'trop',\n",
       " 'sa',\n",
       " 'val',\n",
       " 'notes',\n",
       " 'seulement',\n",
       " 'mois',\n",
       " 'serait',\n",
       " 'quelle',\n",
       " 'echeant',\n",
       " 'moins',\n",
       " 'ayons',\n",
       " 'chaque',\n",
       " 'place',\n",
       " 'je',\n",
       " 'nommée',\n",
       " 'fusse',\n",
       " 'tes',\n",
       " 'étant',\n",
       " 'nouveau',\n",
       " 'eussent',\n",
       " 'aurais',\n",
       " 'votre',\n",
       " 'qu',\n",
       " 'seriez',\n",
       " 'leur']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#voir si utile\n",
    "def remove_stopwords(text,stopwords_list):\n",
    "    text_temp = \" \".join(text.split())+\" \"\n",
    "    for word in stopwords_list:\n",
    "        text_temp = text_temp.replace(\" \"+word+\" \", \" \")\n",
    "    return text_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, cv in dico_global.items():\n",
    "    cv.cv = remove_stopwords(cv.cv, stop_words_main)\n",
    "    dico_global[key] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultant junior amoa formation 1 2011 1 2011 master 2 entrepreneuriat strategie marketing commerciale elaboration business plan gestion financiere sup'career 1 2007 1 2008 master 1 entrepreneuriat conception evaluation projets management organisations controle gestion 12 creteil competences savoir gestion relation client conseil gestion portefeuille clients professionnels techniques planification gestion projets marketing informatique logiciels gestion erp crm bureautique pack office word excel access powerpoint experience professionnelle 27 2015 29 2016 teleconseillere qualigaz aubervilliers 8 2014 9 2015 conseillere clientele comearth orsay 11 2013 29 2014 assistante maternelle particulier 1 2012 15 2012 conseillere clientele olympus rungis 1 2010 30 2011 assistante administrative mtpro services pierrelaye 1 2009 14 2010 chargee assistance automobile axa assistance chatillon 1 2008 30 2008 stage assistant chef projet smartbox langues anglais conversationnel formation encours anglais professionnel centres interet chant lecture couture coiffure \n"
     ]
    }
   ],
   "source": [
    "for key, value in dico_global.items():\n",
    "    print(value.cv)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SnowballStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "\n",
    "for key, cv in dico_global.items():\n",
    "    #cv.cv = remove_stopwords(cv.cv, stop_words_main)\n",
    "    #dico_cv[key] = cv\n",
    "    allwords_stemmed = tokenize_and_stem(cv.cv) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(cv.cv)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "\n",
    "\n",
    "#for i in liste_cv_no_stop:\n",
    "    #allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    #totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    #allwords_tokenized = tokenize_only(i)\n",
    "    #totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 260259 items in vocab_frame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')\n",
    "len(vocab_frame['words'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vocab.txt\",\"r\") as file:\n",
    "    vocab_list = file.read()\n",
    "vocab_list = vocab_list.split(\",\")[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACP X KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.5,min_df=0.05,\\\n",
    "                           #preprocessor=text_treatment,tokenizer=tokenize_and_stem, ngram_range=(3,3))\n",
    "    \n",
    "# sans stemming : \n",
    "    \n",
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,vocabulary=vocab_list,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#matrix = count_vec.fit_transform(liste_cv_no_stop)\n",
    "liste_cv_no_stop = list()\n",
    "liste_title = list()\n",
    "liste_doctype = list()\n",
    "for key, cv in dico_global.items():\n",
    "    cv.cv = remove_stopwords(cv.cv, stop_words_main)\n",
    "    liste_cv_no_stop.append(cv.cv)\n",
    "    liste_title.append(cv.filename)\n",
    "    liste_doctype.append(cv.doc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_idf_indeed = tf_vect.fit_transform(liste_cv_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 361)\n",
      "668\n",
      "668\n",
      "668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ao', 'cv'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bow_idf_indeed.shape)\n",
    "bow_idf_indeed\n",
    "print(len(liste_cv_no_stop))\n",
    "\n",
    "print(len(liste_cv_no_stop))\n",
    "print(len(liste_cv_no_stop))\n",
    "\n",
    "bow_idf_indeed[0] # 1er doc\n",
    "liste_cv_no_stop[0]\n",
    "liste_title[0]\n",
    "set(liste_doctype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_eucl_dist(v1, v2):\n",
    "    a = np.array(v1)\n",
    "    b = np.array(v2)\n",
    "    return np.dot((a-b), np.transpose(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liste_cv_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AO_CV_Dist:\n",
    "    def __init__(self, ao, cv, dist):\n",
    "        self.ao = ao\n",
    "        self.cv = cv\n",
    "        self.dist = dist\n",
    "        \n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'ao': self.ao,\n",
    "            'cv': self.cv,\n",
    "            'dist': self.dist,\n",
    "        }\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute euc. distance ao cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_ao_cv = list()\n",
    "list_df = list()\n",
    "for i in range(0, len(liste_cv_no_stop)):\n",
    "    if liste_doctype[i] == 'ao':\n",
    "        list_by_ao = list()\n",
    "        for j in range(0, len(liste_cv_no_stop)):\n",
    "            if i > j:\n",
    "                if liste_doctype[j] == 'cv':\n",
    "                    local_dist = compute_eucl_dist(bow_idf_indeed[i], bow_idf_indeed[j])[0,0]\n",
    "                    ao_cv = AO_CV_Dist(liste_title[i], liste_title[j], local_dist)\n",
    "                    list_ao_cv.append(ao_cv)\n",
    "                    list_by_ao.append(ao_cv)\n",
    "        df = pd.DataFrame.from_records([s.to_dict() for s in list_by_ao])\n",
    "        list_df.append(df.sort_values(by='dist'))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    ao               cv  \\\n",
      "540  245_Description_mission_CDPT_3P2Iv2_Consultati...   CV_5_BROSS.txt   \n",
      "127  245_Description_mission_CDPT_3P2Iv2_Consultati...  FGICV TALAN.txt   \n",
      "370  245_Description_mission_CDPT_3P2Iv2_Consultati...    CV_5_DIAG.txt   \n",
      "533  245_Description_mission_CDPT_3P2Iv2_Consultati...  TJACV TALAN.txt   \n",
      "60   245_Description_mission_CDPT_3P2Iv2_Consultati...     CV_5_DOT.txt   \n",
      "304  245_Description_mission_CDPT_3P2Iv2_Consultati...         MARI.txt   \n",
      "209  245_Description_mission_CDPT_3P2Iv2_Consultati...  PVNCV TALAN.txt   \n",
      "27   245_Description_mission_CDPT_3P2Iv2_Consultati...     CV_MDM_1.txt   \n",
      "473  245_Description_mission_CDPT_3P2Iv2_Consultati...     CV_5_NOU.txt   \n",
      "146  245_Description_mission_CDPT_3P2Iv2_Consultati...     CV_5_JAW.txt   \n",
      "\n",
      "         dist  \n",
      "540  1.369347  \n",
      "127  1.411723  \n",
      "370  1.428189  \n",
      "533  1.435095  \n",
      "60   1.438485  \n",
      "304  1.468788  \n",
      "209  1.492266  \n",
      "27   1.494986  \n",
      "473  1.501688  \n",
      "146  1.504013  \n"
     ]
    }
   ],
   "source": [
    "print(list_df[17].iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:0, 343_ISIDA_1948_Prestation CDP_Concepteur_SPOT Outillage_2016.txt\n",
      "idx:1, 304_EB_SAS-24-02-2016.txt\n",
      "idx:2, Fiche Expression de Besoin- 909 - Developpeur Tableau Software.txt\n",
      "idx:3, 246_DSIRI_-_IVRC_-_MOE_et_intégrateur_BROKER_IV_Consultation_n°246.txt\n",
      "idx:4, Consultation_HCC_AST_3485-_Fiche_expression_de_besoin_-_Chef_de_Projet.txt\n",
      "idx:5, 388_ISIDA_1993_Prestation ASTR MOA Fonctionnel Maximo OPTISPOT-v0.4_1.txt\n",
      "idx:6, HCC_AST_288_Datastage_confirmé-_CSI_DEC.txt\n",
      "idx:7, Consultation - Mission Progiciels-v4.txt\n",
      "idx:8, Consultation_HCC_AST_3515_-_Gestionnaire_de_patrimoine_DEC_-_Accès_Réseau.txt\n",
      "idx:9, 259_ISIDA_1816_Consultation_Mission_ASTR_QMAQMSI_Décisionnel_Consultation n°259.txt\n",
      "idx:10, 256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONFIRME_MAXIMO_MOBILITE_Consultation n°256.txt\n",
      "idx:11, 481_Renouvellement_cd_STELSIA_32524-0000012774.txt\n",
      "idx:12, 390_Cahier des charges _Transilien_chargé d_étude stat.txt\n",
      "idx:13, Consultation_Portail__Stocks_ELAN_15-10-2015.txt\n",
      "idx:14, Consultation n°136 - LYON - SIRH - Concepteur fonctionnel confirmé Déclaratif.txt\n",
      "idx:15, CC_AST_3466_-_912_PAR_-_Chef_de_Projet_Big_Data.txt\n",
      "idx:16, SNCF-Consultation-STELSIA n°176 - mission progiciels DEC V4 - réponse technique EXL Group.txt\n",
      "idx:17, 245_Description_mission_CDPT_3P2Iv2_Consultation_n°245.txt\n",
      "idx:18, 259_ISIDA_1816_Consultation_Mission_ASTR_QMAQMSI_Décisionnel_Consultation_n°259.txt\n",
      "idx:19, 2015 Consultation conduite projet et accompagnement projet_V2.txt\n",
      "idx:20, 2015 Consultation-GCL-CMDB_Bornéo_V2.txt\n",
      "idx:21, 256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONFIRME_MAXIMO_MOBILITE_Consultation_n°256.txt\n",
      "idx:22, CDC SNCF - Consultation AST 2017 N°000012-profil 905 - Data scientific.txt\n",
      "idx:23, Consultation_HCC_AST_3484_-_Fiche_expression_de_besoin_-_Chef_de_Projet.txt\n",
      "idx:24, Consultation_HCC_AST_3486_-_Chef_de_Projet-_Besoin_Socle.txt\n",
      "idx:25, 596 DESCRIPTION DE MISSION.txt\n",
      "idx:26, Consultation_HCC_AST_3496_-_Consultant_confirmé_TM1.txt\n",
      "idx:27, Prestation ASTR MOA Fonctionnel Maximo-v0 4(Profil opérationnel).txt\n",
      "idx:28, HCC_AST_293-_AMOA_Gestionnaire_Réclamations-_SEO_MIS.txt\n",
      "idx:29, Fiche_expression_de_besoin_-_HCC_AST_271_Tableau_Software_20170908.txt\n",
      "idx:30, Prestation ASTR MOA Fonctionnel Maximo-v0 4(Profil étude).txt\n",
      "idx:31, 341_ISIDA_1940_EMI_SPOT_Outillage_Recrutement-Formateur-2015-2016_V2.0 (2).txt\n",
      "idx:32, Fiche_expression_de_besoin_-_912_-_Chef_de_Projet_Big_Data.txt\n",
      "idx:33, Fiche_expression_de_besoin_-_Consultant_Technique_Decisionnel_Flume,_Sqoop.txt\n",
      "idx:34, 481_Renouvellement cd STELSIA 32524-0000012774.txt\n",
      "idx:35, 327_ISIDA_1918_Prestation ASTR MOA Fonctionnel Maximo (1).txt\n",
      "idx:36, 329_CDC.txt\n",
      "idx:37, Prestation ASTR MOA Consultant fonct  erp  Maximo-v0 8-2015-9 (1).txt\n",
      "idx:38, Consultation_ELAN_.txt\n",
      "idx:39, Cahier_des_charges_forfait_expertise_technique_A_S_domaine_Décisionnel.txt\n",
      "idx:40, 304_EB SAS-24-02-2016.txt\n",
      "idx:41, 388_ISIDA_1993_Prestation_ASTR_MOA_Fonctionnel_Maximo_OPTISPOT-v0.4_1.txt\n",
      "idx:42, 384_Cahier_des_charges_prestataire_SIDV_2016_05_30.txt\n",
      "idx:43, 390_Cahier_des_charges__Transilien_chargé_d_étude_stat.txt\n",
      "idx:44, CC_AST_283_-_Consultation_Build_-_904PAR_-_Chef_de_projet_Décisionnel.txt\n",
      "idx:45, Consultation_HCC_AST_3467-_Chef_de_projet_Décisionnel.txt\n",
      "idx:46, HCC_AST_3468-_Chef_de_projet_Décisionnel.txt\n",
      "idx:47, Consultation n°196- PARIS - ISI - Pôle Données ARMEN- MOA1- 20151019_V2 (2).txt\n",
      "idx:48, CC_AST_3489_-_Besoin_Socle_-_912_PAR_-_Chef_de_Projet_Exploitation.txt\n",
      "idx:49, 384_Cahier des charges prestataire SIDV 2016 05 30.txt\n",
      "idx:50, Consultation N° 200 CC AST Informatique - profils 502 ou 902 province.txt\n",
      "idx:51, Expression de besoin AST Informatique_PMO.txt\n",
      "idx:52, GMAO_SPOT_Outillage_CdC_-_Métier_Fiche_de_Poste_TEMMAR_Cahier_des_charges_R3_.txt\n",
      "idx:53, CC_AST_290_-_909_PAR_-_Concepteur_-_développeur_Big_data.txt\n",
      "idx:54, 343_ISIDA_1948_Prestation_CDP_Concepteur_SPOT_Outillage_2016.txt\n",
      "idx:55, AO_Consultation_Build_-_909_-_Tableau_Software.txt\n",
      "idx:56, Consultation_HCC_AST_310_-_Contract_Manager_Centre_de_Service.txt\n",
      "idx:57, 262_ISIDA_1813_Consultation_Mission_ASTR_MOA_Consultant_fonct_erp_junior_Maximo_Consultation_n°262.txt\n",
      "idx:58, Mission_AMO_Planification_PSNext.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_df)):\n",
    "    print(\"idx:{}, {}\".format(i,list_df[i].iloc[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 1029)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = bow_idf_indeed\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   8.93059365e-01,   9.58214626e-01, ...,\n",
       "          8.90518063e-01,   9.24013152e-01,   1.00000000e+00],\n",
       "       [  8.93059365e-01,  -4.44089210e-16,   9.47156268e-01, ...,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00],\n",
       "       [  9.58214626e-01,   9.47156268e-01,  -2.22044605e-16, ...,\n",
       "          9.61752124e-01,   9.70149385e-01,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  8.90518063e-01,   1.00000000e+00,   9.61752124e-01, ...,\n",
       "          0.00000000e+00,   8.92587903e-02,   1.00000000e+00],\n",
       "       [  9.24013152e-01,   1.00000000e+00,   9.70149385e-01, ...,\n",
       "          8.92587903e-02,   1.11022302e-16,   9.77536041e-01],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "          1.00000000e+00,   9.77536041e-01,   0.00000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = 1 - cosine_similarity(matrix)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as ssd\n",
    "from scipy import cluster\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# convert the redundant n*n square matrix form into a condensed nC2 array\n",
    "dist2=np.array(dist)\n",
    "dist2[dist2 < 0] = 0\n",
    "np.fill_diagonal(dist2, 0)\n",
    "X = ssd.squareform(dist2) # distArray[{n choose 2}-{n-i choose 2} + (j-i-1)] is the distance between points i and j\n",
    "#Z = cluster.hierarchy.linkage(X, method='ward', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36585,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Suppression des doublons **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ajout une étape pour supprimer les doublons\n",
    "buffer = pd.DataFrame(data=bow_idf_indeed.toarray())\n",
    "buffer.drop_duplicates(inplace=True)\n",
    "bow_idf_indeed = buffer.values\n",
    "bow_idf_indeed = shuffle(bow_idf_indeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Clustering **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.6 ms, sys: 35.6 ms, total: 116 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 6\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, n_jobs=-1)\n",
    "\n",
    "%time km.fit(matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "#clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, I create a dictionary of titles, cv body, the cluster assignment\n",
    "cv_titles = [cv.filename for cv in dico_global.values()]\n",
    "cv_bodies = [cv.cv for cv in dico_global.values()]\n",
    "cv_types = [cv.doc_type for cv in dico_global.values()]\n",
    "\n",
    "cvs = { 'title': cv_titles, 'cv': cv_bodies, 'cluster': clusters, 'doc_type':cv_types }\n",
    "#cvs = { 'title': cv_titles,  'cluster': clusters }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "271\n",
      "271\n"
     ]
    }
   ],
   "source": [
    "print(len(cv_titles))\n",
    "print(len(cv_bodies))\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(cvs, index = [clusters] , columns = ['title', 'cluster', 'doc_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADD.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGNCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIT.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  cluster doc_type\n",
       "2          ACH.txt        2       cv\n",
       "4          ADD.txt        4       cv\n",
       "1  ADECV TALAN.txt        1       cv\n",
       "1  AGNCV TALAN.txt        1       cv\n",
       "4          AIT.txt        4       cv"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    84\n",
       "2    82\n",
       "1    35\n",
       "0    30\n",
       "5    23\n",
       "3    17\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['cluster'].value_counts() #number of cv per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_BD_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_10.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_11.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_12.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_15.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_4.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_5.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_6.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_7.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_8.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_DS_9.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_ETL_13.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_ETL_8.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_TalanSolutions_AJOL.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_TalanSolutions_FVAL.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_TalanSolutions_JCLE.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_TalanSolutions_JLAG.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_TalanSolutions_MDEB.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV ABEN.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV AFAB.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV AGIR.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV CLEV.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV COUA.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV EGTA.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV IARK.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV MPRO.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talan - CV RDJE.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDC SNCF - Consultation AST 2017 N°000012-prof...</td>\n",
       "      <td>0</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  cluster doc_type\n",
       "0                                        CV_BD_2.txt        0       cv\n",
       "0                                        CV_DS_1.txt        0       cv\n",
       "0                                       CV_DS_10.txt        0       cv\n",
       "0                                       CV_DS_11.txt        0       cv\n",
       "0                                       CV_DS_12.txt        0       cv\n",
       "0                                       CV_DS_15.txt        0       cv\n",
       "0                                        CV_DS_2.txt        0       cv\n",
       "0                                        CV_DS_4.txt        0       cv\n",
       "0                                        CV_DS_5.txt        0       cv\n",
       "0                                        CV_DS_6.txt        0       cv\n",
       "0                                        CV_DS_7.txt        0       cv\n",
       "0                                        CV_DS_8.txt        0       cv\n",
       "0                                        CV_DS_9.txt        0       cv\n",
       "0                                      CV_ETL_13.txt        0       cv\n",
       "0                                       CV_ETL_8.txt        0       cv\n",
       "0                         CV_TalanSolutions_AJOL.txt        0       cv\n",
       "0                         CV_TalanSolutions_FVAL.txt        0       cv\n",
       "0                         CV_TalanSolutions_JCLE.txt        0       cv\n",
       "0                         CV_TalanSolutions_JLAG.txt        0       cv\n",
       "0                         CV_TalanSolutions_MDEB.txt        0       cv\n",
       "0                                Talan - CV ABEN.txt        0       cv\n",
       "0                                Talan - CV AFAB.txt        0       cv\n",
       "0                                Talan - CV AGIR.txt        0       cv\n",
       "0                                Talan - CV CLEV.txt        0       cv\n",
       "0                                Talan - CV COUA.txt        0       cv\n",
       "0                                Talan - CV EGTA.txt        0       cv\n",
       "0                                Talan - CV IARK.txt        0       cv\n",
       "0                                Talan - CV MPRO.txt        0       cv\n",
       "0                                Talan - CV RDJE.txt        0       cv\n",
       "0  CDC SNCF - Consultation AST 2017 N°000012-prof...        0       ao"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGNCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APHCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APICV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPUCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAPCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLSCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELCCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCHCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HABCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDUCV Talan.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HGZCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HHACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HMECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBNCV Talan.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JCOCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJUCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KMACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNTCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGUCV Talan.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NSACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PVNCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RHICV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPICV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFRCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TJACV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VLOCV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WBECV TALAN.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  cluster doc_type\n",
       "1  ADECV TALAN.txt        1       cv\n",
       "1  AGNCV TALAN.txt        1       cv\n",
       "1  AKACV TALAN.txt        1       cv\n",
       "1  APHCV TALAN.txt        1       cv\n",
       "1  APICV TALAN.txt        1       cv\n",
       "1  BLACV TALAN.txt        1       cv\n",
       "1  BPUCV TALAN.txt        1       cv\n",
       "1  CAPCV TALAN.txt        1       cv\n",
       "1  CLSCV TALAN.txt        1       cv\n",
       "1  ELCCV TALAN.txt        1       cv\n",
       "1  GCHCV TALAN.txt        1       cv\n",
       "1  GLACV TALAN.txt        1       cv\n",
       "1  HABCV TALAN.txt        1       cv\n",
       "1  HDUCV Talan.txt        1       cv\n",
       "1  HGZCV TALAN.txt        1       cv\n",
       "1  HHACV TALAN.txt        1       cv\n",
       "1  HMECV TALAN.txt        1       cv\n",
       "1  IBNCV Talan.txt        1       cv\n",
       "1  JBECV TALAN.txt        1       cv\n",
       "1  JCOCV TALAN.txt        1       cv\n",
       "1  JJUCV TALAN.txt        1       cv\n",
       "1  KMACV TALAN.txt        1       cv\n",
       "1  LNTCV TALAN.txt        1       cv\n",
       "1  NGUCV Talan.txt        1       cv\n",
       "1  NSACV TALAN.txt        1       cv\n",
       "1  PVNCV TALAN.txt        1       cv\n",
       "1  RHICV TALAN.txt        1       cv\n",
       "1  RPICV TALAN.txt        1       cv\n",
       "1  SBECV TALAN.txt        1       cv\n",
       "1  SDECV TALAN.txt        1       cv\n",
       "1  SFRCV TALAN.txt        1       cv\n",
       "1  SMACV TALAN.txt        1       cv\n",
       "1  TJACV TALAN.txt        1       cv\n",
       "1  VLOCV TALAN.txt        1       cv\n",
       "1  WBECV TALAN.txt        1       cv"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENA.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGHCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BKICV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLPCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOA.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOUT.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUDU.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEK.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHER.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COUL.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV TalanSolutions CPOU.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV TalanSolutions DJS.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV TalanSolutions JPL.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV-TalanSolutions_VGA.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_BD_5.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_MDM_2.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DELCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DESNO.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBACV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EJI_CV_20171201.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELMAA.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXL Group_CV EXL_ECH.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXL Group_CV EXL_NIT 2017.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGECV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGICV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FQUCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRANC.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAJCV ALJANE.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGACV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGUE.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORICV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OUEG.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIERM.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAM.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAVA.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROUS.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SADO.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SALM.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBOU.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBRCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDZCV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPECV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UZUN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VCACV TALAN.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WANK.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015 Consultation conduite projet et accompagn...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015 Consultation-GCL-CMDB_Bornéo_V2.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259_ISIDA_1816_Consultation_Mission_ASTR_QMAQM...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304_EB SAS-24-02-2016.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329_CDC.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384_Cahier des charges prestataire SIDV 2016 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cahier_des_charges_forfait_expertise_technique...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consultation N° 200 CC AST Informatique - prof...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consultation_HCC_AST_310_-_Contract_Manager_Ce...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expression de besoin AST Informatique_PMO.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mission_AMO_Planification_PSNext.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNCF-Consultation-STELSIA n°176 - mission prog...</td>\n",
       "      <td>2</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  cluster doc_type\n",
       "2                                             ACH.txt        2       cv\n",
       "2                                             BAR.txt        2       cv\n",
       "2                                            BENA.txt        2       cv\n",
       "2                                     BGHCV TALAN.txt        2       cv\n",
       "2                                     BKICV TALAN.txt        2       cv\n",
       "2                                     BLPCV TALAN.txt        2       cv\n",
       "2                                             BOA.txt        2       cv\n",
       "2                                            BOUT.txt        2       cv\n",
       "2                                            BUDU.txt        2       cv\n",
       "2                                            CHEK.txt        2       cv\n",
       "2                                            CHER.txt        2       cv\n",
       "2                                            COUL.txt        2       cv\n",
       "2                          CV TalanSolutions CPOU.txt        2       cv\n",
       "2                           CV TalanSolutions DJS.txt        2       cv\n",
       "2                           CV TalanSolutions JPL.txt        2       cv\n",
       "2                           CV-TalanSolutions_VGA.txt        2       cv\n",
       "2                                         CV_BD_5.txt        2       cv\n",
       "2                                        CV_MDM_2.txt        2       cv\n",
       "2                                     DELCV TALAN.txt        2       cv\n",
       "2                                           DESNO.txt        2       cv\n",
       "2                                     EBACV TALAN.txt        2       cv\n",
       "2                                 EJI_CV_20171201.txt        2       cv\n",
       "2                                           ELMAA.txt        2       cv\n",
       "2                            EXL Group_CV EXL_ECH.txt        2       cv\n",
       "2                       EXL Group_CV EXL_NIT 2017.txt        2       cv\n",
       "2                                     FGECV TALAN.txt        2       cv\n",
       "2                                     FGICV TALAN.txt        2       cv\n",
       "2                                            file.txt        2       cv\n",
       "2                                     FQUCV TALAN.txt        2       cv\n",
       "2                                           FRANC.txt        2       cv\n",
       "..                                                ...      ...      ...\n",
       "2                                    NAJCV ALJANE.txt        2       cv\n",
       "2                                     NGACV TALAN.txt        2       cv\n",
       "2                                            NGUE.txt        2       cv\n",
       "2                                     ORICV TALAN.txt        2       cv\n",
       "2                                            OUEG.txt        2       cv\n",
       "2                                           PIERM.txt        2       cv\n",
       "2                                            PLAM.txt        2       cv\n",
       "2                                            RAVA.txt        2       cv\n",
       "2                                            ROUS.txt        2       cv\n",
       "2                                            SADO.txt        2       cv\n",
       "2                                            SALM.txt        2       cv\n",
       "2                                            SBOU.txt        2       cv\n",
       "2                                     SBRCV TALAN.txt        2       cv\n",
       "2                                     SDZCV TALAN.txt        2       cv\n",
       "2                                     SPECV TALAN.txt        2       cv\n",
       "2                                            UZUN.txt        2       cv\n",
       "2                                     VCACV TALAN.txt        2       cv\n",
       "2                                            WANK.txt        2       cv\n",
       "2   2015 Consultation conduite projet et accompagn...        2       ao\n",
       "2           2015 Consultation-GCL-CMDB_Bornéo_V2.txt        2       ao\n",
       "2   259_ISIDA_1816_Consultation_Mission_ASTR_QMAQM...        2       ao\n",
       "2                           304_EB SAS-24-02-2016.txt        2       ao\n",
       "2                                         329_CDC.txt        2       ao\n",
       "2   384_Cahier des charges prestataire SIDV 2016 0...        2       ao\n",
       "2   Cahier_des_charges_forfait_expertise_technique...        2       ao\n",
       "2   Consultation N° 200 CC AST Informatique - prof...        2       ao\n",
       "2   Consultation_HCC_AST_310_-_Contract_Manager_Ce...        2       ao\n",
       "2       Expression de besoin AST Informatique_PMO.txt        2       ao\n",
       "2                Mission_AMO_Planification_PSNext.txt        2       ao\n",
       "2   SNCF-Consultation-STELSIA n°176 - mission prog...        2       ao\n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AO_Consultation_Build_-_909_-_Tableau_Software...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC_AST_283_-_Consultation_Build_-_904PAR_-_Che...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC_AST_290_-_909_PAR_-_Concepteur_-_développe...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC_AST_3466_-_912_PAR_-_Chef_de_Projet_Big_Dat...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC_AST_3489_-_Besoin_Socle_-_912_PAR_-_Chef_de...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3467-_Chef_de_projet_Déc...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3484_-_Fiche_expression_d...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3485-_Fiche_expression_de...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3486_-_Chef_de_Projet-_Be...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3496_-_Consultant_confirm...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultation_HCC_AST_3515_-_Gestionnaire_de_pa...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiche Expression de Besoin- 909 - Developpeur ...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiche_expression_de_besoin_-_912_-_Chef_de_Pro...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiche_expression_de_besoin_-_Consultant_Techni...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiche_expression_de_besoin_-_HCC_AST_271_Table...</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCC_AST_288_Datastage_confirmé-_CSI_DEC.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCC_AST_3468-_Chef_de_projet_Décisionnel.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  cluster doc_type\n",
       "3  AO_Consultation_Build_-_909_-_Tableau_Software...        3       ao\n",
       "3  CC_AST_283_-_Consultation_Build_-_904PAR_-_Che...        3       ao\n",
       "3  CC_AST_290_-_909_PAR_-_Concepteur_-_développe...        3       ao\n",
       "3  CC_AST_3466_-_912_PAR_-_Chef_de_Projet_Big_Dat...        3       ao\n",
       "3  CC_AST_3489_-_Besoin_Socle_-_912_PAR_-_Chef_de...        3       ao\n",
       "3  Consultation_HCC_AST_3467-_Chef_de_projet_Déc...        3       ao\n",
       "3  Consultation_HCC_AST_3484_-_Fiche_expression_d...        3       ao\n",
       "3  Consultation_HCC_AST_3485-_Fiche_expression_de...        3       ao\n",
       "3  Consultation_HCC_AST_3486_-_Chef_de_Projet-_Be...        3       ao\n",
       "3  Consultation_HCC_AST_3496_-_Consultant_confirm...        3       ao\n",
       "3  Consultation_HCC_AST_3515_-_Gestionnaire_de_pa...        3       ao\n",
       "3  Fiche Expression de Besoin- 909 - Developpeur ...        3       ao\n",
       "3  Fiche_expression_de_besoin_-_912_-_Chef_de_Pro...        3       ao\n",
       "3  Fiche_expression_de_besoin_-_Consultant_Techni...        3       ao\n",
       "3  Fiche_expression_de_besoin_-_HCC_AST_271_Table...        3       ao\n",
       "3       HCC_AST_288_Datastage_confirmé-_CSI_DEC.txt        3       ao\n",
       "3      HCC_AST_3468-_Chef_de_projet_Décisionnel.txt        3       ao"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADD.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIT.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AME.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDA.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOUD.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV - TalanSolutions - AGU.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV - TalanSolutions - CJD.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV - TalanSolutions - DPE.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV _TalanSolutions_AAG AOUT 2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV AAU_TS2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV collaborateur_IZA.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV collaborateur_TS2017_JAU_201710.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV HME_TS2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV LKH - TALAN-2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV NPO.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions ABAH.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions ACH.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions AIQ.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions AMO.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions ANDO.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions ATR.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions BILI.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions DJE.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions FGA.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions ICHO.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions JBOU.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions LVE.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions MCH.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions MCHI.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV TalanSolutions MSME.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_3.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_4.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_5.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_6.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_7.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_ETL_9.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_1.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_10.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_3.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_4.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_5.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_6.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_7.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_8.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_MDM_9.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_TalanSolutions_WZHA.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV_YWA_TS2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DELH.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDIC.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXL Group_CV EXL AFI.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGU_CV Talan.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDD.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAH.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KADI.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OUAA.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talan - CV ALJN.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talan - CV SBES.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talan - CV SSOW.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talans solutions_CV Talans_MTR juillet 2017.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZEKR.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  cluster doc_type\n",
       "4                                           ADD.txt        4       cv\n",
       "4                                           AIT.txt        4       cv\n",
       "4                                           AME.txt        4       cv\n",
       "4                                          ANDA.txt        4       cv\n",
       "4                                          BOUD.txt        4       cv\n",
       "4                     CV - TalanSolutions - AGU.txt        4       cv\n",
       "4                     CV - TalanSolutions - CJD.txt        4       cv\n",
       "4                     CV - TalanSolutions - DPE.txt        4       cv\n",
       "4              CV _TalanSolutions_AAG AOUT 2017.txt        4       cv\n",
       "4                                 CV AAU_TS2017.txt        4       cv\n",
       "4                          CV collaborateur_IZA.txt        4       cv\n",
       "4            CV collaborateur_TS2017_JAU_201710.txt        4       cv\n",
       "4                                 CV HME_TS2017.txt        4       cv\n",
       "4                           CV LKH - TALAN-2017.txt        4       cv\n",
       "4                                        CV NPO.txt        4       cv\n",
       "4                        CV TalanSolutions ABAH.txt        4       cv\n",
       "4                         CV TalanSolutions ACH.txt        4       cv\n",
       "4                         CV TalanSolutions AIQ.txt        4       cv\n",
       "4                         CV TalanSolutions AMO.txt        4       cv\n",
       "4                        CV TalanSolutions ANDO.txt        4       cv\n",
       "4                         CV TalanSolutions ATR.txt        4       cv\n",
       "4                        CV TalanSolutions BILI.txt        4       cv\n",
       "4                         CV TalanSolutions DJE.txt        4       cv\n",
       "4                         CV TalanSolutions FGA.txt        4       cv\n",
       "4                        CV TalanSolutions ICHO.txt        4       cv\n",
       "4                        CV TalanSolutions JBOU.txt        4       cv\n",
       "4                         CV TalanSolutions LVE.txt        4       cv\n",
       "4                         CV TalanSolutions MCH.txt        4       cv\n",
       "4                        CV TalanSolutions MCHI.txt        4       cv\n",
       "4                        CV TalanSolutions MSME.txt        4       cv\n",
       "..                                              ...      ...      ...\n",
       "4                                      CV_ETL_3.txt        4       cv\n",
       "4                                      CV_ETL_4.txt        4       cv\n",
       "4                                      CV_ETL_5.txt        4       cv\n",
       "4                                      CV_ETL_6.txt        4       cv\n",
       "4                                      CV_ETL_7.txt        4       cv\n",
       "4                                      CV_ETL_9.txt        4       cv\n",
       "4                                      CV_MDM_1.txt        4       cv\n",
       "4                                     CV_MDM_10.txt        4       cv\n",
       "4                                      CV_MDM_3.txt        4       cv\n",
       "4                                      CV_MDM_4.txt        4       cv\n",
       "4                                      CV_MDM_5.txt        4       cv\n",
       "4                                      CV_MDM_6.txt        4       cv\n",
       "4                                      CV_MDM_7.txt        4       cv\n",
       "4                                      CV_MDM_8.txt        4       cv\n",
       "4                                      CV_MDM_9.txt        4       cv\n",
       "4                        CV_TalanSolutions_WZHA.txt        4       cv\n",
       "4                                 CV_YWA_TS2017.txt        4       cv\n",
       "4                                          DELH.txt        4       cv\n",
       "4                                          EDIC.txt        4       cv\n",
       "4                          EXL Group_CV EXL AFI.txt        4       cv\n",
       "4                                  FGU_CV Talan.txt        4       cv\n",
       "4                                           IDD.txt        4       cv\n",
       "4                                          IMAH.txt        4       cv\n",
       "4                                          KADI.txt        4       cv\n",
       "4                                          OUAA.txt        4       cv\n",
       "4                               Talan - CV ALJN.txt        4       cv\n",
       "4                               Talan - CV SBES.txt        4       cv\n",
       "4                               Talan - CV SSOW.txt        4       cv\n",
       "4   Talans solutions_CV Talans_MTR juillet 2017.txt        4       cv\n",
       "4                                          ZEKR.txt        4       cv\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>doc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>245_Description_mission_CDPT_3P2Iv2_Consultati...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>246_DSIRI_-_IVRC_-_MOE_et_intégrateur_BROKER_...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONF...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>262_ISIDA_1813_Consultation_Mission_ASTR_MOA_C...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>327_ISIDA_1918_Prestation ASTR MOA Fonctionnel...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>341_ISIDA_1940_EMI_SPOT_Outillage_Recrutement-...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>343_ISIDA_1948_Prestation CDP_Concepteur_SPOT ...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>388_ISIDA_1993_Prestation ASTR MOA Fonctionnel...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>390_Cahier des charges _Transilien_chargé d_e...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>481_Renouvellement cd STELSIA 32524-0000012774...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>596 DESCRIPTION DE MISSION.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultation - Mission Progiciels-v4.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultation n°136 - LYON - SIRH - Concepteur ...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultation n°196- PARIS - ISI - Pôle Donné...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultation_ELAN_.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consultation_Portail__Stocks_ELAN_15-10-2015.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GMAO_SPOT_Outillage_CdC_-_Métier_Fiche_de_Pos...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HCC_AST_293-_AMOA_Gestionnaire_Réclamations-_...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prestation ASTR MOA Consultant fonct  erp  Max...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prestation ASTR MOA Consultant fonct  erp  Max...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prestation ASTR MOA Consultant fonct  erp  Max...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prestation ASTR MOA Fonctionnel Maximo-v0 4(Pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prestation ASTR MOA Fonctionnel Maximo-v0 4(Pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>ao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  cluster doc_type\n",
       "5  245_Description_mission_CDPT_3P2Iv2_Consultati...        5       ao\n",
       "5  246_DSIRI_-_IVRC_-_MOE_et_intégrateur_BROKER_...        5       ao\n",
       "5  256_ISIDA_1810_CONSULTANT_FONCTIONNEL_ERP_CONF...        5       ao\n",
       "5  262_ISIDA_1813_Consultation_Mission_ASTR_MOA_C...        5       ao\n",
       "5  327_ISIDA_1918_Prestation ASTR MOA Fonctionnel...        5       ao\n",
       "5  341_ISIDA_1940_EMI_SPOT_Outillage_Recrutement-...        5       ao\n",
       "5  343_ISIDA_1948_Prestation CDP_Concepteur_SPOT ...        5       ao\n",
       "5  388_ISIDA_1993_Prestation ASTR MOA Fonctionnel...        5       ao\n",
       "5  390_Cahier des charges _Transilien_chargé d_e...        5       ao\n",
       "5  481_Renouvellement cd STELSIA 32524-0000012774...        5       ao\n",
       "5                     596 DESCRIPTION DE MISSION.txt        5       ao\n",
       "5           Consultation - Mission Progiciels-v4.txt        5       ao\n",
       "5  Consultation n°136 - LYON - SIRH - Concepteur ...        5       ao\n",
       "5  Consultation n°196- PARIS - ISI - Pôle Donné...        5       ao\n",
       "5                             Consultation_ELAN_.txt        5       ao\n",
       "5   Consultation_Portail__Stocks_ELAN_15-10-2015.txt        5       ao\n",
       "5  GMAO_SPOT_Outillage_CdC_-_Métier_Fiche_de_Pos...        5       ao\n",
       "5  HCC_AST_293-_AMOA_Gestionnaire_Réclamations-_...        5       ao\n",
       "5  Prestation ASTR MOA Consultant fonct  erp  Max...        5       ao\n",
       "5  Prestation ASTR MOA Consultant fonct  erp  Max...        5       ao\n",
       "5  Prestation ASTR MOA Consultant fonct  erp  Max...        5       ao\n",
       "5  Prestation ASTR MOA Fonctionnel Maximo-v0 4(Pr...        5       ao\n",
       "5  Prestation ASTR MOA Fonctionnel Maximo-v0 4(Pr...        5       ao"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame ['cluster']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: b'big',"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [['data', 'science']] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-340ce0d3f7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#replace 6 with n words per cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvocab_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvocab_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcluster_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot index with multidimensional key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_validate_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                 raise KeyError(\"None of [%s] are in the [%s]\" %\n\u001b[0;32m-> 1418\u001b[0;31m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [['data', 'science']] are in the [index]\""
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "cluster_names = {}\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    txt = \"\"\n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        txt = txt + vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0] + \", \"\n",
    "        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    cluster_names[i] = txt\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "    print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in frame.ix[i]['title'].values.tolist():\n",
    "        print('     %s;' % title, end='')\n",
    "        #print('\\n')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os  # for os.path.basename\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()\n",
    "\n",
    "# convert two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1, n_jobs=-1)\n",
    "\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
    "\n",
    "#set up cluster names using a dict\n",
    "#cluster_names = {0: 'informatiques, donnee, gestion, formation, developpement, projet', \n",
    "#                 1: 'Police, killed, murders', \n",
    "#                 2: 'Father, New York, brothers', \n",
    "#                 3: 'Dance, singing, love', \n",
    "#                 4: 'Killed, soldiers, captain'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some ipython magic to show the matplotlib plots inline\n",
    "%matplotlib inline \n",
    "\n",
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters))#, title=cv_titles)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "##add label in x,y position with the label as the film title\n",
    "#for i in range(len(df)):\n",
    "#    ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8)  \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=cv_titles)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "#define custom css to format the font and to remove the axis labeling\n",
    "css = \"\"\"\n",
    "text.mpld3-text, div.mpld3-tooltip {\n",
    "  font-family:Arial, Helvetica, sans-serif;\n",
    "}\n",
    "\n",
    "g.mpld3-xaxis, g.mpld3-yaxis {\n",
    "display: none; }\n",
    "\n",
    "svg.mpld3-figure {\n",
    "margin-left: -50px;}\n",
    "\"\"\"\n",
    "\n",
    "# Plot \n",
    "fig, ax = plt.subplots(figsize=(14,6)) #set plot size\n",
    "#ax.margins(0.03) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    points = ax.plot(group.x, group.y, marker='o', linestyle='', ms=18, \n",
    "                     label=cluster_names[name], mec='none', \n",
    "                     color=cluster_colors[name])\n",
    "    ax.set_aspect('auto')\n",
    "    labels = [i for i in group.title]\n",
    "    \n",
    "    #set tooltip using points, labels and the already defined 'css'\n",
    "    tooltip = mpld3.plugins.PointHTMLTooltip(points[0], labels,\n",
    "                                       voffset=10, hoffset=10, css=css)\n",
    "    #connect tooltip to fig\n",
    "    mpld3.plugins.connect(fig, tooltip, TopToolbar())    \n",
    "    \n",
    "    #set tick marks as blank\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    \n",
    "    #set axis as blank\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "ax.legend(numpoints=1) #show legend with only one dot\n",
    "\n",
    "mpld3.display() #show the plot\n",
    "\n",
    "#uncomment the below to export to html\n",
    "#html = mpld3.fig_to_html(fig)\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vect.vocabulary_\n",
    "vocab_liste_pca_indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trop de mots !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster centers visualization\n",
    "def get_kmeans_cluster_words_lsa(bow_idf,lsa_number,cluster_number,word_number,vocab_frame,vocab_liste):\n",
    "    \n",
    "    #implement LSA\n",
    "    svd = TruncatedSVD(lsa_number)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    bow_idf_reduced_lsa = lsa.fit_transform(bow_idf)\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "    \n",
    "    #clustering using kmeans\n",
    "    n_class = cluster_number\n",
    "    km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "    km.fit(bow_idf_reduced_lsa)\n",
    "\n",
    "    #cluster centroid lsa\n",
    "    cluster_centroids_lsa = km.cluster_centers_\n",
    "    liste_cluster_word=[]\n",
    "    \n",
    "    #via l'opération inveserse je rebascule les centroids dans l'espace des mots \n",
    "    original_space_centroids = svd.inverse_transform(cluster_centroids_lsa)\n",
    "    #ordre decroissant pour chaque cluster les indices des mots à plus forte corrélation\n",
    "    idx_ordered_centroids = np.argsort(original_space_centroids,axis=1)[:,::-1] \n",
    "    \n",
    "    for i in range(0, cluster_centroids_lsa.shape[0]): #nombre de clusters\n",
    "        text = list()\n",
    "        for j in range(0, word_number): #nombre de mots\n",
    "            mylist = vocab_liste[idx_ordered_centroids[i,j]].split() # on fait ça car on n utilise pas forcément des unigrammes\n",
    "            #print(mylist)\n",
    "            # si stem : \n",
    "            #text.append([vocab_frame.loc[el].values.tolist()[0][0] for el in mylist])\n",
    "            # si pas stem : \n",
    "            text.append(mylist)\n",
    "        print((text))\n",
    "        liste_cluster_word.append(text)\n",
    "        \n",
    "    return bow_idf_reduced_lsa, liste_cluster_word, km.labels_, cluster_centroids_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibilité de rebasculer dans l'espace des mots\n",
    "Puis on ordonne de manière décroissante les vecteurs de coefficients pour chaque cluster\n",
    "On récupère les indices des mots aux plus grands coefficients pour chaque cluster\n",
    "Via l'attribut vocabulaire du tf_idf vec on affiche les mots ayant les plus grand coeff pour chaque cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_idf_reduced_lsa_indeed, liste_cluster_word_lsa_indeed, labels_lsa_indeed, cluster_centroids_lsa_indeed = \\\n",
    "get_kmeans_cluster_words_lsa(bow_idf_indeed,150,5,6,vocab_frame_indeed,vocab_liste_pca_indeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NMF X KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on part d'un bag of words tf-idf\n",
    "tf_vect_2 = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "\n",
    "bow_idf_2 = tf_vect_2.fit_transform(liste_cv_indeed_no_stop)\n",
    "\n",
    "vocab_liste_nmf_indeed = tf_vect_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster centers visualization\n",
    "def get_kmens_cluster_words_nmf(bow_idf,nmf_number,cluster_number,word_number,vocab_frame,vocab_liste):\n",
    "    #implement NMF\n",
    "    print(\"Fitting the NMF model on with n_samples = \"+str(bow_idf.shape[0])+ \" and n_features = \"+str(bow_idf.shape[1]))\n",
    "    nmf = NMF(n_components=nmf_number).fit(bow_idf) \n",
    "    \n",
    "    liste_topic = []\n",
    "    for topic_idx, topic in enumerate(nmf.components_):\n",
    "        #explain each topix with the words with the strongest coeff\n",
    "        liste_topic.append(\" \".join([vocab_frame.loc[vocab_liste[i]].values.tolist()[0][0]  for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    \n",
    "    #get text matrix in nmf topic space\n",
    "    bow_idf_reduced_nmf = nmf.fit_transform(bow_idf)\n",
    "    bow_idf_reduced_nmf_normalized = l2_norm.fit_transform(bow_idf_reduced_nmf) #l2 observation normalization\n",
    "    \n",
    "    #clustering using kmeans\n",
    "    n_class = cluster_number\n",
    "    km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "    km.fit(bow_idf_reduced_nmf_normalized)\n",
    "\n",
    "    #cluster centroid nmf\n",
    "    cluster_centroids_nmf = km.cluster_centers_\n",
    "    \n",
    "    liste_cluster_word=[]\n",
    "    \n",
    "    #via l'opération inveserse je rebascule les centroids dans l'espace des mots !!!\n",
    "    original_space_centroids = nmf.inverse_transform(cluster_centroids_nmf)\n",
    "    #ordre decroissant pour chaque cluster les indices des mots à plus forte corrélation\n",
    "    idx_ordered_centroids = np.argsort(original_space_centroids,axis=1)[:,::-1] \n",
    "    \n",
    "    for i in range(0,cluster_centroids_nmf.shape[0]): #nombre de clusters\n",
    "        text=\"\"\n",
    "        for j in range(0,word_number): #nombre de mots\n",
    "            text+= vocab_frame.loc[vocab_liste[idx_ordered_centroids[i,j]]].values.tolist()[0][0]+ \" \"\n",
    "        liste_cluster_word.append(text)\n",
    "        \n",
    "    return bow_idf_reduced_nmf_normalized, liste_topic, liste_cluster_word, km.labels_, cluster_centroids_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow_idf_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d696dfedb6b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbow_idf_reduced_nmf_indeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_cluster_nmf_indeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_nmf_indeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_centroid_nmf_indeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kmens_cluster_words_nmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_idf_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_frame_indeed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_liste_nmf_indeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow_idf_2' is not defined"
     ]
    }
   ],
   "source": [
    "bow_idf_reduced_nmf_indeed, liste_topic, liste_cluster_nmf_indeed, labels_nmf_indeed, cluster_centroid_nmf_indeed = get_kmens_cluster_words_nmf(bow_idf_2,150,5,6,vocab_frame_indeed,vocab_liste_nmf_indeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liste_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f3ce7d1aa0a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliste_topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'liste_topic' is not defined"
     ]
    }
   ],
   "source": [
    "liste_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liste_cluster_nmf_indeed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-bfa0f867c328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliste_cluster_nmf_indeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'liste_cluster_nmf_indeed' is not defined"
     ]
    }
   ],
   "source": [
    "liste_cluster_nmf_indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDEED SEMI-SUPERVISED AUTOMATIC LABELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liste_cv_indeed_no_stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-20067166f83d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get observations cluster distrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mliste_cv_indeed_no_stop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#all textes sans doublons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_idf_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_idf_reduced_lsa_indeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_cluster_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_lsa_indeed\u001b[0m \u001b[0;31m#labels correspondants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-20067166f83d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get observations cluster distrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mliste_cv_indeed_no_stop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#all textes sans doublons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_idf_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_idf_reduced_lsa_indeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_cluster_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_lsa_indeed\u001b[0m \u001b[0;31m#labels correspondants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liste_cv_indeed_no_stop' is not defined"
     ]
    }
   ],
   "source": [
    "#get observations cluster distrib\n",
    "X_texts = [liste_cv_indeed_no_stop[i] for i in buffer.index] #all textes sans doublons\n",
    "X_idf_reduced = bow_idf_reduced_lsa_indeed\n",
    "y_cluster_pca = labels_lsa_indeed #labels correspondants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_res = dict()\n",
    "for i in np.unique(y_cluster_pca):\n",
    "    dict_res[\"label_\"+str(i)] = len(np.where(y_cluster_pca == i)[0])\n",
    "dict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idéé : Prenons dans un premiers temps les x observations les plus proche du cluster centroid au sens de la cosine similarity et attribuons leur le label du cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_closest_points(nb_points,X,labels,cluster_centroids):\n",
    "    distance_idx = np.zeros((len(np.unique(labels)),nb_points))\n",
    "    for i in np.unique(labels):\n",
    "        buffer_2 = euclidean_distances(X,np.transpose(cluster_centroids[i].reshape(-1,1)))\n",
    "        distance_idx[i] = np.argsort(buffer_2,axis=0)[:nb_points].reshape(-1,)\n",
    "    return distance_idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_per_cluster = get_idx_closest_points(12,X_idf_reduced,y_cluster_pca,cluster_centroids_lsa_indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cluster_pca[1002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build first train set with these labelled data from the clustering + lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_semi_supervised_draft(idx,X,labels):\n",
    "    \"\"\"Method for the manual implementation of semi supervised learning, without sklearn\"\"\"\n",
    "    X_train = np.zeros((idx.shape[0]*idx.shape[1],X.shape[1]))\n",
    "    y_train = np.zeros(idx.shape[0]*idx.shape[1])\n",
    "    nb_points = idx.shape[1]\n",
    "    #set train set\n",
    "    for i in range(idx.shape[0]): #pour chaque cluster/label\n",
    "        X_train[i*nb_points:(i+1)*nb_points,:] = X[idx[i]]\n",
    "        if(i>0):\n",
    "            y_train[i*nb_points:(i+1)*nb_points] = i\n",
    "    #set test \n",
    "    X_test = np.delete(X,idx.ravel(),axis=0)\n",
    "    y_test = np.delete(labels,idx.ravel(),axis=0)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = get_input_semi_supervised_draft(idx_per_cluster,X_idf_reduced,y_cluster_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - regularized logistic regression with 1 leave out cross val ? (using probabilities to decide)\n",
    "    - svm with 1 leave out cross val ? (using distance to hyperplan to decide)\n",
    "    - tree based methods ? (using class probabilities to decide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2',C=2)\n",
    "res = np.zeros((X_train.shape[0]+X_test.shape[0],2)) -1\n",
    "\n",
    "for i in range(0,150):\n",
    "    log_reg.fit(X_train,y_train.reshape(-1,))\n",
    "    pred_prob_max = np.max(log_reg.predict_proba(X_test),axis=1) \n",
    "    buffer_pred = log_reg.predict(X_test)\n",
    "    idx = np.where(pred_prob_max>0.65)\n",
    "    \n",
    "    #store results\n",
    "    print(y_test[idx])\n",
    "    res[idx,0] = y_test[idx]\n",
    "    res[idx,1] = buffer_pred[idx]\n",
    "    \n",
    "    #update datasets\n",
    "    X_train = np.vstack((X_train,X_test[idx]))\n",
    "    y_train = np.vstack((y_train.reshape(-1,1),buffer_pred[idx].reshape(-1,1)))\n",
    "    X_test = np.delete(X_test,idx,axis=0)\n",
    "    \n",
    "    if len(y_test)<10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = res[res[:,0]!=-1]\n",
    "np.mean(test[:,0]==test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat peu concluant, à peine 25% de labéllisation commune avec le clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel augmenter C : risque d'overfitter, on priorise la minimisation de l'erreur sur la maximisation de la marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(decision_function_shape='ovr', probability=True,C=10)\n",
    "res = np.zeros((X_train.shape[0]+X_test.shape[0],2)) -1\n",
    "\n",
    "for i in range(0,150):\n",
    "    svm.fit(X_train,y_train.reshape(-1,))\n",
    "    pred_prob_max = np.max(svm.predict_proba(X_test),axis=1) \n",
    "    buffer_pred = log_reg.predict(X_test)\n",
    "    idx = np.where(pred_prob_max>0.6)\n",
    "    \n",
    "    #store results\n",
    "    print(y_test[idx])\n",
    "    res[idx,0] = y_test[idx]\n",
    "    res[idx,1] = buffer_pred[idx]\n",
    "    \n",
    "    #update datasets\n",
    "    X_train = np.vstack((X_train,X_test[idx]))\n",
    "    y_train = np.vstack((y_train.reshape(-1,1),buffer_pred[idx].reshape(-1,1)))\n",
    "    X_test = np.delete(X_test,idx,axis=0)\n",
    "    \n",
    "    if len(y_test)<10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = res[res[:,0]!=-1]\n",
    "np.mean(test[:,0]==test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEMI SUPERVISED WITH SEMI SUPERVISED METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_semi_supervised(idx,labels):\n",
    "    \"\"\"Method to preprocess the data before using sklearn semi-supervised\n",
    "    return labels array with -1 for unknown labels\"\"\"\n",
    "    y_semi_sup = -1*np.ones(labels.shape[0])\n",
    "    for label in range(idx.shape[0]):\n",
    "        print(label)\n",
    "        y_semi_sup[idx[label]] = label\n",
    "    return y_semi_sup.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_semi_sup = get_input_semi_supervised(idx_per_cluster,y_cluster_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(y_semi_sup==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_spread = LabelSpreading()\n",
    "\n",
    "label_spread.fit(X_idf_reduced,y_semi_sup)\n",
    "test = label_spread.predict(X_idf_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cluster_pca[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_to_clustering(labels_clustering,new_labels):\n",
    "    return np.mean(labels_clustering==new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_to_clustering(test,y_cluster_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download talan CVs \n",
    "liste_cv_talan = []\n",
    "\n",
    "path = \"/Users/mehdiregina/FilRouge/Mehdi/data_talan\"\n",
    "filenames = sorted(glob(os.path.join(path,\"*.txt\")))\n",
    "print(len(filenames))\n",
    "for file in filenames:\n",
    "    liste_cv_talan.append(open(file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_cv_talan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression des saut de lignes\n",
    "liste_cv_talan = [del_line_feed(text).lower() for text in liste_cv_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression de la ponctuation\n",
    "liste_cv_talan_no_punc = [del_punct(text) for text in liste_cv_talan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selectionner seulement cvs fr\n",
    "liste_cv_talan_fr = get_cv_langue(liste_cv_talan_no_punc,'french')\n",
    "\n",
    "nb_cv = len(liste_cv_talan_no_punc)\n",
    "nb_cv_fr = len(liste_cv_talan_fr)\n",
    "\n",
    "print(\"proportion cv french :\",1- ((nb_cv-nb_cv_fr)/nb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On supprime les caractères étranges, accents et stop words\n",
    "liste_cv_treated_talan = [text_treatment(text) for text in liste_cv_talan_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove stop word\n",
    "liste_cv_talan_no_stop = [remove_stopwords(text,stop_words_main) for text in liste_cv_treated_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#facultatif add only for talan cv (delete numbers) -> could be use for the preprocessing in general !\n",
    "liste_cv_talan_clean = [re.sub('[0-9 ]+', ' ', text) for text in liste_cv_talan_no_stop]\n",
    "liste_cv_talan_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalvocab_stemmed_talan = []\n",
    "totalvocab_tokenized_talan = []\n",
    "for text in liste_cv_talan_no_stop:\n",
    "    allwords_stemmed = tokenize_and_stem(text) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed_talan.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(text)\n",
    "    totalvocab_tokenized_talan.extend(allwords_tokenized)\n",
    "\n",
    "vocab_frame_talan = pd.DataFrame({'words': totalvocab_tokenized_talan}, index = totalvocab_stemmed_talan)\n",
    "print('there are ' + str(vocab_frame_talan.shape[0]) + ' items in vocab_frame')\n",
    "vocab_frame_talan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frame_talan.loc['obie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACP X KMEANS TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TF IDF BOW Representation\n",
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.1,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "test_idf_talan = tf_vect.fit_transform(liste_cv_talan_clean)\n",
    "\n",
    "vocab_liste_talan = tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_liste_talan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSA\n",
    "svd = TruncatedSVD(40)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa_talan = make_pipeline(svd, normalizer)\n",
    "\n",
    "test_idf_reduced_talan = lsa_talan.fit_transform(test_idf_talan)\n",
    "print(test_idf_reduced_talan.shape)\n",
    "\n",
    "#keep the same variance than for the the indeed data above\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeans\n",
    "n_class = 5\n",
    "km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(test_idf_reduced_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_cluster_words(7,km.cluster_centers_,vocab_frame_talan,vocab_liste_talan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF X KMEANS TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on part d'un bag of words tf-idf\n",
    "tf_vect_2 = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "\n",
    "test_idf_2_talan = tf_vect_2.fit_transform(liste_cv_talan_clean)\n",
    "\n",
    "vocab_liste_nmf_talan = tf_vect_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_topic, liste_cluster = get_kmens_cluster_words_nmf(test_idf_2_talan,20,5,5,vocab_frame_talan,vocab_liste_nmf_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
