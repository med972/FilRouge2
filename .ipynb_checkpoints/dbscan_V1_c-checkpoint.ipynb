{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#TEXT PROCESSING\n",
    "import nltk\n",
    "import re\n",
    "import codecs\n",
    "import unidecode\n",
    "import mpld3\n",
    "import stop_words\n",
    "from nltk import SnowballStemmer, pos_tag, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer,TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import *\n",
    "from sklearn.semi_supervised import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lecture des données **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download cv in a list\n",
    "def load_cv_list(nombre):\n",
    "    path = '../data_indeed/txt/'\n",
    "    liste_paths = [path+directory for directory in os.listdir(path)]\n",
    "    liste_cv = []\n",
    "    liste_files = []\n",
    "    for path in liste_paths :\n",
    "        if \"informaticien\" and \"dba\" and \"chef_de_projet_informatique\" not in path:\n",
    "            filenames = sorted(glob(os.path.join(path,\"*.txt\")))\n",
    "           \n",
    "            for file in filenames[:nombre]:\n",
    "                liste_cv.append(open(file).read())\n",
    "                liste_files.append(file.split('/')[-1].split('.')[0])\n",
    "    return liste_cv,liste_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 cvs\n"
     ]
    }
   ],
   "source": [
    "liste_cv_indeed,liste_files = load_cv_list(200)\n",
    "print(len(liste_cv_indeed), \"cvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"INFORMATICIEN DÉVELOPPEMENT ET\\nRÉSEAUX\\n\\nDéveloppeur Intégrateur Web\\n\\nÉragny (95) - Email me on Indeed: indeed.com/r/d7e8913ed00d0384\\n\\nAujourd’hui, je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de\\nmonter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation.\\n\\nEXPÉRIENCE\\n\\nINFORMATICIEN DÉVELOPPEMENT ET RÉSEAUX\\n\\nLeGrandCercle95  -  Éragny (95) -\\n\\nnovembre 2016 - juin 2017\\n\\nInformaticien de l'entreprise, mes missions était de gérer les différent problème dans l'entreprise. Mise en\\nplace d'un antivirus serveur, sauvegarde Nas... Créé et gérer les droits sur l'Active Directory. Paramétrer des\\nclients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en IP fixe.\\n\\nRéajustement du code html et css sur le site grand public selon les normes w3c.\\nCréation d'une source ODBC\\nCréation d'un code en php - sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré\\nen fiche xml.\\nCréation de bannières pour les différents évènements avec photoshop et formation d'une personne sur place\\nau logiciel photoshop.\\n\\nCHARGE DE CLIENTELE\\n\\nEuropcar France Commercial  -  Saint-Ouen-l'Aumône (95) -\\n\\nnovembre 2008 - novembre 2016\\n\\nMes missions principales : \\n\\n- Qualité de service :\\nAssurer l'accueil des clients et le respect de la charte en agence.\\n\\n- Gestion des clients :\\nTraiter l'ensemble des appels téléphoniques.\\nAnalyser les besoins du client.\\nAssurer le suivi de la clientèle.\\n\\n- Logistique et Administratif :\\nS'assurer de la disponibilité des véhicules.\\nGérer l'administratif de l'agence.\\nGestion de la caisse.\\n\\n- Polyvalence\\n\\n\\x0cFormation Développeur Intégrateur Web\\n\\n-\\n\\nseptembre 2015 - juin 2016\\n\\nC.I.F)\\nCentre de formation IFOCOP (8mois)\\n\\n- Création de différents sites. (portfolio)\\n- Présentation d'un site e-commerce créé de A à Z pour l'examen\\n\\nDéveloppeur Web (stage)\\n\\nLe Club des formateurs  -  Éragny (95) -\\n\\nfévrier 2016 - mai 2016\\n\\nDéveloppement d'un site sous Wordpress de A à Z.\\n\\nCommercial stagiaire\\n\\nLAMY Assurance -\\n\\nnovembre 2007 - décembre 2007\\n\\nstagiaire\\n\\nPort Marly accessoires  -  Le Port-Marly (78) -\\n\\nmai 2007 - juin 2007\\n\\nLes Galeries Lafayette Vendeur\\n\\n-\\n\\n2005 - 2006\\n\\nconfection homme) Job étudiant\\n\\nBrice Vendeur\\n\\nPAP Job -\\n\\n2004 - 2004\\n\\nétudiant\\n\\nFORMATION\\n\\nniveau II bac+3 bac+4 en Développeur intégrateur web\\n\\nifocop  -  Éragny (95)\\n\\n2015 - 2016\\n\\n\\x0c\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cv_indeed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des sauts de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string,re\n",
    "regex = re.compile('[%s]' % '(\\\\n)*(\\\\x0c)*')\n",
    "def del_line_feed(s):  \n",
    "    \"\"\"Delete \\n in the text\"\"\"\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien développement et réseaux  développeur intégrateur web  éragny  95  - email me on indeed: indeed.com/r/d7e8913ed00d0384  aujourd’hui, je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de monter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation.  expérience  informaticien développement et réseaux  legrandcercle95  -  éragny  95  -  novembre 2016 - juin 2017  informaticien de l'entreprise, mes missions était de gérer les différent problème dans l'entreprise. mise en place d'un antivirus serveur, sauvegarde nas... créé et gérer les droits sur l'active directory. paramétrer des clients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en ip fixe.  réajustement du code html et css sur le site grand public selon les normes w3c. création d'une source odbc création d'un code en php - sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré en fiche xml. création de bannières pour les différents évènements avec photoshop et formation d'une personne sur place au logiciel photoshop.  charge de clientele  europcar france commercial  -  saint-ouen-l'aumône  95  -  novembre 2008 - novembre 2016  mes missions principales :   - qualité de service : assurer l'accueil des clients et le respect de la charte en agence.  - gestion des clients : traiter l'ensemble des appels téléphoniques. analyser les besoins du client. assurer le suivi de la clientèle.  - logistique et administratif : s'assurer de la disponibilité des véhicules. gérer l'administratif de l'agence. gestion de la caisse.  - polyvalence   formation développeur intégrateur web  -  septembre 2015 - juin 2016  c.i.f  centre de formation ifocop  8mois   - création de différents sites.  portfolio  - présentation d'un site e-commerce créé de a à z pour l'examen  développeur web  stage   le club des formateurs  -  éragny  95  -  février 2016 - mai 2016  développement d'un site sous wordpress de a à z.  commercial stagiaire  lamy assurance -  novembre 2007 - décembre 2007  stagiaire  port marly accessoires  -  le port-marly  78  -  mai 2007 - juin 2007  les galeries lafayette vendeur  -  2005 - 2006  confection homme  job étudiant  brice vendeur  pap job -  2004 - 2004  étudiant  formation  niveau ii bac+3 bac+4 en développeur intégrateur web  ifocop  -  éragny  95   2015 - 2016   \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cv_indeed = [del_line_feed(text).lower() for text in liste_cv_indeed]\n",
    "liste_cv_indeed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#le maintient de la ponctuation pertube le stop words, apostrophe gérée dans text_treatment\n",
    "regex = re.compile('[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_{|}~')) \n",
    "def del_punct(s):  \n",
    "    \"\"\"Delete punctuation in the text\"\"\"\n",
    "    return regex.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien développement et réseaux  développeur intégrateur web  éragny  95   email me on indeed indeedcomrd7e8913ed00d0384  aujourd’hui je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de monter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation  expérience  informaticien développement et réseaux  legrandcercle95    éragny  95    novembre 2016  juin 2017  informaticien de l'entreprise mes missions était de gérer les différent problème dans l'entreprise mise en place d'un antivirus serveur sauvegarde nas créé et gérer les droits sur l'active directory paramétrer des clients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en ip fixe  réajustement du code html et css sur le site grand public selon les normes w3c création d'une source odbc création d'un code en php  sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré en fiche xml création de bannières pour les différents évènements avec photoshop et formation d'une personne sur place au logiciel photoshop  charge de clientele  europcar france commercial    saintouenl'aumône  95    novembre 2008  novembre 2016  mes missions principales     qualité de service  assurer l'accueil des clients et le respect de la charte en agence   gestion des clients  traiter l'ensemble des appels téléphoniques analyser les besoins du client assurer le suivi de la clientèle   logistique et administratif  s'assurer de la disponibilité des véhicules gérer l'administratif de l'agence gestion de la caisse   polyvalence   formation développeur intégrateur web    septembre 2015  juin 2016  cif  centre de formation ifocop  8mois    création de différents sites  portfolio   présentation d'un site ecommerce créé de a à z pour l'examen  développeur web  stage   le club des formateurs    éragny  95    février 2016  mai 2016  développement d'un site sous wordpress de a à z  commercial stagiaire  lamy assurance   novembre 2007  décembre 2007  stagiaire  port marly accessoires    le portmarly  78    mai 2007  juin 2007  les galeries lafayette vendeur    2005  2006  confection homme  job étudiant  brice vendeur  pap job   2004  2004  étudiant  formation  niveau ii bac3 bac4 en développeur intégrateur web  ifocop    éragny  95   2015  2016   \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test \n",
    "liste_cv_indeed_no_punc = [del_punct(text) for text in liste_cv_indeed]\n",
    "liste_cv_indeed_no_punc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reconnaissance du langage du CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_languages_ratios(text):\n",
    "    \"\"\"\n",
    "    Calculate probability of given text to be written in several languages and\n",
    "    return a dictionary that looks like {'french': 2, 'spanish': 4, 'english': 0}\n",
    "    \"\"\"\n",
    "\n",
    "    languages_ratios = {}\n",
    "\n",
    "    '''\n",
    "    nltk.wordpunct_tokenize() splits all punctuations into separate tokens\n",
    "    \n",
    "    >>> wordpunct_tokenize(\"That's thirty minutes away. I'll be there in ten.\")\n",
    "    ['That', \"'\", 's', 'thirty', 'minutes', 'away', '.', 'I', \"'\", 'll', 'be', 'there', 'in', 'ten', '.']\n",
    "    '''\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens] #from text get list of word in minuscule\n",
    "\n",
    "    \n",
    "    for language in stopwords.fileids(): # pour chaque langue\n",
    "        stopwords_set = set(stopwords.words(language)) #je mets les stop words du langage dans un set\n",
    "        words_set = set(words) #je mets les mots de mon texte dans un set\n",
    "        #je prends l'intersection entre les mots de mon texte et les mots du stopwords dans le langage donné\n",
    "        common_elements = words_set & stopwords_set\n",
    "        \n",
    "        #je compute mon score comme le nombre d'éléments en communs dictionnaire [langage : score]\n",
    "        languages_ratios[language] = len(common_elements) # language \"score\"\n",
    "\n",
    "    return languages_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mehdiregina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cv_langue(liste_cv, language,cv_names) :\n",
    "    \"\"\"Return resume witten in the specified language in parameter\"\"\"\n",
    "    liste_2 = []\n",
    "    french_cv_names = []\n",
    "    i=0\n",
    "    for cv in liste_cv:\n",
    "        if max(_calculate_languages_ratios(cv),key =_calculate_languages_ratios(cv).get)=='french':\n",
    "            liste_2.append(cv)\n",
    "            french_cv_names.append(cv_names[i])\n",
    "        i+=1\n",
    "    return liste_2,french_cv_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion cv french : 0.704\n"
     ]
    }
   ],
   "source": [
    "liste_cv_indeed_fr,liste_files_fr = get_cv_langue(liste_cv_indeed_no_punc,'french',liste_files)\n",
    "nb_cv = len(liste_cv_indeed_no_punc)\n",
    "nb_cv_fr = len(liste_cv_indeed_fr)\n",
    "\n",
    "print(\"proportion cv french :\",1- ((nb_cv-nb_cv_fr)/nb_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocessing du text **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_treatment (text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\x00\", '').replace(\"\\x01\", '').replace(\"\\x02\", '').replace(\"\\x03\", '') \\\n",
    "    .replace(\"\\x04\", '').replace(\"\\x05\", '').replace(\"\\x06\", '').replace(\"\\x07\", '').replace(\"\\x08\", '') \\\n",
    "    .replace(\"\\x0e\", '').replace(\"\\x11\", '').replace(\"\\x12\", '').replace(\"\\x10\", '').replace(\"\\x19\", '') \\\n",
    "    .replace(\"\\x1b\", '').replace(\"\\x14\", '').replace(\"\\x15\", '').replace('/', '').replace('=', '').replace(\"〓\", \"\") \\\n",
    "    .replace(\"»\", \"\").replace(\"«\", \"\").replace(\"¬\", \"\").replace('`', '').replace (\" -\", \"\").replace(\"•\", \"\")\\\n",
    "    .replace(\"l'\", \"\").replace(\"l’\", \"\").replace(\"l´\", \"\").replace(\"d’\", \"\").replace(\"d'\", \"\").replace(\"d´\",\"\")\\\n",
    "    .replace(\"j’\", \"\").replace(\"j'\", \"\").replace(\"j´\",\"\").replace(\"n’\", \"\").replace(\"n'\", \"\").replace(\"n´\",\"\")\\\n",
    "    .replace(\"”\", \"\").replace(\"~\", \"\").replace(\"§\", \"\").replace(\"¨\", \"\").replace(\"©\", \"\").replace(\"›\", \"\")\\\n",
    "    .replace(\"₋\", \"\").replace(\"→\", \"\").replace(\"⇨\", \"\").replace(\"∎\", \"\").replace(\"√\", \"\").replace(\"□\", \"\")\\\n",
    "    .replace(\"*\", \"\").replace(\"&\", \"\").replace(\"►\", \"\").replace(\"◊\", \"\").replace(\"☞\", \"\").replace(\"#\", \"\")\\\n",
    "    .replace(\"%\", \"\").replace(\"❖\", \"\").replace(\"➠\", \"\").replace(\"➢\", \"\").replace(\"\", \"\").replace(\"✓\", \"\") \\\n",
    "    .replace(\"√\", \"\").replace(\"✔\", \"\").replace(\"♦\", \"\").replace(\"◦\", \"\").replace(\"●\", \"\").replace(\"▫\", \"\")\\\n",
    "    .replace(\"▪\", \"\").replace(\"…\", \"\").replace(\"þ\", \"\").replace(\"®\", \"\").replace('', '').replace(\"...\", \"\")\n",
    "    text = unidecode.unidecode(text) # remove accent\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien developpement et reseaux  developpeur integrateur web  eragny  95   email me on indeed indeedcomrd7e8913ed00d0384  aujourhui je suis en recherche une opportunite sur un poste de developpeur ou integrateur web afin de monter toujours plus en competence et approfondir les bases solide que ai acquis en formation  experience  informaticien developpement et reseaux  legrandcercle95    eragny  95    novembre 2016  juin 2017  informaticien de entreprise mes missions etait de gerer les different probleme dans entreprise mise en place un antivirus serveur sauvegarde nas cree et gerer les droits sur active directory parametrer des clients leger ainsi que du materiel informatique comme des imprimantes ou des etiqueteuse en ip fixe  reajustement du code html et css sur le site grand public selon les normes w3c creation une source odbc creation un code en php  sql afin de recupere des donnees librairie sur un site fournisseur pour les enregistre en fiche xml creation de bannieres pour les differents evenements avec photoshop et formation une personne sur place au logiciel photoshop  charge de clientele  europcar france commercial    saintouenaumone  95    novembre 2008  novembre 2016  mes missions principales     qualite de service  assurer accueil des clients et le respect de la charte en agence   gestion des clients  traiter ensemble des appels telephoniques analyser les besoins du client assurer le suivi de la clientele   logistique et administratif  s'assurer de la disponibilite des vehicules gerer administratif de agence gestion de la caisse   polyvalence   formation developpeur integrateur web    septembre 2015  juin 2016  cif  centre de formation ifocop  8mois    creation de differents sites  portfolio   presentation un site ecommerce cree de a a z pour examen  developpeur web  stage   le club des formateurs    eragny  95    fevrier 2016  mai 2016  developpement un site sous wordpress de a a z  commercial stagiaire  lamy assurance   novembre 2007  decembre 2007  stagiaire  port marly accessoires    le portmarly  78    mai 2007  juin 2007  les galeries lafayette vendeur    2005  2006  confection homme  job etudiant  brice vendeur  pap job   2004  2004  etudiant  formation  niveau ii bac3 bac4 en developpeur integrateur web  ifocop    eragny  95   2015  2016   \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On supprime les caractères étranges, accents et stop words\n",
    "liste_cv_indeed_treated = [text_treatment(text) for text in liste_cv_indeed_fr]\n",
    "#test\n",
    "liste_cv_indeed_treated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gestion des stop words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille stop words liste :  368\n"
     ]
    }
   ],
   "source": [
    "#generate stopwords\n",
    "stop_words_py = set(stop_words.get_stop_words('french'))\n",
    "\n",
    "# attention certains stop words pourraient être utiles par la suite\n",
    "stopwords_set_manuel = set([\"an\", \"ans\", 'les', 'moins', 'd\\'un','janvier', 'fevrier', 'février', 'mars', 'avril', \\\n",
    "                 'mai', 'juin', 'juillet', 'aout', 'août', 'septembre', 'octobre', 'novembre', 'décembre', \\\n",
    "                  'decembre', 'moins', 'mise', 'universit\\xc3\\xa9', 'université', 'universite', 'ion','sage', \\\n",
    "                  'o', 'rac', 'vers', 'via', 'p\\xc3\\xa9rim\\xc3\\xa8tre', 'périmètre','et','paris','x',\"\\x00\",\\\n",
    "                          \"\\x01\",\"\\x02\", \"\\x03\",\"\\x04\",\"\\x05\",\"\\x06\",\"\\x07\",\"\\x08\",\"\\x09\",\"\\x0e\",\"\\x0e\",\"\\x11\",\\\n",
    "                           \"\\x12\",\"\\x13\",\"\\x14\",\"\\x15\",\"\\x16\",\"\\x17\",\"\\x18\",\"\\x19\",\"transport\",\"puis\",\"lieu\",\\\n",
    "                           \"adresse\",\"entre\",'dun','dune','chez','boulognebillancourt','bt','etc','recrutement','main',\\\n",
    "                           'and', 'paie','paiement','environ','place','france','paris','mois','mobile','mobiles',\\\n",
    "                           'nanterre','source','sources','concerne','concernant','of','non','notes','rh','minimum',\\\n",
    "                           'maximum','bac','site','sites','actuellement','telephone','telephonique','telephoniques','ca','demenager',\\\n",
    "                           'demenagement','participer','participation','lycee','baccalaureat','lien','liens','in',\\\n",
    "                           'indeed','email','indeedcomrd7e8913ed00d0384','aujourhui','afin','toujours','enterprise',\\\n",
    "                           \"guide\",\"10g\",\"11g\",\"9i\",'ad','v10','v2','v3','v5','v6','v8','v9',])\n",
    "stop_words_main = stop_words_py | stopwords_set_manuel\n",
    "stop_words_main = list(stop_words_main)\n",
    "print(\"taille stop words liste : \", len(stop_words_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eussions',\n",
       " 'devrons',\n",
       " 'que',\n",
       " 'ceci',\n",
       " 'à',\n",
       " 'novembre',\n",
       " 'au',\n",
       " 'auraient',\n",
       " 'lien',\n",
       " 'là',\n",
       " 'me',\n",
       " 'pour',\n",
       " 'octobre',\n",
       " 'v5',\n",
       " 'aux',\n",
       " 'seras',\n",
       " 'elle',\n",
       " '\\x19',\n",
       " 'mais',\n",
       " 'bon',\n",
       " 'vu',\n",
       " 'paie',\n",
       " 'concerne',\n",
       " 'pÃ©rimÃ¨tre',\n",
       " 'août',\n",
       " 'je',\n",
       " 'nommé',\n",
       " 'était',\n",
       " 'dois',\n",
       " 'peu',\n",
       " 'eurent',\n",
       " 'decembre',\n",
       " 'telephonique',\n",
       " '\\x18',\n",
       " 'aucun',\n",
       " 'aurions',\n",
       " 'fais',\n",
       " 'état',\n",
       " 'eussent',\n",
       " 'chez',\n",
       " 'personnes',\n",
       " 'où',\n",
       " 'x',\n",
       " 'as',\n",
       " 'toi',\n",
       " 'v2',\n",
       " 'vers',\n",
       " '\\x08',\n",
       " 'quelles',\n",
       " 'dun',\n",
       " '\\x15',\n",
       " 'serons',\n",
       " 'personne',\n",
       " 'fûtes',\n",
       " 'ceux',\n",
       " 'ne',\n",
       " 'te',\n",
       " '\\x0e',\n",
       " 'une',\n",
       " 'bac',\n",
       " 'encore',\n",
       " 'enterprise',\n",
       " 'périmètre',\n",
       " 'dès',\n",
       " 'se',\n",
       " 'ci',\n",
       " 'seriez',\n",
       " '9i',\n",
       " '\\x07',\n",
       " 'sources',\n",
       " 'lycee',\n",
       " 'v9',\n",
       " 'nouveau',\n",
       " 'eux',\n",
       " 'baccalaureat',\n",
       " 'êtes',\n",
       " 'ce',\n",
       " 'donc',\n",
       " 'valeur',\n",
       " 'eue',\n",
       " 'guide',\n",
       " 'est',\n",
       " 'pourquoi',\n",
       " 'demenager',\n",
       " 'comment',\n",
       " 'furent',\n",
       " 'ta',\n",
       " 'boulognebillancourt',\n",
       " 'seront',\n",
       " \"d'un\",\n",
       " 'environ',\n",
       " 'v6',\n",
       " 'eusses',\n",
       " 'n',\n",
       " 'aurons',\n",
       " 'haut',\n",
       " 'peut',\n",
       " 'v3',\n",
       " 'février',\n",
       " 'eus',\n",
       " 'sa',\n",
       " 'universitÃ©',\n",
       " 'concernant',\n",
       " 'lui',\n",
       " 'si',\n",
       " 'votre',\n",
       " 'ca',\n",
       " 'juin',\n",
       " 'eût',\n",
       " 'sont',\n",
       " 'ton',\n",
       " 'rac',\n",
       " 'aies',\n",
       " 'depuis',\n",
       " 'ici',\n",
       " 'les',\n",
       " '\\x04',\n",
       " 'aout',\n",
       " 'étions',\n",
       " 'avez',\n",
       " 'nouveaux',\n",
       " 'moins',\n",
       " 'ai',\n",
       " 'avril',\n",
       " 'la',\n",
       " 'etc',\n",
       " 'aurai',\n",
       " 'actuellement',\n",
       " 'v10',\n",
       " 'soi',\n",
       " 'auront',\n",
       " 'tu',\n",
       " 'quand',\n",
       " 'droite',\n",
       " 'on',\n",
       " 'ils',\n",
       " 'sage',\n",
       " 'dans',\n",
       " 'ni',\n",
       " 'auriez',\n",
       " 'avoir',\n",
       " 'sans',\n",
       " '\\x16',\n",
       " '\\x12',\n",
       " 'eut',\n",
       " 'soyons',\n",
       " '\\x02',\n",
       " 'liens',\n",
       " 'son',\n",
       " 'fut',\n",
       " 'sujet',\n",
       " 'y',\n",
       " 'seraient',\n",
       " 'telephone',\n",
       " 'bt',\n",
       " 'indeed',\n",
       " 'ces',\n",
       " 'non',\n",
       " 'fusses',\n",
       " 'nommés',\n",
       " 'afin',\n",
       " 'deux',\n",
       " 'ayant',\n",
       " 'soient',\n",
       " 'sommes',\n",
       " 'car',\n",
       " 'aurais',\n",
       " 'ses',\n",
       " 'paiement',\n",
       " 'leurs',\n",
       " 'voient',\n",
       " 'serais',\n",
       " 'dehors',\n",
       " 'avec',\n",
       " 'tellement',\n",
       " 'lieu',\n",
       " 'étiez',\n",
       " 'des',\n",
       " 'participer',\n",
       " 'sien',\n",
       " 'faisez',\n",
       " 'ou',\n",
       " 'étais',\n",
       " '\\t',\n",
       " 'mise',\n",
       " 'mobiles',\n",
       " 'quels',\n",
       " 'même',\n",
       " 'm',\n",
       " 'source',\n",
       " 'décembre',\n",
       " 'fus',\n",
       " 'ayons',\n",
       " 'fait',\n",
       " 'avait',\n",
       " 'fussions',\n",
       " 'email',\n",
       " 'sous',\n",
       " '\\x03',\n",
       " 'in',\n",
       " 'dos',\n",
       " 'mes',\n",
       " 'avaient',\n",
       " 'ma',\n",
       " 'devoir',\n",
       " 'fusse',\n",
       " 'via',\n",
       " 'nous',\n",
       " 'quel',\n",
       " 'tes',\n",
       " 'transport',\n",
       " 'été',\n",
       " 'ans',\n",
       " 'adresse',\n",
       " 'mars',\n",
       " 'nom',\n",
       " 'eu',\n",
       " 'septembre',\n",
       " 'par',\n",
       " 'vous',\n",
       " 'place',\n",
       " 'fois',\n",
       " 'soit',\n",
       " 'devrez',\n",
       " 'france',\n",
       " 'nommée',\n",
       " 'devrait',\n",
       " 'auras',\n",
       " 'cela',\n",
       " 'janvier',\n",
       " 'paris',\n",
       " 'v8',\n",
       " 'aviez',\n",
       " 'o',\n",
       " 'étant',\n",
       " 'ait',\n",
       " 'vont',\n",
       " 'mot',\n",
       " 'font',\n",
       " 'maximum',\n",
       " 'de',\n",
       " 'cet',\n",
       " 'recrutement',\n",
       " 'tandis',\n",
       " 'minimum',\n",
       " 'être',\n",
       " 'sur',\n",
       " 'vos',\n",
       " 'sites',\n",
       " 'il',\n",
       " 'indeedcomrd7e8913ed00d0384',\n",
       " 'université',\n",
       " 'fevrier',\n",
       " 'aie',\n",
       " 'un',\n",
       " 'avons',\n",
       " 'fussiez',\n",
       " 'avant',\n",
       " '\\x05',\n",
       " 'universite',\n",
       " '\\x00',\n",
       " 'elles',\n",
       " 'parole',\n",
       " '\\x01',\n",
       " 'aurez',\n",
       " '\\x06',\n",
       " 'serions',\n",
       " 'devront',\n",
       " 'eûtes',\n",
       " 'es',\n",
       " 'étés',\n",
       " 'ont',\n",
       " 'début',\n",
       " 'nos',\n",
       " 'aura',\n",
       " 'ayez',\n",
       " 'notes',\n",
       " 'comme',\n",
       " 'participation',\n",
       " 'fût',\n",
       " 't',\n",
       " 'mon',\n",
       " 'and',\n",
       " 'avais',\n",
       " 'chaque',\n",
       " 'tout',\n",
       " 'eusse',\n",
       " 'l',\n",
       " 'seulement',\n",
       " 'hors',\n",
       " 'sera',\n",
       " 'parce',\n",
       " 'serez',\n",
       " 'en',\n",
       " '11g',\n",
       " '\\x17',\n",
       " 'tels',\n",
       " 'cette',\n",
       " 'doit',\n",
       " 'leur',\n",
       " 'devriez',\n",
       " 'très',\n",
       " 'avions',\n",
       " 'qu',\n",
       " 'a',\n",
       " 'eussiez',\n",
       " 'nanterre',\n",
       " 'soyez',\n",
       " 'force',\n",
       " 'mois',\n",
       " '\\x11',\n",
       " 'toujours',\n",
       " '\\x14',\n",
       " 'quelle',\n",
       " 'alors',\n",
       " 'maintenant',\n",
       " 'j',\n",
       " 'moi',\n",
       " 'aussi',\n",
       " 'suis',\n",
       " 'an',\n",
       " 'voit',\n",
       " 'étaient',\n",
       " 'mobile',\n",
       " 'dedans',\n",
       " 'faites',\n",
       " 'notre',\n",
       " '10g',\n",
       " 'of',\n",
       " 'ça',\n",
       " 'entre',\n",
       " 'le',\n",
       " 'demenagement',\n",
       " 'faire',\n",
       " 'pas',\n",
       " '\\x13',\n",
       " 'aujourhui',\n",
       " 'autre',\n",
       " 'aurait',\n",
       " 'd',\n",
       " 'devrions',\n",
       " 'site',\n",
       " 'qui',\n",
       " 'telephoniques',\n",
       " 'serai',\n",
       " 'eues',\n",
       " 'main',\n",
       " 'dune',\n",
       " 'du',\n",
       " 'juste',\n",
       " 'ad',\n",
       " 'plupart',\n",
       " 'trop',\n",
       " 'et',\n",
       " 'eûmes',\n",
       " 'fûmes',\n",
       " 'juillet',\n",
       " 'tous',\n",
       " 'vois',\n",
       " 'fussent',\n",
       " 'serait',\n",
       " 'mai',\n",
       " 'rh',\n",
       " 'ion',\n",
       " 'dù',\n",
       " 'sois',\n",
       " 'aient',\n",
       " 'puis']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text,stopwords_list):\n",
    "    text_temp = \" \".join(text.split())+\" \"\n",
    "    for word in stopwords_list:\n",
    "        text_temp = text_temp.replace(\" \"+word+\" \", \" \")\n",
    "    return text_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien developpement reseaux developpeur integrateur web eragny 95 recherche opportunite poste developpeur integrateur web monter plus competence approfondir bases solide acquis formation experience informaticien developpement reseaux legrandcercle95 eragny 95 2016 2017 informaticien entreprise missions etait gerer different probleme entreprise antivirus serveur sauvegarde nas cree gerer droits active directory parametrer clients leger ainsi materiel informatique imprimantes etiqueteuse ip fixe reajustement code html css grand public selon normes w3c creation odbc creation code php sql recupere donnees librairie fournisseur enregistre fiche xml creation bannieres differents evenements photoshop formation logiciel photoshop charge clientele europcar commercial saintouenaumone 95 2008 2016 missions principales qualite service assurer accueil clients respect charte agence gestion clients traiter ensemble appels analyser besoins client assurer suivi clientele logistique administratif s'assurer disponibilite vehicules gerer administratif agence gestion caisse polyvalence formation developpeur integrateur web 2015 2016 cif centre formation ifocop 8mois creation differents portfolio presentation ecommerce cree a z examen developpeur web stage club formateurs eragny 95 2016 2016 developpement wordpress a z commercial stagiaire lamy assurance 2007 2007 stagiaire port marly accessoires portmarly 78 2007 2007 galeries lafayette vendeur 2005 2006 confection homme job etudiant brice vendeur pap job 2004 2004 etudiant formation niveau ii bac3 bac4 developpeur integrateur web ifocop eragny 95 2015 2016 \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test \n",
    "liste_cv_indeed_no_stop = [remove_stopwords(text,stop_words_main) for text in liste_cv_indeed_treated]\n",
    "liste_cv_indeed_no_stop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SnowballStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalvocab_indeed_stemmed = []\n",
    "totalvocab_indeed_tokenized = []\n",
    "for text in liste_cv_indeed_no_stop:\n",
    "    allwords_stemmed = tokenize_and_stem(text) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_indeed_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(text)\n",
    "    totalvocab_indeed_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame_indeed = pd.DataFrame({'words': totalvocab_indeed_tokenized}, index = totalvocab_indeed_stemmed)\n",
    "print('there are ' + str(vocab_frame_indeed.shape[0]) + ' items in vocab_frame')\n",
    "vocab_frame_indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bag of word tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "bow_idf_indeed = tf_vect.fit_transform(liste_cv_indeed_no_stop)\n",
    "l2_norm = make_pipeline(Normalizer(copy=False))\n",
    "bow_idf_indeed = l2_norm.fit_transform(bow_idf_indeed)\n",
    "\n",
    "vocab_liste_indeed = tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ajout une étape pour supprimer les doublons & shuffle\n",
    "buffer = pd.DataFrame(data=bow_idf_indeed.toarray())\n",
    "buffer = shuffle(buffer)\n",
    "buffer.drop_duplicates(inplace=True)\n",
    "\n",
    "new_idx = buffer.index\n",
    "bow_idf_indeed = buffer.values\n",
    "liste_files_new = []\n",
    "for idx in new_idx:\n",
    "    liste_files_new.append(liste_files_fr[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(eps=0.9, min_samples=6, metric='euclidean', algorithm='auto', leaf_size=30, p=None, n_jobs=1)\n",
    "labels_dbscan = dbs.fit_predict(bow_idf_indeed)\n",
    "pd.DataFrame(labels_dbscan,columns=[\"Label\"]).groupby([\"Label\"])[\"Label\"].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find topics behind each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionnary with doc core sample idx for each cluster\n",
    "idx_core_samples = dbs.core_sample_indices_\n",
    "dict_core_idx_label = dict()\n",
    "for label in np.unique(labels_dbscan):\n",
    "    liste_idx_label = []\n",
    "    for idx in idx_core_samples:\n",
    "        if(labels_dbscan[idx])==label:\n",
    "            liste_idx_label.append(idx)\n",
    "    dict_core_idx_label[\"cluster_\"+str(label)] = liste_idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each doc return n first words according to tf-idf\n",
    "dict_core_word_label = dict()\n",
    "for key in dict_core_idx_label.keys():\n",
    "    idx = dict_core_idx_label[key]\n",
    "    if len(idx)>0:\n",
    "        liste_cluster_word =list()\n",
    "        for i in idx :\n",
    "            idx_ordered_core = np.argsort(bow_idf_indeed[i])[::-1]\n",
    "            text = \"\"\n",
    "            for j in range(0, 4):  # nombre de mots\n",
    "                text += vocab_frame_indeed.loc[vocab_liste_indeed[idx_ordered_core[j]]].values.tolist()[0][0] + \" \"\n",
    "            liste_cluster_word.append(text)\n",
    "        dict_core_word_label[key] = liste_cluster_word\n",
    "        \n",
    "    #cluster -1 has no core samples\n",
    "    else :\n",
    "        dict_core_word_label[key] = [\"bruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_core_word_label.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN X LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement dimension reduction with LSA before DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement LSA\n",
    "lsa_number = 165\n",
    "svd = TruncatedSVD(lsa_number)\n",
    "bow_idf_reduced_indeed = svd.fit_transform(bow_idf_indeed)\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(eps=0.83, min_samples=10, metric='euclidean', algorithm='auto', leaf_size=30, p=None, n_jobs=1)\n",
    "labels_dbscan = dbs.fit_predict(bow_idf_reduced_indeed)\n",
    "pd.DataFrame(labels_dbscan,columns=[\"Label\"]).groupby([\"Label\"])[\"Label\"].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find topics behind each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_core_samples = dbs.core_sample_indices_\n",
    "dict_core_idx_label = dict()\n",
    "for label in np.unique(labels_dbscan):\n",
    "    liste_idx_label = []\n",
    "    for idx in idx_core_samples:\n",
    "        if(labels_dbscan[idx])==label:\n",
    "            liste_idx_label.append(idx)\n",
    "    dict_core_idx_label[\"cluster_\"+str(label)] = liste_idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_core_idx_label[\"cluster_-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_core_word_label = dict()\n",
    "for key in dict_core_idx_label.keys():\n",
    "    idx = dict_core_idx_label[key]\n",
    "    if len(idx)>0:\n",
    "        liste_cluster_word =list()\n",
    "        for i in idx :\n",
    "            idx_ordered_core = np.argsort(bow_idf_indeed[i])[::-1]\n",
    "            text = \"\"\n",
    "            for j in range(0, 4):  # nombre de motss\n",
    "                text += vocab_frame_indeed.loc[vocab_liste_indeed[idx_ordered_core[j]]].values.tolist()[0][0] + \" \"\n",
    "            liste_cluster_word.append(text)\n",
    "        dict_core_word_label[key] = liste_cluster_word\n",
    "    else :\n",
    "        dict_core_word_label[key] = [\"bruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('cluster_-1', ['bruit']), ('cluster_0', ['marketing data analyser strategie ', 'commercial assurer clients marketing ', 'chargee profils entretien recherche ', 'algorithme construction e r ', 'r statistiques data donnees ', 'marketing strategie veille analyser ', 'statistiques donnees r mathematiques ', 'r mathematiques scientist data ', 'scientist stagiaire data r ', 'marketing partenaires gestion editeur ', 'statistiques r scientist stagiaire ', 'grand commercial commande comptes ', 'statistiques data decision economie ', 'entretien it profils selection ', 'communication marketing media partenariat ', 'valider projets transformateur service ', 'chargee entretien genie profils ', 'data stage certification learning ', 'projets word conduite chef ', 'chargee entretien genie profils ', 'learning machines sciences analyser ', 'scientist data certificationslicenses sas ', 'reunions chef plannings produits ', 'data scientist stage classification ', 'marches produits synthese europe ', 'emploi entretien physique disposition ', 'projets comites fort pilotage ', 'marketing operationnel directeur definition ', 'marketing digital communication vente ', 'projets chef comites recette ', 'scientist python learning data ', 'moe projets solutions chef ', 'commercial strategie affaires consultant ', 'data stagiaire analytics big ', 'data big ingenieur scientist ', 'applications projets chef redaction ', 'projets techniques gestion methodes ', 'scientist data learning sciences ', 'data big r analyser ', 'scientist data sas clients ', 'moe projets redaction recette ', 'agile chef code equipe ', 'data stage annees mathematiques ', 'methodes scientist data r ', 'r learning stagiaire data ', 'commercial juniors clients chef ', 'marketing produits conception vente ', 'telecom python analyser scientist ', 'r algorithme data responsabilites ', 'profils entretien chargee commercial ', 'digital commercial directeur management ', 'agile migrations pilotage plannings ', 'data membre equipe developpeur ', 'marketing veille strategie etudes ', 'comptes resultat commercial grand ', 'marketing digital marques strategie ', 'scientist data learning machines ', 'scientist data automatiques master ', 'moe projets calcul risques ', 'direction projets pilotage encadrement ', 'pilotage projets telecom tests ', 'c profils data r ', 'data algorithme mysql juniors ', 'marketing creation communication produits ', 'data learning r scientist ', 'profils chargee entretien projets ', 'mathematiques data learning scientist ', 'scientist data mathematiques sas ', 'fonctionnelle redaction analyser besoins ', 'marketing offres consultant nouvelles ', 'data scientist analyste ingenieur ', 'marketing animation responsabilites stage ', 'stagiaire data scientist statistiques ', 'statistiques r data construction ', 'data big biais tableaux ', 'chargee qualifie entretien selection ', 'marketing communication management international ', 'chargee evenements entretien suivi ', 'recette fonctionnelle redaction competence ', 'data scientist stagiaire sciences ', 'marketing crm deploiements strategie ', 'commercial prospection chargee bureau ', 'marketing analyste business suivi ', 'statistiques ingenieur scientist data ', 'marketing erp offres responsable ', 'data r machines donnees ', 'learning data machines algorithme ', 'vente commercial marketing management ', 'marketing analyser data tableaux ', 'statistiques data scientist algorithme ', 'python data learning scientist ', 'marketing charge produits international ', 'chef offres digital marketing ', 'clients management portefeuille negociation ', 'commercial marches vente business ', 'moe projets bancaires permettant ', 'statistiques modelisation mathematiques data ', 'marketing strategie direction marques ', 'data scientist tant cree ', 'data juniors scientist accueil ', 'marketing analytics campagne performances ', 'cadre coordination gestion projets ', 'recette techniques prestataires developpement ', 'data scientist appliquees mathematiques ', 'marketing marques google vente ', 'data sciences learning machines ', 'entretien prospection collaborateurs clients ', 'marketing international lance produits ', 'statistiques modelisation scientist mathematiques ', 'commercial activite entreprise pays ', 'public data scientist projets ', 'scientist data leader r ', 'digital marques media marketing ', 'marketing produits chef alternance ', 'statistiques learning data mathematiques ', 'marketing produits analyser crm ', 'mathematiques stage scientist statistiques ', 'marketing campagne crm reporting ', 'strategie lance marketing grand ', 'projets specifications chef methodologie ', 'marketing entites direction groupes ', 'data analyste software donnees ', 'learning machines data r ', 'marketing produits support campagne ', 'scientist statistiques consultant data ', 'profils suivi consultant humaines ', 'marketing strategie pilotage offres ', 'entretien profils responsable emploi ', 'commercial chargee qualifie entretien ', 'communication produits marketing commercial ', 'offres produits management definition ', 'marketing innovantes clients juniors ', 'projets infrastructures reseaux solutions ', 'data stage r scientist ', 'processus migrations choix utilisateurs ']), ('cluster_1', ['oracle donnees bases configuration ', 'oracle dba type bases ', 'oracle donnees sql bases ', 'oracle expert performances dba ', 'dba oracle production migrations ', 'oracle dba unix prestation ', 'oracle bases server sql ', 'oracle bases donnees dba ', 'oracle reseaux installations systeme ', 'oracle bases referentiel donnees ', 'oracle vmware production dba ', 'oracle bases suivi dba ', 'oracle donnees bases dba ', 'bases oracle support donnees ', 'oracle donnees developpement sql ', 'oracle dba production bases ', 'oracle dba ibm migrations ', 'oracle bases consulting version ', 'oracle dba expert administratif ', 'oracle parametrage installations production ', 'oracle dba bases controle ', 'bases oracle dba realisation ', 'oracle migrations unix dba ', 'script superviser oracle serveur ', 'oracle xml dba applications ', 'oracle dba projets chef ', 'migrations performances oracle bases ', 'oracle bases gerer projets ', 'oracle donnees applications travaux ', 'oracle bases dba techniques ', 'oracle production dba bases ', 'oracle data bases oeuvre ', 'oracle bases dba production ', 'oracle dba bases transfert ', 'oracle bases architecture sauvegarde ', 'oracle administratif installations version ', 'oracle dba script bases ', 'oracle suite sap plus ', 'oracle equipe applications encadrement ', 'plsql oracle moe sql ', 'oracle plsql unix donnees ', 'oracle dba administratif parc ', 'oracle performances dba production ', 'oracle production audit dba ', 'oracle unix administratif dba ', 'oracle installations configuration bases ', 'bases donnees oracle installations ', 'oracle serveur dba applications ', 'dba oracle senior sciences ', 'oracle dba applications support ', 'oracle dba gestion sap ', 'oracle bases production incidents ', 'oracle bases sauvegarde administratif ', 'oracle bases donnees server ', 'oracle architecture applications bases ', 'oracle plateforme livraison administratif ']), ('cluster_2', ['reseaux serveur vpn technicien ', 'configuration administratif installations windows ', 'connaissances reseaux windows informatique ', 'reseaux informatique administratif electronique ', 'reseaux telecom systeme installations ', 'commande incidents technicien windows ', 'technicien incidents distance poste ', 'administratif configuration reseaux vmware ', 'niveau pilote exploitation windows ', 'serveur infrastructures projets equipe ', 'informatique reseaux agence systeme ', 'gestion administratif serveur parc ', 'reseaux orange informatique technicien ', 'pc technicien informatique prise ', 'support technicien freelance logiciel ', 'serveur administratif incidents gestion ', 'administratif cisco systeme reseaux ', 'serveur securite administratif systeme ', 'reseaux configuration informaticien installations ', 'reseaux administratif utilisateurs informatique ', 'administratif serveur messagerie windows ', 'reseaux cisco maintenance techniques ', 'support technicien utilisateurs android ', 'licence reseaux vpn cisco ', 'serveur techniques windows administratif ', 'installations maintenance gestion reseaux ', 'distance installations serveur informatique ', 'vmware windows server informatique ', 'technicien server informatique cisco ', 'reseaux informatique mettre gerer ', 'gestion utilisateurs acces sauvegarde ', 'windows serveur reseaux configuration ', 'societes installations informatique technicien ', 'reseaux windows installations comptes ', 'reseaux informatique systeme administratif ', 'reseaux informatique systeme configuration ']), ('cluster_3', ['comptable facturation bancaires comptes ', 'controle comptable mensuel comptes ', 'financiers prestataires comptable directeur ', 'comptable comptes etablissement controle ', 'pilotage controle financiers budget ', 'financiers audit specialisation banque ', 'filiale suivi entites budget ', 'business cree controle strategie ']), ('cluster_4', ['web developpeur developpement applications ', 'integrateur web developpeur stagiaire ', 'developpeur web design css ', 'web c developpeur competence ', 'web developpeur reseaux centrale ', 'developpeur web tant creation ', 'web developpeur complementaires photoshop ', 'web developpeur espace freelance ', 'developpeur android java c ', 'web developpeur etudiant stagiaire ', 'web developpeur devis intranet ', 'web developpeur alternance integrateur ', 'developpeur web photoshop niveau ']), ('cluster_5', ['statistiques reporting outil sas '])])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_core_word_label.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#download talan CVs \n",
    "liste_cv_talan = []\n",
    "liste_files_talan = []\n",
    "path = \"/Users/mehdiregina/FilRouge/Commun/Data_talan\"\n",
    "filenames = sorted(glob(os.path.join(path,\"*.txt\")))\n",
    "print(len(filenames))\n",
    "for file in filenames:\n",
    "    liste_cv_talan.append(open(file).read())\n",
    "    liste_files_talan.append(file.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e6a82ecd68d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliste_cv_talan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "liste_cv_talan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression des saut de lignes\n",
    "liste_cv_talan = [del_line_feed(text).lower() for text in liste_cv_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression de la ponctuation\n",
    "liste_cv_talan_no_punc = [del_punct(text) for text in liste_cv_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion cv french : 0.9940119760479041\n"
     ]
    }
   ],
   "source": [
    "#selectionner seulement cvs fr\n",
    "liste_cv_talan_fr,liste_files_talan_fr = get_cv_langue(liste_cv_talan_no_punc,'french',liste_files_talan)\n",
    "\n",
    "nb_cv = len(liste_cv_talan_no_punc)\n",
    "nb_cv_fr = len(liste_cv_talan_fr)\n",
    "\n",
    "print(\"proportion cv french :\",1- ((nb_cv-nb_cv_fr)/nb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On supprime les caractères étranges, accents et stop words\n",
    "liste_cv_treated_talan = [text_treatment(text) for text in liste_cv_talan_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove stop word\n",
    "liste_cv_talan_no_stop = [remove_stopwords(text,stop_words_main) for text in liste_cv_treated_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bases donnees relationnelles mysql sybase ingenieur amoa formation master travail cooperatif travail reseaux centrale lyon ingenieur centrale lyon specialisation tic projet option creation base gestion connaissances laboratoire recherche ged gestion contenu interface web projet industriel etude flux information production entreprise prosodie competences c c java j ee html jsp javascript shell script php unix windows nt ms experience professionnelle consultant systeme information assistance maitrise ouvrage erdf electricite reseau distribution - projet gec gestion comptages recette preparation recette application etude proposition organisation recette projet mercuri specifications specification application coordination partenaires suivi avancement projet amm suivi prise compte mutuelle contraintes communes projet sar assistance maitrise ouvrage specifications transverse coaching coaching consultants junior consultant systeme information assistance maitrise ouvrage erdf electricite reseau distribution - projet systeme gestion echanges recette unitaire b b recette cas metier execution tests identifies recette fonctionnelle identification tests fonctionnels b b redaction cas test creation jeux donnees execution recette cycle complet preparation plates formes recette preparation jeux donnees redaction scenarios plans test suivi execution homologation reunions definition service homologation preparation plates formes redaction documentation interne modes operatoires controles montee version retour experience externe catalogue tests modes operatoires externes preparation jeux donnees cahier charges automatisation processus selection accompagnement fournisseurs lors campagnes test appui technique fonctionnel suivi quotidien tests reunions lancement bilan pilotage interne equipe lors phases test offre homologation plus creation offre redaction documents presentation suivi tests specification test redaction guides utilisateur outils inclus pack bouchons b b interfaces tri donnees outils transformation fichiers environnement technique unix hp ux shell script mysql oracle webservices soap webmethods integration server bea weblogic applications xml transformation xsl xml schema xpath stagiaire concepteur developpeur atos worldline - projet extranet suivi application push sms objet projet conception extranet mesurer qualite service application envoi sms bancaires etude besoin etude existant formalisation besoin redaction cahier charges detaille redaction specifications techniques conception basee modele mvc modularite vue developpement mutualise vue adapter livrable choix technologies java j ee apache tomcat realisation application developpement tests unitaires fonctionnalites tests systeme evaluation performances qualification application production application procedures livraison production creation systeme alertes suivi exploitation sein equipe applicative creation posteriori module gestion temps reel messages sms desabonnement suite demande client environnement technique unix hp ux shell script c j ee servlets jsp perl mysql sybase apache tomcat rational rose stagiaire concepteur developpeur districhem - stage application objet stage lancement produit prospection supports communication prospection enquete clients redaction contenu technique web stagiaire technicien tunisie micro informatique stage execution objet projet taches equipe techniciens preparation postes travail missions ponctuelles installation reseau formations langues anglais courant arabe bilingue espagnol bases centres interets culture photographie danse musique percussions theatre sport basketball athletisme associations tresorier association tunisiens grandes ecoles lyon membre reseau international jeunes ambassadeurs lyon '"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#facultatif add only for talan cv (delete numbers) -> could be use for the preprocessing in general !\n",
    "liste_cv_talan_clean = [re.sub('[0-9 ]+', ' ', text) for text in liste_cv_talan_no_stop]\n",
    "liste_cv_talan_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 90114 items in vocab_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>competent</th>\n",
       "      <td>competences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sectoriel</th>\n",
       "      <td>sectorielles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financ</th>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sant</th>\n",
       "      <td>sante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serveur</th>\n",
       "      <td>serveurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliqu</th>\n",
       "      <td>applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>progiciel</th>\n",
       "      <td>progiciels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reuter</th>\n",
       "      <td>reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powerplus</th>\n",
       "      <td>powerplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pro</th>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodolog</th>\n",
       "      <td>methodologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xml</th>\n",
       "      <td>xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langag</th>\n",
       "      <td>langages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outil</th>\n",
       "      <td>outils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developp</th>\n",
       "      <td>developpement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>visual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic</th>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html</th>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>materiel</th>\n",
       "      <td>materiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>systemes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploit</th>\n",
       "      <td>exploitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt</th>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bas</th>\n",
       "      <td>bases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donne</th>\n",
       "      <td>donnees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationnel</th>\n",
       "      <td>relationnelles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracl</th>\n",
       "      <td>oracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consult</th>\n",
       "      <td>consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>junior</th>\n",
       "      <td>junior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeux</th>\n",
       "      <td>jeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developp</th>\n",
       "      <td>developpement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requet</th>\n",
       "      <td>requetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sas</th>\n",
       "      <td>sas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environ</th>\n",
       "      <td>environnement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techniqu</th>\n",
       "      <td>technique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sas</th>\n",
       "      <td>sas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepris</th>\n",
       "      <td>entreprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excel</th>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langu</th>\n",
       "      <td>langues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anglais</th>\n",
       "      <td>anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cour</th>\n",
       "      <td>courant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>espagnol</th>\n",
       "      <td>espagnol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notion</th>\n",
       "      <td>notion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centr</th>\n",
       "      <td>centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interet</th>\n",
       "      <td>interets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natat</th>\n",
       "      <td>natation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judo</th>\n",
       "      <td>judo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyag</th>\n",
       "      <td>voyage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usa</th>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexiqu</th>\n",
       "      <td>mexique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>egypt</th>\n",
       "      <td>egypte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qatar</th>\n",
       "      <td>qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tunis</th>\n",
       "      <td>tunisie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maroc</th>\n",
       "      <td>maroc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>espagn</th>\n",
       "      <td>espagne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90114 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      words\n",
       "competent       competences\n",
       "sectoriel      sectorielles\n",
       "financ              finance\n",
       "sant                  sante\n",
       "serveur            serveurs\n",
       "appliqu        applications\n",
       "progiciel        progiciels\n",
       "reuter              reuters\n",
       "powerplus         powerplus\n",
       "pro                     pro\n",
       "methodolog    methodologies\n",
       "xml                     xml\n",
       "langag             langages\n",
       "outil                outils\n",
       "developp      developpement\n",
       "sql                     sql\n",
       "visual               visual\n",
       "basic                 basic\n",
       "html                   html\n",
       "materiel           materiel\n",
       "system             systemes\n",
       "exploit        exploitation\n",
       "window              windows\n",
       "nt                       nt\n",
       "bas                   bases\n",
       "donne               donnees\n",
       "relationnel  relationnelles\n",
       "oracl                oracle\n",
       "consult          consultant\n",
       "junior               junior\n",
       "...                     ...\n",
       "jeux                   jeux\n",
       "test                  tests\n",
       "developp      developpement\n",
       "requet             requetes\n",
       "sas                     sas\n",
       "environ       environnement\n",
       "techniqu          technique\n",
       "sas                     sas\n",
       "entrepris        entreprise\n",
       "excel                 excel\n",
       "access               access\n",
       "langu               langues\n",
       "anglais             anglais\n",
       "cour                courant\n",
       "espagnol           espagnol\n",
       "notion               notion\n",
       "centr               centres\n",
       "interet            interets\n",
       "sport                sports\n",
       "football           football\n",
       "natat              natation\n",
       "judo                   judo\n",
       "voyag                voyage\n",
       "usa                     usa\n",
       "mexiqu              mexique\n",
       "egypt                egypte\n",
       "qatar                 qatar\n",
       "tunis               tunisie\n",
       "maroc                 maroc\n",
       "espagn              espagne\n",
       "\n",
       "[90114 rows x 1 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalvocab_stemmed_talan = []\n",
    "totalvocab_tokenized_talan = []\n",
    "for text in liste_cv_talan_no_stop:\n",
    "    allwords_stemmed = tokenize_and_stem(text) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed_talan.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(text)\n",
    "    totalvocab_tokenized_talan.extend(allwords_tokenized)\n",
    "\n",
    "vocab_frame_talan = pd.DataFrame({'words': totalvocab_tokenized_talan}, index = totalvocab_stemmed_talan)\n",
    "print('there are ' + str(vocab_frame_talan.shape[0]) + ' items in vocab_frame')\n",
    "vocab_frame_talan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehdiregina/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "#TF IDF BOW Representation\n",
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.7,min_df=0.1,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "bow_idf_talan = tf_vect.fit_transform(liste_cv_talan_clean)\n",
    "\n",
    "vocab_liste_talan = tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_liste_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ajout une étape pour supprimer les doublons & shuffle\n",
    "buffer = pd.DataFrame(data=bow_idf_talan.toarray())\n",
    "buffer = shuffle(buffer)\n",
    "buffer.drop_duplicates(inplace=True)\n",
    "\n",
    "new_idx = buffer.index\n",
    "bow_idf_talan = buffer.values\n",
    "liste_files_new = []\n",
    "for idx in new_idx:\n",
    "    liste_files_new.append(liste_files_talan_fr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "-1    112\n",
       " 0     36\n",
       " 1      8\n",
       " 2      8\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs = DBSCAN(eps=0.97, min_samples=6, metric='euclidean', algorithm='auto', leaf_size=30, p=None, n_jobs=1)\n",
    "labels_dbscan = dbs.fit_predict(bow_idf_talan)\n",
    "\n",
    "pd.DataFrame(labels_dbscan,columns=[\"Label\"]).groupby([\"Label\"])[\"Label\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_core_samples = dbs.core_sample_indices_\n",
    "dict_core_idx_label = dict()\n",
    "for label in np.unique(labels_dbscan):\n",
    "    liste_idx_label = []\n",
    "    for idx in idx_core_samples:\n",
    "        if(labels_dbscan[idx])==label:\n",
    "            liste_idx_label.append(idx)\n",
    "    dict_core_idx_label[\"cluster_\"+str(label)] = liste_idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_core_word_label = dict()\n",
    "for key in dict_core_idx_label.keys():\n",
    "    idx = dict_core_idx_label[key]\n",
    "    if len(idx)>0:\n",
    "        liste_cluster_word =list()\n",
    "        for i in idx :\n",
    "            idx_ordered_core = np.argsort(bow_idf_indeed[i])[::-1]\n",
    "            text = \"\"\n",
    "            for j in range(0, 4):  # nombre de motss\n",
    "                text += vocab_frame_indeed.loc[vocab_liste_indeed[idx_ordered_core[j]]].values.tolist()[0][0] + \" \"\n",
    "            liste_cluster_word.append(text)\n",
    "        dict_core_word_label[key] = liste_cluster_word\n",
    "    else :\n",
    "        dict_core_word_label[key] = [\"bruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['management partenariat business strategie ',\n",
       " 'gestionnaires finance structure ecommerce ',\n",
       " 'financiers sap droits humaines ']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_core_word_label[\"cluster_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat non concluant la majorité des CVs appartiennent au bruit, la metric euclidienne ou cosine n'est pas adaptée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
