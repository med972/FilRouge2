{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#TEXT PROCESSING\n",
    "import nltk\n",
    "import re\n",
    "import codecs\n",
    "import unidecode\n",
    "#pip install unidecode\n",
    "import mpld3\n",
    "# pip install mpld3\n",
    "import stop_words\n",
    "# pip install stop-words\n",
    "from nltk import SnowballStemmer, pos_tag, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer,TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import *\n",
    "from sklearn.semi_supervised import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lecture des données **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download cv in a list\n",
    "def load_cv_list(nombre):\n",
    "    path = '../data_indeed/Txt/'\n",
    "    liste_paths = [path+directory for directory in os.listdir(path)]\n",
    "    liste_cv = []\n",
    "    for path in liste_paths :\n",
    "        if \"informaticien\" and \"dba\" and \"chef_de_projet_informatique\" not in path:\n",
    "            filenames = sorted(glob(os.path.join(path,\"*.txt\")))\n",
    "            for file in filenames[:nombre]:\n",
    "                liste_cv.append(open(file).read())\n",
    "    return liste_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 cvs\n"
     ]
    }
   ],
   "source": [
    "liste_cv_indeed = load_cv_list(200)\n",
    "print(len(liste_cv_indeed), \"cvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"INFORMATICIEN DÉVELOPPEMENT ET\\nRÉSEAUX\\n\\nDéveloppeur Intégrateur Web\\n\\nÉragny (95) - Email me on Indeed: indeed.com/r/d7e8913ed00d0384\\n\\nAujourd’hui, je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de\\nmonter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation.\\n\\nEXPÉRIENCE\\n\\nINFORMATICIEN DÉVELOPPEMENT ET RÉSEAUX\\n\\nLeGrandCercle95  -  Éragny (95) -\\n\\nnovembre 2016 - juin 2017\\n\\nInformaticien de l'entreprise, mes missions était de gérer les différent problème dans l'entreprise. Mise en\\nplace d'un antivirus serveur, sauvegarde Nas... Créé et gérer les droits sur l'Active Directory. Paramétrer des\\nclients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en IP fixe.\\n\\nRéajustement du code html et css sur le site grand public selon les normes w3c.\\nCréation d'une source ODBC\\nCréation d'un code en php - sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré\\nen fiche xml.\\nCréation de bannières pour les différents évènements avec photoshop et formation d'une personne sur place\\nau logiciel photoshop.\\n\\nCHARGE DE CLIENTELE\\n\\nEuropcar France Commercial  -  Saint-Ouen-l'Aumône (95) -\\n\\nnovembre 2008 - novembre 2016\\n\\nMes missions principales : \\n\\n- Qualité de service :\\nAssurer l'accueil des clients et le respect de la charte en agence.\\n\\n- Gestion des clients :\\nTraiter l'ensemble des appels téléphoniques.\\nAnalyser les besoins du client.\\nAssurer le suivi de la clientèle.\\n\\n- Logistique et Administratif :\\nS'assurer de la disponibilité des véhicules.\\nGérer l'administratif de l'agence.\\nGestion de la caisse.\\n\\n- Polyvalence\\n\\n\\x0cFormation Développeur Intégrateur Web\\n\\n-\\n\\nseptembre 2015 - juin 2016\\n\\nC.I.F)\\nCentre de formation IFOCOP (8mois)\\n\\n- Création de différents sites. (portfolio)\\n- Présentation d'un site e-commerce créé de A à Z pour l'examen\\n\\nDéveloppeur Web (stage)\\n\\nLe Club des formateurs  -  Éragny (95) -\\n\\nfévrier 2016 - mai 2016\\n\\nDéveloppement d'un site sous Wordpress de A à Z.\\n\\nCommercial stagiaire\\n\\nLAMY Assurance -\\n\\nnovembre 2007 - décembre 2007\\n\\nstagiaire\\n\\nPort Marly accessoires  -  Le Port-Marly (78) -\\n\\nmai 2007 - juin 2007\\n\\nLes Galeries Lafayette Vendeur\\n\\n-\\n\\n2005 - 2006\\n\\nconfection homme) Job étudiant\\n\\nBrice Vendeur\\n\\nPAP Job -\\n\\n2004 - 2004\\n\\nétudiant\\n\\nFORMATION\\n\\nniveau II bac+3 bac+4 en Développeur intégrateur web\\n\\nifocop  -  Éragny (95)\\n\\n2015 - 2016\\n\\n\\x0c\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cv_indeed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des sauts de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[%s]' % '(\\\\n)*(\\\\x0c)*')\n",
    "def del_line_feed(s):  \n",
    "    \"\"\"Delete \\n in the text\"\"\"\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien développement et réseaux  développeur intégrateur web  éragny  95  - email me on indeed: indeed.com/r/d7e8913ed00d0384  aujourd’hui, je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de monter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation.  expérience  informaticien développement et réseaux  legrandcercle95  -  éragny  95  -  novembre 2016 - juin 2017  informaticien de l'entreprise, mes missions était de gérer les différent problème dans l'entreprise. mise en place d'un antivirus serveur, sauvegarde nas... créé et gérer les droits sur l'active directory. paramétrer des clients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en ip fixe.  réajustement du code html et css sur le site grand public selon les normes w3c. création d'une source odbc création d'un code en php - sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré en fiche xml. création de bannières pour les différents évènements avec photoshop et formation d'une personne sur place au logiciel photoshop.  charge de clientele  europcar france commercial  -  saint-ouen-l'aumône  95  -  novembre 2008 - novembre 2016  mes missions principales :   - qualité de service : assurer l'accueil des clients et le respect de la charte en agence.  - gestion des clients : traiter l'ensemble des appels téléphoniques. analyser les besoins du client. assurer le suivi de la clientèle.  - logistique et administratif : s'assurer de la disponibilité des véhicules. gérer l'administratif de l'agence. gestion de la caisse.  - polyvalence   formation développeur intégrateur web  -  septembre 2015 - juin 2016  c.i.f  centre de formation ifocop  8mois   - création de différents sites.  portfolio  - présentation d'un site e-commerce créé de a à z pour l'examen  développeur web  stage   le club des formateurs  -  éragny  95  -  février 2016 - mai 2016  développement d'un site sous wordpress de a à z.  commercial stagiaire  lamy assurance -  novembre 2007 - décembre 2007  stagiaire  port marly accessoires  -  le port-marly  78  -  mai 2007 - juin 2007  les galeries lafayette vendeur  -  2005 - 2006  confection homme  job étudiant  brice vendeur  pap job -  2004 - 2004  étudiant  formation  niveau ii bac+3 bac+4 en développeur intégrateur web  ifocop  -  éragny  95   2015 - 2016   \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cv_indeed = [del_line_feed(text).lower() for text in liste_cv_indeed]\n",
    "liste_cv_indeed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#le maintient de la ponctuation pertube le stop words, apostrophe gérée dans text_treatment\n",
    "regex = re.compile('[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_{|}~')) \n",
    "\n",
    "def del_punct(s):  \n",
    "    \"\"\"Delete punctuation in the text\"\"\"\n",
    "    return regex.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien développement et réseaux  développeur intégrateur web  éragny  95   email me on indeed indeedcomrd7e8913ed00d0384  aujourd’hui je suis en recherche d'une opportunité sur un poste de développeur ou d’intégrateur web afin de monter toujours plus en compétence et d’approfondir les bases solide que j’ai acquis en formation  expérience  informaticien développement et réseaux  legrandcercle95    éragny  95    novembre 2016  juin 2017  informaticien de l'entreprise mes missions était de gérer les différent problème dans l'entreprise mise en place d'un antivirus serveur sauvegarde nas créé et gérer les droits sur l'active directory paramétrer des clients léger ainsi que du matériel informatique comme des imprimantes ou des étiqueteuse en ip fixe  réajustement du code html et css sur le site grand public selon les normes w3c création d'une source odbc création d'un code en php  sql afin de récupéré des données librairie sur un site fournisseur pour les enregistré en fiche xml création de bannières pour les différents évènements avec photoshop et formation d'une personne sur place au logiciel photoshop  charge de clientele  europcar france commercial    saintouenl'aumône  95    novembre 2008  novembre 2016  mes missions principales     qualité de service  assurer l'accueil des clients et le respect de la charte en agence   gestion des clients  traiter l'ensemble des appels téléphoniques analyser les besoins du client assurer le suivi de la clientèle   logistique et administratif  s'assurer de la disponibilité des véhicules gérer l'administratif de l'agence gestion de la caisse   polyvalence   formation développeur intégrateur web    septembre 2015  juin 2016  cif  centre de formation ifocop  8mois    création de différents sites  portfolio   présentation d'un site ecommerce créé de a à z pour l'examen  développeur web  stage   le club des formateurs    éragny  95    février 2016  mai 2016  développement d'un site sous wordpress de a à z  commercial stagiaire  lamy assurance   novembre 2007  décembre 2007  stagiaire  port marly accessoires    le portmarly  78    mai 2007  juin 2007  les galeries lafayette vendeur    2005  2006  confection homme  job étudiant  brice vendeur  pap job   2004  2004  étudiant  formation  niveau ii bac3 bac4 en développeur intégrateur web  ifocop    éragny  95   2015  2016   \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test \n",
    "liste_cv_indeed_no_punc = [del_punct(text) for text in liste_cv_indeed]\n",
    "liste_cv_indeed_no_punc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reconnaissance du langage du CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_languages_ratios(text):\n",
    "    \"\"\"\n",
    "    Calculate probability of given text to be written in several languages and\n",
    "    return a dictionary that looks like {'french': 2, 'spanish': 4, 'english': 0}\n",
    "    \"\"\"\n",
    "\n",
    "    languages_ratios = {}\n",
    "\n",
    "    '''\n",
    "    nltk.wordpunct_tokenize() splits all punctuations into separate tokens\n",
    "    \n",
    "    >>> wordpunct_tokenize(\"That's thirty minutes away. I'll be there in ten.\")\n",
    "    ['That', \"'\", 's', 'thirty', 'minutes', 'away', '.', 'I', \"'\", 'll', 'be', 'there', 'in', 'ten', '.']\n",
    "    '''\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens] #from text get list of word in minuscule\n",
    "\n",
    "    \n",
    "    for language in stopwords.fileids(): # pour chaque langue\n",
    "        stopwords_set = set(stopwords.words(language)) #je mets les stop words du langage dans un set\n",
    "        words_set = set(words) #je mets les mots de mon texte dans un set\n",
    "        #je prends l'intersection entre les mots de mon texte et les mots du stopwords dans le langage donné\n",
    "        common_elements = words_set & stopwords_set\n",
    "        \n",
    "        #je compute mon score comme le nombre d'éléments en communs dictionnaire [langage : score]\n",
    "        languages_ratios[language] = len(common_elements) # language \"score\"\n",
    "\n",
    "    return languages_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mehdiregina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cv_langue(liste_cv, language) :\n",
    "    \"\"\"Return resume witten in the specified language in parameter\"\"\"\n",
    "    liste_2 = []\n",
    "    for cv in liste_cv:\n",
    "        if max(_calculate_languages_ratios(cv),key =_calculate_languages_ratios(cv).get)=='french':\n",
    "            liste_2.append(cv)\n",
    "    return liste_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste_cv_indeed_fr = get_cv_langue(liste_cv_indeed_no_punc,'french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion cv french : 0.704\n"
     ]
    }
   ],
   "source": [
    "nb_cv = len(liste_cv_indeed_no_punc)\n",
    "nb_cv_fr = len(liste_cv_indeed_fr)\n",
    "\n",
    "print(\"proportion cv french :\",1- ((nb_cv-nb_cv_fr)/nb_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocessing du text **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_treatment (text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\x00\", '').replace(\"\\x01\", '').replace(\"\\x02\", '').replace(\"\\x03\", '') \\\n",
    "    .replace(\"\\x04\", '').replace(\"\\x05\", '').replace(\"\\x06\", '').replace(\"\\x07\", '').replace(\"\\x08\", '') \\\n",
    "    .replace(\"\\x0e\", '').replace(\"\\x11\", '').replace(\"\\x12\", '').replace(\"\\x10\", '').replace(\"\\x19\", '') \\\n",
    "    .replace(\"\\x1b\", '').replace(\"\\x14\", '').replace(\"\\x15\", '').replace('/', '').replace('=', '').replace(\"〓\", \"\") \\\n",
    "    .replace(\"»\", \"\").replace(\"«\", \"\").replace(\"¬\", \"\").replace('`', '').replace (\" -\", \"\").replace(\"•\", \"\")\\\n",
    "    .replace(\"l'\", \"\").replace(\"l’\", \"\").replace(\"l´\", \"\").replace(\"d’\", \"\").replace(\"d'\", \"\").replace(\"d´\",\"\")\\\n",
    "    .replace(\"j’\", \"\").replace(\"j'\", \"\").replace(\"j´\",\"\").replace(\"n’\", \"\").replace(\"n'\", \"\").replace(\"n´\",\"\")\\\n",
    "    .replace(\"”\", \"\").replace(\"~\", \"\").replace(\"§\", \"\").replace(\"¨\", \"\").replace(\"©\", \"\").replace(\"›\", \"\")\\\n",
    "    .replace(\"₋\", \"\").replace(\"→\", \"\").replace(\"⇨\", \"\").replace(\"∎\", \"\").replace(\"√\", \"\").replace(\"□\", \"\")\\\n",
    "    .replace(\"*\", \"\").replace(\"&\", \"\").replace(\"►\", \"\").replace(\"◊\", \"\").replace(\"☞\", \"\").replace(\"#\", \"\")\\\n",
    "    .replace(\"%\", \"\").replace(\"❖\", \"\").replace(\"➠\", \"\").replace(\"➢\", \"\").replace(\"\", \"\").replace(\"✓\", \"\") \\\n",
    "    .replace(\"√\", \"\").replace(\"✔\", \"\").replace(\"♦\", \"\").replace(\"◦\", \"\").replace(\"●\", \"\").replace(\"▫\", \"\")\\\n",
    "    .replace(\"▪\", \"\").replace(\"…\", \"\").replace(\"þ\", \"\").replace(\"®\", \"\").replace('', '').replace(\"...\", \"\")\n",
    "    text = unidecode.unidecode(text) # remove accent\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien developpement et reseaux  developpeur integrateur web  eragny  95   email me on indeed indeedcomrd7e8913ed00d0384  aujourhui je suis en recherche une opportunite sur un poste de developpeur ou integrateur web afin de monter toujours plus en competence et approfondir les bases solide que ai acquis en formation  experience  informaticien developpement et reseaux  legrandcercle95    eragny  95    novembre 2016  juin 2017  informaticien de entreprise mes missions etait de gerer les different probleme dans entreprise mise en place un antivirus serveur sauvegarde nas cree et gerer les droits sur active directory parametrer des clients leger ainsi que du materiel informatique comme des imprimantes ou des etiqueteuse en ip fixe  reajustement du code html et css sur le site grand public selon les normes w3c creation une source odbc creation un code en php  sql afin de recupere des donnees librairie sur un site fournisseur pour les enregistre en fiche xml creation de bannieres pour les differents evenements avec photoshop et formation une personne sur place au logiciel photoshop  charge de clientele  europcar france commercial    saintouenaumone  95    novembre 2008  novembre 2016  mes missions principales     qualite de service  assurer accueil des clients et le respect de la charte en agence   gestion des clients  traiter ensemble des appels telephoniques analyser les besoins du client assurer le suivi de la clientele   logistique et administratif  s'assurer de la disponibilite des vehicules gerer administratif de agence gestion de la caisse   polyvalence   formation developpeur integrateur web    septembre 2015  juin 2016  cif  centre de formation ifocop  8mois    creation de differents sites  portfolio   presentation un site ecommerce cree de a a z pour examen  developpeur web  stage   le club des formateurs    eragny  95    fevrier 2016  mai 2016  developpement un site sous wordpress de a a z  commercial stagiaire  lamy assurance   novembre 2007  decembre 2007  stagiaire  port marly accessoires    le portmarly  78    mai 2007  juin 2007  les galeries lafayette vendeur    2005  2006  confection homme  job etudiant  brice vendeur  pap job   2004  2004  etudiant  formation  niveau ii bac3 bac4 en developpeur integrateur web  ifocop    eragny  95   2015  2016   \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On supprime les caractères étranges, accents et stop words\n",
    "liste_cv_indeed_treated = [text_treatment(text) for text in liste_cv_indeed_fr]\n",
    "#test\n",
    "liste_cv_indeed_treated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gestion des stop words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille stop words liste :  413\n"
     ]
    }
   ],
   "source": [
    "#generate stopwords\n",
    "stop_words_py = set(stop_words.get_stop_words('french'))\n",
    "\n",
    "# attention certains stop words pourraient être utiles par la suite\n",
    "stopwords_set_manuel = set([\"an\", \"ans\", 'les', 'moins', 'd\\'un','janvier', 'fevrier', 'février', 'mars', 'avril', \\\n",
    "                 'mai', 'juin', 'juillet', 'aout', 'août', 'septembre', 'octobre', 'novembre', 'décembre', \\\n",
    "                  'decembre', 'moins', 'mise', 'universit\\xc3\\xa9', 'université', 'universite', 'ion','sage', \\\n",
    "                  'o', 'rac', 'vers', 'via', 'p\\xc3\\xa9rim\\xc3\\xa8tre', 'périmètre','et','paris','x',\"\\x00\",\\\n",
    "                          \"\\x01\",\"\\x02\", \"\\x03\",\"\\x04\",\"\\x05\",\"\\x06\",\"\\x07\",\"\\x08\",\"\\x09\",\"\\x0e\",\"\\x0e\",\"\\x11\",\\\n",
    "                           \"\\x12\",\"\\x13\",\"\\x14\",\"\\x15\",\"\\x16\",\"\\x17\",\"\\x18\",\"\\x19\",\"transport\",\"puis\",\"lieu\",\\\n",
    "                           \"adresse\",\"entre\",'dun','dune','chez','boulognebillancourt','bt','etc','recrutement','main',\\\n",
    "                           'and', 'paie','paiement','environ','place','france','paris','mois','mobile','mobiles',\\\n",
    "                           'nanterre','source','sources','concerne','concernant','of','non','notes','rh','minimum',\\\n",
    "                           'maximum','bac','site','sites','actuellement','telephone','telephonique','telephoniques','ca','demenager',\\\n",
    "                           'demenagement','participer','participation','lycee','baccalaureat','lien','liens','in',\\\n",
    "                           'indeed','email','indeedcomrd7e8913ed00d0384','aujourhui','afin','toujours','enterprise',\\\n",
    "                           \"guide\",\"10g\",\"11g\",\"9i\",'ad','v10','v2','v3','v5','v6','v8','v9','talan','talansolutions',\\\n",
    "                           \"aide\",\"ainsi\",'aix','aupres','autour','autres','b','bonne','campagnes','cas','chaine',\\\n",
    "                           'choix','coherence','departement','differentes','differents','divers','fin','for','grandes',\\\n",
    "                           'i','ii','jour','lies','lors','lu','mettre','necessaires','national','nationale','nouvelle',\\\n",
    "                           'nouvelles','parle','partir','partie','permettant','permettte','plusieurs','reel','selon',\\\n",
    "                           'temps','toutes','v'])\n",
    "stop_words_main = stop_words_py | stopwords_set_manuel\n",
    "stop_words_main = list(stop_words_main)\n",
    "print(\"taille stop words liste : \", len(stop_words_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vous',\n",
       " 'eusse',\n",
       " 'aurai',\n",
       " '\\x14',\n",
       " 'elles',\n",
       " 'peu',\n",
       " 'rac',\n",
       " 'fevrier',\n",
       " 'notre',\n",
       " 'eussent',\n",
       " 'minimum',\n",
       " 'eus',\n",
       " 'état',\n",
       " 'a',\n",
       " 'deux',\n",
       " 'tels',\n",
       " 'dos',\n",
       " 'mise',\n",
       " 'devrez',\n",
       " 'environ',\n",
       " 'aussi',\n",
       " 'v6',\n",
       " 'ici',\n",
       " 'la',\n",
       " 'universite',\n",
       " 'o',\n",
       " '\\x00',\n",
       " 'parle',\n",
       " 'site',\n",
       " 'bt',\n",
       " 'indeed',\n",
       " 'bon',\n",
       " 'l',\n",
       " 'nommés',\n",
       " 'nouvelles',\n",
       " 'mois',\n",
       " 'fin',\n",
       " 'source',\n",
       " 'quelles',\n",
       " 'vont',\n",
       " 'avait',\n",
       " 'mes',\n",
       " 'devriez',\n",
       " 'une',\n",
       " 'ne',\n",
       " 'hors',\n",
       " 'soit',\n",
       " 'entre',\n",
       " 't',\n",
       " 'étant',\n",
       " 'fusse',\n",
       " 'auras',\n",
       " 'ta',\n",
       " 'juin',\n",
       " 'nationale',\n",
       " 'national',\n",
       " 'devrions',\n",
       " 'peut',\n",
       " 'parole',\n",
       " 'quels',\n",
       " 'aviez',\n",
       " 'fussions',\n",
       " 'et',\n",
       " 'étaient',\n",
       " 'avant',\n",
       " 'elle',\n",
       " 'seraient',\n",
       " 'fussent',\n",
       " 'suis',\n",
       " 'tout',\n",
       " 'transport',\n",
       " 'etc',\n",
       " 'adresse',\n",
       " 'concernant',\n",
       " 'des',\n",
       " 'aies',\n",
       " 'mobile',\n",
       " 'soyez',\n",
       " 'dun',\n",
       " 'on',\n",
       " 'ils',\n",
       " 'and',\n",
       " 'fait',\n",
       " 'devrait',\n",
       " 'aide',\n",
       " 'sans',\n",
       " 'eût',\n",
       " 'étiez',\n",
       " 'paris',\n",
       " 'eue',\n",
       " 'donc',\n",
       " 'decembre',\n",
       " 'être',\n",
       " 'août',\n",
       " 'ai',\n",
       " 'êtes',\n",
       " 'bac',\n",
       " 'un',\n",
       " 'me',\n",
       " 'aux',\n",
       " 'via',\n",
       " 'lien',\n",
       " 'pas',\n",
       " 'baccalaureat',\n",
       " 'b',\n",
       " 'seulement',\n",
       " 'fois',\n",
       " 'doit',\n",
       " '\\x0e',\n",
       " 'par',\n",
       " 'étés',\n",
       " 'fusses',\n",
       " 'devront',\n",
       " '\\x19',\n",
       " 'aujourhui',\n",
       " 'les',\n",
       " 'dois',\n",
       " 'toujours',\n",
       " 'avais',\n",
       " 'choix',\n",
       " 'ainsi',\n",
       " 'haut',\n",
       " 'tellement',\n",
       " 'ont',\n",
       " 'avions',\n",
       " 'eux',\n",
       " 'talansolutions',\n",
       " 'ou',\n",
       " 'soient',\n",
       " 'bonne',\n",
       " 'tandis',\n",
       " 'demenager',\n",
       " 'qui',\n",
       " 'eut',\n",
       " 'vu',\n",
       " 'autour',\n",
       " 'selon',\n",
       " 'mettre',\n",
       " 'que',\n",
       " 'je',\n",
       " 'dehors',\n",
       " 'dedans',\n",
       " 'dès',\n",
       " 'v3',\n",
       " 'mobiles',\n",
       " 'cet',\n",
       " 'sont',\n",
       " 'ca',\n",
       " 'même',\n",
       " \"d'un\",\n",
       " 'février',\n",
       " 'chaque',\n",
       " 'devoir',\n",
       " 'très',\n",
       " 'maintenant',\n",
       " 'en',\n",
       " 'recrutement',\n",
       " 'parce',\n",
       " 'plusieurs',\n",
       " 'aix',\n",
       " 'est',\n",
       " 'comme',\n",
       " 'devrons',\n",
       " 'ton',\n",
       " 'an',\n",
       " 'nouveau',\n",
       " 'aie',\n",
       " 'eûtes',\n",
       " 'pour',\n",
       " 'nos',\n",
       " 'toutes',\n",
       " 'lui',\n",
       " 'mot',\n",
       " 'ceux',\n",
       " 'participer',\n",
       " 'mais',\n",
       " 'grandes',\n",
       " 'aout',\n",
       " 'aupres',\n",
       " 'v9',\n",
       " 'boulognebillancourt',\n",
       " 'lu',\n",
       " 'nouvelle',\n",
       " 'alors',\n",
       " 'moi',\n",
       " 'eûmes',\n",
       " 'fus',\n",
       " 'v10',\n",
       " 'indeedcomrd7e8913ed00d0384',\n",
       " 'universitÃ©',\n",
       " 'nouveaux',\n",
       " 'es',\n",
       " 'du',\n",
       " 'sois',\n",
       " 'ayez',\n",
       " '\\x04',\n",
       " 'temps',\n",
       " 'n',\n",
       " 'paie',\n",
       " 'lieu',\n",
       " 'jour',\n",
       " 'reel',\n",
       " 'd',\n",
       " 'dans',\n",
       " '10g',\n",
       " 'trop',\n",
       " 'cette',\n",
       " 'plupart',\n",
       " 'vers',\n",
       " 'participation',\n",
       " 'janvier',\n",
       " 'talan',\n",
       " 'soyons',\n",
       " 'de',\n",
       " 'droite',\n",
       " 'telephoniques',\n",
       " '\\x13',\n",
       " 'force',\n",
       " 'si',\n",
       " 'necessaires',\n",
       " 'votre',\n",
       " 'avec',\n",
       " 'il',\n",
       " 'aient',\n",
       " 'au',\n",
       " 'nous',\n",
       " 'cela',\n",
       " 'valeur',\n",
       " 'enterprise',\n",
       " 'ses',\n",
       " 'avez',\n",
       " 'sous',\n",
       " 'quel',\n",
       " '\\x16',\n",
       " '\\x05',\n",
       " '\\x02',\n",
       " '\\x15',\n",
       " 'mon',\n",
       " 'font',\n",
       " 'voit',\n",
       " 'eu',\n",
       " 'pourquoi',\n",
       " 'maximum',\n",
       " 'nommée',\n",
       " 'ad',\n",
       " 'avaient',\n",
       " 'sur',\n",
       " 'faisez',\n",
       " 'voient',\n",
       " 'v',\n",
       " 'of',\n",
       " 'le',\n",
       " 'divers',\n",
       " 'qu',\n",
       " '\\x06',\n",
       " 'partir',\n",
       " 'fussiez',\n",
       " 'partie',\n",
       " 'leur',\n",
       " 'auront',\n",
       " 'faites',\n",
       " 'moins',\n",
       " 'étions',\n",
       " 'ci',\n",
       " 'leurs',\n",
       " 'lycee',\n",
       " 'serais',\n",
       " 'chaine',\n",
       " '\\x03',\n",
       " 'avril',\n",
       " 'autre',\n",
       " 'non',\n",
       " 'sera',\n",
       " 'sujet',\n",
       " 'as',\n",
       " 'personne',\n",
       " 'ait',\n",
       " 'coherence',\n",
       " 'quelle',\n",
       " 'toi',\n",
       " 'serez',\n",
       " 'x',\n",
       " 'aura',\n",
       " 'ayons',\n",
       " 'chez',\n",
       " 'aucun',\n",
       " 'serons',\n",
       " 'for',\n",
       " 'novembre',\n",
       " 'dune',\n",
       " 'octobre',\n",
       " 'ayant',\n",
       " 'demenagement',\n",
       " 'ma',\n",
       " 'se',\n",
       " '11g',\n",
       " 'aurons',\n",
       " 'pÃ©rimÃ¨tre',\n",
       " '\\x08',\n",
       " 'fûmes',\n",
       " 'autres',\n",
       " 'lors',\n",
       " '\\x07',\n",
       " 'auriez',\n",
       " 'departement',\n",
       " 'dù',\n",
       " '9i',\n",
       " 'soi',\n",
       " 'aurions',\n",
       " 'depuis',\n",
       " 'à',\n",
       " '\\x01',\n",
       " 'v2',\n",
       " 'juste',\n",
       " 'ii',\n",
       " 'où',\n",
       " 'nom',\n",
       " 'cas',\n",
       " 'i',\n",
       " 'quand',\n",
       " 'ans',\n",
       " 'actuellement',\n",
       " 'eues',\n",
       " 'là',\n",
       " 'sites',\n",
       " 'auraient',\n",
       " 'serai',\n",
       " 'v5',\n",
       " 'nanterre',\n",
       " 'notes',\n",
       " 'vos',\n",
       " 'mars',\n",
       " '\\x11',\n",
       " 'ceci',\n",
       " 'ni',\n",
       " 'in',\n",
       " 'sources',\n",
       " 'comment',\n",
       " 'main',\n",
       " 'furent',\n",
       " 'car',\n",
       " 'differents',\n",
       " 'rh',\n",
       " 'permettte',\n",
       " 'tes',\n",
       " 'guide',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'été',\n",
       " 'fut',\n",
       " 'septembre',\n",
       " 'aurez',\n",
       " 'sien',\n",
       " 'encore',\n",
       " 'differentes',\n",
       " 'j',\n",
       " '\\x17',\n",
       " 'vois',\n",
       " 'campagnes',\n",
       " 'seras',\n",
       " 'juillet',\n",
       " 'puis',\n",
       " 'avoir',\n",
       " 'telephonique',\n",
       " 'liens',\n",
       " 'nommé',\n",
       " 'eusses',\n",
       " 'fûtes',\n",
       " 'v8',\n",
       " 'email',\n",
       " 'eussiez',\n",
       " 'telephone',\n",
       " 'eussions',\n",
       " 'tu',\n",
       " 'lies',\n",
       " 'ces',\n",
       " 'france',\n",
       " 'eurent',\n",
       " 'seront',\n",
       " 'serait',\n",
       " '\\t',\n",
       " 'avons',\n",
       " 'université',\n",
       " '\\x18',\n",
       " 'ce',\n",
       " 'fût',\n",
       " 'sommes',\n",
       " 'ça',\n",
       " 'début',\n",
       " 'y',\n",
       " 'fais',\n",
       " 'te',\n",
       " 'son',\n",
       " 'étais',\n",
       " '\\x12',\n",
       " 'tous',\n",
       " 'personnes',\n",
       " 'permettant',\n",
       " 'afin',\n",
       " 'aurais',\n",
       " 'périmètre',\n",
       " 'paiement',\n",
       " 'était',\n",
       " 'place',\n",
       " 'm',\n",
       " 'sa',\n",
       " 'mai',\n",
       " 'sage',\n",
       " 'décembre',\n",
       " 'concerne',\n",
       " 'faire',\n",
       " 'aurait',\n",
       " 'ion']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#voir si utile\n",
    "def remove_stopwords(text,stopwords_list):\n",
    "    text_temp = \" \".join(text.split())+\" \"\n",
    "    for word in stopwords_list:\n",
    "        text_temp = text_temp.replace(\" \"+word+\" \", \" \")\n",
    "    return text_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"informaticien developpement reseaux developpeur integrateur web eragny 95 recherche opportunite poste developpeur integrateur web monter plus competence approfondir bases solide acquis formation experience informaticien developpement reseaux legrandcercle95 eragny 95 2016 2017 informaticien entreprise missions etait gerer different probleme entreprise antivirus serveur sauvegarde nas cree gerer droits active directory parametrer clients leger materiel informatique imprimantes etiqueteuse ip fixe reajustement code html css grand public normes w3c creation odbc creation code php sql recupere donnees librairie fournisseur enregistre fiche xml creation bannieres evenements photoshop formation logiciel photoshop charge clientele europcar commercial saintouenaumone 95 2008 2016 missions principales qualite service assurer accueil clients respect charte agence gestion clients traiter ensemble appels analyser besoins client assurer suivi clientele logistique administratif s'assurer disponibilite vehicules gerer administratif agence gestion caisse polyvalence formation developpeur integrateur web 2015 2016 cif centre formation ifocop 8mois creation portfolio presentation ecommerce cree a z examen developpeur web stage club formateurs eragny 95 2016 2016 developpement wordpress a z commercial stagiaire lamy assurance 2007 2007 stagiaire port marly accessoires portmarly 78 2007 2007 galeries lafayette vendeur 2005 2006 confection homme job etudiant brice vendeur pap job 2004 2004 etudiant formation niveau bac3 bac4 developpeur integrateur web ifocop eragny 95 2015 2016 \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test \n",
    "liste_cv_indeed_no_stop = [remove_stopwords(text,stop_words_main) for text in liste_cv_indeed_treated]\n",
    "liste_cv_indeed_no_stop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SnowballStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalvocab_indeed_stemmed = []\n",
    "totalvocab_indeed_tokenized = []\n",
    "for text in liste_cv_indeed_no_stop:\n",
    "    allwords_stemmed = tokenize_and_stem(text) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_indeed_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(text)\n",
    "    totalvocab_indeed_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 302518 items in vocab_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>informaticien</th>\n",
       "      <td>informaticien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developp</th>\n",
       "      <td>developpement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reseau</th>\n",
       "      <td>reseaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developpeur</th>\n",
       "      <td>developpeur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integr</th>\n",
       "      <td>integrateur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eragny</th>\n",
       "      <td>eragny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recherch</th>\n",
       "      <td>recherche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opportunit</th>\n",
       "      <td>opportunite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>poste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developpeur</th>\n",
       "      <td>developpeur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integr</th>\n",
       "      <td>integrateur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mont</th>\n",
       "      <td>monter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plus</th>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competent</th>\n",
       "      <td>competence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approfond</th>\n",
       "      <td>approfondir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bas</th>\n",
       "      <td>bases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solid</th>\n",
       "      <td>solide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquis</th>\n",
       "      <td>acquis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <td>formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experient</th>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informaticien</th>\n",
       "      <td>informaticien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developp</th>\n",
       "      <td>developpement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reseau</th>\n",
       "      <td>reseaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legrandcercle95</th>\n",
       "      <td>legrandcercle95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eragny</th>\n",
       "      <td>eragny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informaticien</th>\n",
       "      <td>informaticien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepris</th>\n",
       "      <td>entreprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mission</th>\n",
       "      <td>missions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saintgobain</th>\n",
       "      <td>saintgobain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass</th>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgg</th>\n",
       "      <td>sgg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avantvent</th>\n",
       "      <td>avantvente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realis</th>\n",
       "      <td>realisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projet</th>\n",
       "      <td>projet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2b</th>\n",
       "      <td>b2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extranet</th>\n",
       "      <td>extranet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarqu</th>\n",
       "      <td>embarquant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>configur</th>\n",
       "      <td>configurateur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selectic</th>\n",
       "      <td>selectica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intershopenfinity</th>\n",
       "      <td>intershopenfinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepar</th>\n",
       "      <td>preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>command</th>\n",
       "      <td>commande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camion</th>\n",
       "      <td>camions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>transportant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verr</th>\n",
       "      <td>verre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributeur</th>\n",
       "      <td>distributeurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projet</th>\n",
       "      <td>projet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niveau</th>\n",
       "      <td>niveau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europ</th>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interfac</th>\n",
       "      <td>interface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sap</th>\n",
       "      <td>sap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bap</th>\n",
       "      <td>bapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heberg</th>\n",
       "      <td>hebergement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkbynet</th>\n",
       "      <td>linkbynet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equip</th>\n",
       "      <td>equipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebusiness</th>\n",
       "      <td>ebusiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sebastien</th>\n",
       "      <td>sebastien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poh</th>\n",
       "      <td>poher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302518 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               words\n",
       "informaticien          informaticien\n",
       "developp               developpement\n",
       "reseau                       reseaux\n",
       "developpeur              developpeur\n",
       "integr                   integrateur\n",
       "web                              web\n",
       "eragny                        eragny\n",
       "recherch                   recherche\n",
       "opportunit               opportunite\n",
       "post                           poste\n",
       "developpeur              developpeur\n",
       "integr                   integrateur\n",
       "web                              web\n",
       "mont                          monter\n",
       "plus                            plus\n",
       "competent                 competence\n",
       "approfond                approfondir\n",
       "bas                            bases\n",
       "solid                         solide\n",
       "acquis                        acquis\n",
       "format                     formation\n",
       "experient                 experience\n",
       "informaticien          informaticien\n",
       "developp               developpement\n",
       "reseau                       reseaux\n",
       "legrandcercle95      legrandcercle95\n",
       "eragny                        eragny\n",
       "informaticien          informaticien\n",
       "entrepris                 entreprise\n",
       "mission                     missions\n",
       "...                              ...\n",
       "saintgobain              saintgobain\n",
       "glass                          glass\n",
       "sgg                              sgg\n",
       "avantvent                 avantvente\n",
       "realis                   realisation\n",
       "projet                        projet\n",
       "b2b                              b2b\n",
       "extranet                    extranet\n",
       "embarqu                   embarquant\n",
       "configur               configurateur\n",
       "selectic                   selectica\n",
       "intershopenfinity  intershopenfinity\n",
       "prepar                   preparation\n",
       "command                     commande\n",
       "camion                       camions\n",
       "transport               transportant\n",
       "verr                           verre\n",
       "distributeur           distributeurs\n",
       "projet                        projet\n",
       "niveau                        niveau\n",
       "europ                         europe\n",
       "interfac                   interface\n",
       "sap                              sap\n",
       "bap                             bapi\n",
       "heberg                   hebergement\n",
       "linkbynet                  linkbynet\n",
       "equip                         equipe\n",
       "ebusiness                  ebusiness\n",
       "sebastien                  sebastien\n",
       "poh                            poher\n",
       "\n",
       "[302518 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame_indeed = pd.DataFrame({'words': totalvocab_indeed_tokenized}, index = totalvocab_indeed_stemmed)\n",
    "print('there are ' + str(vocab_frame_indeed.shape[0]) + ' items in vocab_frame')\n",
    "vocab_frame_indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words    ins\n",
       "Name: in, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame_indeed.loc['in']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HashVectorizer -> Normalize Documents Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACP X KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_hash = hash_vect.fit_transform(liste_cv_no_stop)\n",
    "bow_idf_indeed = tf_vect.fit_transform(liste_cv_indeed_no_stop)\n",
    "\n",
    "vocab_liste_pca_indeed = tf_vect.get_feature_names()\n",
    "\n",
    "l2_norm = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ajout une étape pour supprimer les doublons\n",
    "buffer = pd.DataFrame(data=bow_idf_indeed.toarray())\n",
    "buffer.drop_duplicates(inplace=True)\n",
    "bow_idf_indeed = buffer.values\n",
    "bow_idf_indeed = shuffle(bow_idf_indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acce': 0,\n",
       " 'access': 1,\n",
       " 'accompagn': 2,\n",
       " 'accueil': 3,\n",
       " 'achat': 4,\n",
       " 'acquisit': 5,\n",
       " 'action': 6,\n",
       " 'activ': 7,\n",
       " 'activit': 8,\n",
       " 'adapt': 9,\n",
       " 'administr': 10,\n",
       " 'affair': 11,\n",
       " 'agenc': 12,\n",
       " 'agent': 13,\n",
       " 'agil': 14,\n",
       " 'algorithm': 15,\n",
       " 'altern': 16,\n",
       " 'amelior': 17,\n",
       " 'analys': 18,\n",
       " 'analyst': 19,\n",
       " 'analytic': 20,\n",
       " 'android': 21,\n",
       " 'anglais': 22,\n",
       " 'anim': 23,\n",
       " 'anne': 24,\n",
       " 'annuel': 25,\n",
       " 'anomal': 26,\n",
       " 'appel': 27,\n",
       " 'appliqu': 28,\n",
       " 'applique': 29,\n",
       " 'architect': 30,\n",
       " 'architectur': 31,\n",
       " 'assist': 32,\n",
       " 'associ': 33,\n",
       " 'assur': 34,\n",
       " 'ateli': 35,\n",
       " 'audit': 36,\n",
       " 'automat': 37,\n",
       " 'automatis': 38,\n",
       " 'bancair': 39,\n",
       " 'banqu': 40,\n",
       " 'bas': 41,\n",
       " 'besoin': 42,\n",
       " 'bi': 43,\n",
       " 'big': 44,\n",
       " 'bilan': 45,\n",
       " 'bnp': 46,\n",
       " 'bord': 47,\n",
       " 'budget': 48,\n",
       " 'bureau': 49,\n",
       " 'bureaut': 50,\n",
       " 'business': 51,\n",
       " 'c': 52,\n",
       " 'cabinet': 53,\n",
       " 'cadr': 54,\n",
       " 'cahi': 55,\n",
       " 'caiss': 56,\n",
       " 'calcul': 57,\n",
       " 'cart': 58,\n",
       " 'centr': 59,\n",
       " 'central': 60,\n",
       " 'certif': 61,\n",
       " 'certificationslicens': 62,\n",
       " 'chang': 63,\n",
       " 'charg': 64,\n",
       " 'charge': 65,\n",
       " 'chef': 66,\n",
       " 'cisco': 67,\n",
       " 'class': 68,\n",
       " 'classif': 69,\n",
       " 'cle': 70,\n",
       " 'client': 71,\n",
       " 'clientel': 72,\n",
       " 'cod': 73,\n",
       " 'collabor': 74,\n",
       " 'collect': 75,\n",
       " 'comit': 76,\n",
       " 'command': 77,\n",
       " 'commerc': 78,\n",
       " 'commercial': 79,\n",
       " 'commun': 80,\n",
       " 'competent': 81,\n",
       " 'complementair': 82,\n",
       " 'complet': 83,\n",
       " 'compos': 84,\n",
       " 'compt': 85,\n",
       " 'comptabilit': 86,\n",
       " 'comptabl': 87,\n",
       " 'concept': 88,\n",
       " 'conduit': 89,\n",
       " 'configur': 90,\n",
       " 'connaiss': 91,\n",
       " 'conseil': 92,\n",
       " 'consolid': 93,\n",
       " 'construct': 94,\n",
       " 'consult': 95,\n",
       " 'consulting': 96,\n",
       " 'contact': 97,\n",
       " 'context': 98,\n",
       " 'contrat': 99,\n",
       " 'contribu': 100,\n",
       " 'control': 101,\n",
       " 'coordin': 102,\n",
       " 'correct': 103,\n",
       " 'cour': 104,\n",
       " 'cout': 105,\n",
       " 'cre': 106,\n",
       " 'creation': 107,\n",
       " 'cred': 108,\n",
       " 'crm': 109,\n",
       " 'css': 110,\n",
       " 'cycl': 111,\n",
       " 'dat': 112,\n",
       " 'dba': 113,\n",
       " 'decis': 114,\n",
       " 'decisionnel': 115,\n",
       " 'defens': 116,\n",
       " 'definit': 117,\n",
       " 'del': 118,\n",
       " 'demand': 119,\n",
       " 'deploi': 120,\n",
       " 'design': 121,\n",
       " 'destin': 122,\n",
       " 'detect': 123,\n",
       " 'dev': 124,\n",
       " 'developp': 125,\n",
       " 'developpeur': 126,\n",
       " 'digital': 127,\n",
       " 'diplom': 128,\n",
       " 'direct': 129,\n",
       " 'directeur': 130,\n",
       " 'directory': 131,\n",
       " 'dispos': 132,\n",
       " 'disposit': 133,\n",
       " 'distanc': 134,\n",
       " 'distribu': 135,\n",
       " 'docu': 136,\n",
       " 'document': 137,\n",
       " 'domain': 138,\n",
       " 'donne': 139,\n",
       " 'dont': 140,\n",
       " 'dossi': 141,\n",
       " 'droit': 142,\n",
       " 'dynam': 143,\n",
       " 'e': 144,\n",
       " 'ecol': 145,\n",
       " 'ecommerc': 146,\n",
       " 'econom': 147,\n",
       " 'edit': 148,\n",
       " 'editeur': 149,\n",
       " 'elabor': 150,\n",
       " 'electron': 151,\n",
       " 'emploi': 152,\n",
       " 'encadr': 153,\n",
       " 'ensembl': 154,\n",
       " 'entit': 155,\n",
       " 'entrepris': 156,\n",
       " 'entretien': 157,\n",
       " 'equip': 158,\n",
       " 'erp': 159,\n",
       " 'espac': 160,\n",
       " 'etabl': 161,\n",
       " 'etat': 162,\n",
       " 'etre': 163,\n",
       " 'etud': 164,\n",
       " 'etudi': 165,\n",
       " 'europ': 166,\n",
       " 'europeen': 167,\n",
       " 'evalu': 168,\n",
       " 'even': 169,\n",
       " 'evolu': 170,\n",
       " 'excel': 171,\n",
       " 'execu': 172,\n",
       " 'exist': 173,\n",
       " 'expert': 174,\n",
       " 'expertis': 175,\n",
       " 'exploit': 176,\n",
       " 'extern': 177,\n",
       " 'extract': 178,\n",
       " 'factur': 179,\n",
       " 'fich': 180,\n",
       " 'fichi': 181,\n",
       " 'filial': 182,\n",
       " 'financ': 183,\n",
       " 'financi': 184,\n",
       " 'financier': 185,\n",
       " 'flux': 186,\n",
       " 'fonction': 187,\n",
       " 'fonctionnel': 188,\n",
       " 'form': 189,\n",
       " 'fort': 190,\n",
       " 'fournisseur': 191,\n",
       " 'fr': 192,\n",
       " 'franc': 193,\n",
       " 'freelanc': 194,\n",
       " 'gen': 195,\n",
       " 'gener': 196,\n",
       " 'general': 197,\n",
       " 'ger': 198,\n",
       " 'gestion': 199,\n",
       " 'gestionnair': 200,\n",
       " 'global': 201,\n",
       " 'googl': 202,\n",
       " 'grand': 203,\n",
       " 'graphiqu': 204,\n",
       " 'group': 205,\n",
       " 'html': 206,\n",
       " 'humain': 207,\n",
       " 'ibm': 208,\n",
       " 'identif': 209,\n",
       " 'imag': 210,\n",
       " 'impact': 211,\n",
       " 'implement': 212,\n",
       " 'import': 213,\n",
       " 'incident': 214,\n",
       " 'indiqu': 215,\n",
       " 'industr': 216,\n",
       " 'industriel': 217,\n",
       " 'inform': 218,\n",
       " 'informat': 219,\n",
       " 'informaticien': 220,\n",
       " 'infrastructur': 221,\n",
       " 'ingenier': 222,\n",
       " 'ingenieur': 223,\n",
       " 'innov': 224,\n",
       " 'install': 225,\n",
       " 'institut': 226,\n",
       " 'integr': 227,\n",
       " 'intelligent': 228,\n",
       " 'interet': 229,\n",
       " 'interfac': 230,\n",
       " 'intern': 231,\n",
       " 'international': 232,\n",
       " 'internet': 233,\n",
       " 'intervent': 234,\n",
       " 'intranet': 235,\n",
       " 'ip': 236,\n",
       " 'it': 237,\n",
       " 'jav': 238,\n",
       " 'javascript': 239,\n",
       " 'junior': 240,\n",
       " 'jurid': 241,\n",
       " 'lanc': 242,\n",
       " 'langag': 243,\n",
       " 'langu': 244,\n",
       " 'lead': 245,\n",
       " 'learning': 246,\n",
       " 'licenc': 247,\n",
       " 'lign': 248,\n",
       " 'linux': 249,\n",
       " 'livraison': 250,\n",
       " 'local': 251,\n",
       " 'logiciel': 252,\n",
       " 'logist': 253,\n",
       " 'machin': 254,\n",
       " 'mainten': 255,\n",
       " 'maitris': 256,\n",
       " 'manag': 257,\n",
       " 'march': 258,\n",
       " 'marketing': 259,\n",
       " 'marqu': 260,\n",
       " 'mast': 261,\n",
       " 'materiel': 262,\n",
       " 'mathemat': 263,\n",
       " 'medi': 264,\n",
       " 'membr': 265,\n",
       " 'mensuel': 266,\n",
       " 'messager': 267,\n",
       " 'mesur': 268,\n",
       " 'method': 269,\n",
       " 'methodolog': 270,\n",
       " 'meti': 271,\n",
       " 'microsoft': 272,\n",
       " 'migrat': 273,\n",
       " 'mis': 274,\n",
       " 'mission': 275,\n",
       " 'mo': 276,\n",
       " 'mod': 277,\n",
       " 'model': 278,\n",
       " 'modelis': 279,\n",
       " 'modul': 280,\n",
       " 'moyen': 281,\n",
       " 'mysql': 282,\n",
       " 'negoci': 283,\n",
       " 'net': 284,\n",
       " 'new': 285,\n",
       " 'niveau': 286,\n",
       " 'norm': 287,\n",
       " 'numer': 288,\n",
       " 'object': 289,\n",
       " 'objet': 290,\n",
       " 'oeuvr': 291,\n",
       " 'offic': 292,\n",
       " 'offre': 293,\n",
       " 'oper': 294,\n",
       " 'operationnel': 295,\n",
       " 'opportunit': 296,\n",
       " 'optimis': 297,\n",
       " 'oracl': 298,\n",
       " 'orang': 299,\n",
       " 'organis': 300,\n",
       " 'os': 301,\n",
       " 'outil': 302,\n",
       " 'pack': 303,\n",
       " 'parametrag': 304,\n",
       " 'parc': 305,\n",
       " 'parcour': 306,\n",
       " 'partenair': 307,\n",
       " 'partenariat': 308,\n",
       " 'pay': 309,\n",
       " 'pc': 310,\n",
       " 'perform': 311,\n",
       " 'personnel': 312,\n",
       " 'phas': 313,\n",
       " 'photoshop': 314,\n",
       " 'php': 315,\n",
       " 'physiqu': 316,\n",
       " 'pilot': 317,\n",
       " 'pilotag': 318,\n",
       " 'plan': 319,\n",
       " 'planif': 320,\n",
       " 'planning': 321,\n",
       " 'plateform': 322,\n",
       " 'plsql': 323,\n",
       " 'plus': 324,\n",
       " 'point': 325,\n",
       " 'pol': 326,\n",
       " 'polit': 327,\n",
       " 'portefeuill': 328,\n",
       " 'post': 329,\n",
       " 'pow': 330,\n",
       " 'powerpoint': 331,\n",
       " 'pratiqu': 332,\n",
       " 'prepar': 333,\n",
       " 'present': 334,\n",
       " 'prestat': 335,\n",
       " 'prestatair': 336,\n",
       " 'principal': 337,\n",
       " 'pris': 338,\n",
       " 'prix': 339,\n",
       " 'problem': 340,\n",
       " 'procedur': 341,\n",
       " 'process': 342,\n",
       " 'processus': 343,\n",
       " 'product': 344,\n",
       " 'produit': 345,\n",
       " 'professionnel': 346,\n",
       " 'profil': 347,\n",
       " 'progiciel': 348,\n",
       " 'programm': 349,\n",
       " 'project': 350,\n",
       " 'projet': 351,\n",
       " 'propos': 352,\n",
       " 'proposit': 353,\n",
       " 'prospect': 354,\n",
       " 'public': 355,\n",
       " 'publiqu': 356,\n",
       " 'python': 357,\n",
       " 'qualif': 358,\n",
       " 'qualit': 359,\n",
       " 'quotidien': 360,\n",
       " 'r': 361,\n",
       " 'rapport': 362,\n",
       " 'realis': 363,\n",
       " 'recept': 364,\n",
       " 'recet': 365,\n",
       " 'recherch': 366,\n",
       " 'recommand': 367,\n",
       " 'recueil': 368,\n",
       " 'redact': 369,\n",
       " 'referent': 370,\n",
       " 'referentiel': 371,\n",
       " 'refont': 372,\n",
       " 'regl': 373,\n",
       " 'relat': 374,\n",
       " 'repons': 375,\n",
       " 'reporting': 376,\n",
       " 'requet': 377,\n",
       " 'reseau': 378,\n",
       " 'resolu': 379,\n",
       " 'respect': 380,\n",
       " 'respons': 381,\n",
       " 'responsabilit': 382,\n",
       " 'ressourc': 383,\n",
       " 'restaur': 384,\n",
       " 'resultat': 385,\n",
       " 'reunion': 386,\n",
       " 'revu': 387,\n",
       " 'risqu': 388,\n",
       " 'sais': 389,\n",
       " 'sant': 390,\n",
       " 'sap': 391,\n",
       " 'sas': 392,\n",
       " 'sauvegard': 393,\n",
       " 'school': 394,\n",
       " 'scienc': 395,\n",
       " 'scientist': 396,\n",
       " 'script': 397,\n",
       " 'secteur': 398,\n",
       " 'securis': 399,\n",
       " 'securit': 400,\n",
       " 'sein': 401,\n",
       " 'select': 402,\n",
       " 'senior': 403,\n",
       " 'serv': 404,\n",
       " 'serveur': 405,\n",
       " 'servic': 406,\n",
       " 'shel': 407,\n",
       " 'social': 408,\n",
       " 'societ': 409,\n",
       " 'softwar': 410,\n",
       " 'solut': 411,\n",
       " 'specialis': 412,\n",
       " 'specif': 413,\n",
       " 'sql': 414,\n",
       " 'stag': 415,\n",
       " 'stagiair': 416,\n",
       " 'standard': 417,\n",
       " 'statist': 418,\n",
       " 'stock': 419,\n",
       " 'strateg': 420,\n",
       " 'structur': 421,\n",
       " 'studio': 422,\n",
       " 'suit': 423,\n",
       " 'suiv': 424,\n",
       " 'superieur': 425,\n",
       " 'supervis': 426,\n",
       " 'support': 427,\n",
       " 'surveil': 428,\n",
       " 'synthes': 429,\n",
       " 'system': 430,\n",
       " 'tableau': 431,\n",
       " 'tach': 432,\n",
       " 'tant': 433,\n",
       " 'technicien': 434,\n",
       " 'techniqu': 435,\n",
       " 'technolog': 436,\n",
       " 'telecom': 437,\n",
       " 'telephon': 438,\n",
       " 'test': 439,\n",
       " 'to': 440,\n",
       " 'trait': 441,\n",
       " 'transfert': 442,\n",
       " 'transform': 443,\n",
       " 'travail': 444,\n",
       " 'travaill': 445,\n",
       " 'traval': 446,\n",
       " 'typ': 447,\n",
       " 'uml': 448,\n",
       " 'university': 449,\n",
       " 'unix': 450,\n",
       " 'utilis': 451,\n",
       " 'valid': 452,\n",
       " 'vba': 453,\n",
       " 'veil': 454,\n",
       " 'vent': 455,\n",
       " 'verif': 456,\n",
       " 'version': 457,\n",
       " 'vi': 458,\n",
       " 'visual': 459,\n",
       " 'vmwar': 460,\n",
       " 'vpn': 461,\n",
       " 'web': 462,\n",
       " 'window': 463,\n",
       " 'word': 464,\n",
       " 'xml': 465}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibilité de rebasculer dans l'espace des mots\n",
    "Puis on ordonne de manière décroissante les vecteurs de coefficients pour chaque cluster\n",
    "On récupère les indices des mots aux plus grands coefficients pour chaque cluster\n",
    "Via l'attribut vocabulaire du tf_idf vec on affiche les mots ayant les plus grand coeff pour chaque cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kmeans_cluster_words_lsa(bow_idf,lsa_number,cluster_number,word_number,vocab_frame,vocab_liste):\n",
    "    \n",
    "    #implement LSA\n",
    "    svd = TruncatedSVD(lsa_number)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    bow_idf_reduced_lsa = lsa.fit_transform(bow_idf)\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "    \n",
    "    #clustering using kmeans\n",
    "    n_class = cluster_number\n",
    "    km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "    km.fit(bow_idf_reduced_lsa)\n",
    "\n",
    "    #cluster centroid lsa\n",
    "    cluster_centroids_lsa = km.cluster_centers_\n",
    "    liste_cluster_word=[]\n",
    "    \n",
    "    #via l'opération inveserse je rebascule les centroids dans l'espace des mots \n",
    "    original_space_centroids = svd.inverse_transform(cluster_centroids_lsa)\n",
    "    #ordre decroissant pour chaque cluster les indices des mots à plus forte corrélation\n",
    "    idx_ordered_centroids = np.argsort(original_space_centroids,axis=1)[:,::-1] \n",
    "    \n",
    "    for i in range(0,cluster_centroids_lsa.shape[0]): #nombre de clusters\n",
    "        text=\"\"\n",
    "        for j in range(0,word_number): #nombre de mots\n",
    "            text+= vocab_frame.loc[vocab_liste[idx_ordered_centroids[i,j]]].values.tolist()[0][0]+ \" \"\n",
    "        liste_cluster_word.append(text)\n",
    "        \n",
    "    return bow_idf_reduced_lsa, liste_cluster_word, km.labels_, cluster_centroids_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 73%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['oracle administratif serveur bases systeme reseaux ',\n",
       " 'marketing commercial management business strategie clients ',\n",
       " 'data scientist donnees statistiques r python ',\n",
       " 'gestion projets suivi clients management equipe ',\n",
       " 'informatique developpeur informaticien web c stage ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_idf_reduced_lsa_indeed, liste_cluster_word_lsa_indeed, labels_lsa_indeed,cluster_centroids_lsa_indeed=get_kmeans_cluster_words_lsa(bow_idf_indeed,150,5,6,vocab_frame_indeed,vocab_liste_pca_indeed)\n",
    "liste_cluster_word_lsa_indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NMF X KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on part d'un bag of words tf-idf\n",
    "tf_vect_2 = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "\n",
    "bow_idf_2 = tf_vect_2.fit_transform(liste_cv_indeed_no_stop)\n",
    "\n",
    "vocab_liste_nmf_indeed = tf_vect_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster centers visualization\n",
    "def get_kmeans_cluster_words_nmf(bow_idf,nmf_number,cluster_number,word_number,vocab_frame,vocab_liste):\n",
    "    #implement NMF\n",
    "    print(\"Fitting the NMF model on with n_samples = \"+str(bow_idf.shape[0])+ \" and n_features = \"+str(bow_idf.shape[1]))\n",
    "    nmf = NMF(n_components=nmf_number).fit(bow_idf) \n",
    "    \n",
    "    liste_topic = []\n",
    "    for topic_idx, topic in enumerate(nmf.components_):\n",
    "        #explain each topix with the words with the strongest coeff\n",
    "        liste_topic.append(\" \".join([vocab_frame.loc[vocab_liste[i]].values.tolist()[0][0]  for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    \n",
    "    #get text matrix in nmf topic space\n",
    "    bow_idf_reduced_nmf = nmf.fit_transform(bow_idf)\n",
    "    bow_idf_reduced_nmf_normalized = l2_norm.fit_transform(bow_idf_reduced_nmf) #l2 observation normalization\n",
    "    \n",
    "    #clustering using kmeans\n",
    "    n_class = cluster_number\n",
    "    km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "    km.fit(bow_idf_reduced_nmf_normalized)\n",
    "\n",
    "    #cluster centroid nmf\n",
    "    cluster_centroids_nmf = km.cluster_centers_\n",
    "    \n",
    "    liste_cluster_word=[]\n",
    "    \n",
    "    #via l'opération inveserse je rebascule les centroids dans l'espace des mots !!!\n",
    "    original_space_centroids = nmf.inverse_transform(cluster_centroids_nmf)\n",
    "    #ordre decroissant pour chaque cluster les indices des mots à plus forte corrélation\n",
    "    idx_ordered_centroids = np.argsort(original_space_centroids,axis=1)[:,::-1] \n",
    "    \n",
    "    for i in range(0,cluster_centroids_nmf.shape[0]): #nombre de clusters\n",
    "        text=\"\"\n",
    "        for j in range(0,word_number): #nombre de mots\n",
    "            text+= vocab_frame.loc[vocab_liste[idx_ordered_centroids[i,j]]].values.tolist()[0][0]+ \" \"\n",
    "        liste_cluster_word.append(text)\n",
    "        \n",
    "    return bow_idf_reduced_nmf_normalized, liste_topic, liste_cluster_word, km.labels_, cluster_centroids_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model on with n_samples = 1408 and n_features = 466\n"
     ]
    }
   ],
   "source": [
    "bow_idf_reduced_nmf_indeed, liste_topic, liste_cluster_nmf_indeed, labels_nmf_indeed, cluster_centroid_nmf_indeed = get_kmeans_cluster_words_nmf(bow_idf_2,150,5,6,vocab_frame_indeed,vocab_liste_nmf_indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gestion contrat planification parc actions prestataires changement organisations entites ensemble',\n",
       " 'scientist data python juniors certificationslicenses decision automatiques recommandations parcours complementaires',\n",
       " 'sas data donnees decisionnel recueil construction sql banque existants calcul',\n",
       " 'oracle bases migrations version sauvegarde suite erp plsql performances expert',\n",
       " 'web javascript conception cree espace internet intranet css lignes devis',\n",
       " 'donnees bases optimisation requetes conception sql interfaces documentation importe generant',\n",
       " 'marketing evenements direction veille digital leader operationnel partenaires construction actions',\n",
       " 'creation sauvegarde fichiers restauration telephonie procedure fournisseur mis internet pc',\n",
       " 'societes sein travaux internet generale niveau filiale interventions interets professionnelles',\n",
       " 'management project business europe global interne selection operationnel changement budget',\n",
       " 'administratif vmware fichiers plateforme messagerie parc personnel facturation installations connaissances',\n",
       " 'marches offres opportunite defense appels quotidien francais prix public secteurs',\n",
       " 'stage pack cles diplome tant complementaires industrielle professionnelles existants e',\n",
       " 'projets conduite externes changement interne documentation principales methodologie generale portefeuille',\n",
       " 'chargee entretien profils selection besoins relations contrat cabinet physique qualifie',\n",
       " 'informaticien locaux maitrise information complementaires genie materiel professionnelles industrielle expert',\n",
       " 'ingenieur genie conception profils diplome cabinet xml ecole devis generant',\n",
       " 'php javascript competence uml information diplome sql plateforme complementaires juniors',\n",
       " 'sap module process erp outil leader implementation migrations reporting tant',\n",
       " 'comptable comptabilite cabinet expertise etablissement bancaires audit comptes etat commerce',\n",
       " 'assistant reception annees reunions verification bancaires presentation sante dossiers taches',\n",
       " 'serveur migrations directory active sauvegarde parc taches vmware deploiements plateforme',\n",
       " 'reseaux cisco vpn ip materiel telephonie superviser parc systeme acces',\n",
       " 'net studio visual ingenierie pc interfaces agile automatiques edition outil',\n",
       " 'linux vmware freelance cartes automatisation securisation server python os physique',\n",
       " 'stagiaire appliquees erp electronique banque professionnelles automatiques centre cree certificationslicenses',\n",
       " 'senior module principales extraction cahiers elaborer europeen execution existants interne',\n",
       " 'sql server rapports plsql visual project microsoft fonctionnement procedure decisionnel',\n",
       " 'economie juniors pays school veille etablissement intelligence licence construction europeen',\n",
       " 'word excel powerpoint maitrise competence access bureautique metiers complementaires connaissances',\n",
       " 'communication relations organisations evenements partenariat interne externes agence chargee publications',\n",
       " 'infrastructures architecture vmware refonte changement deploiements ensemble migrations ingenierie acces',\n",
       " 'developpement conception specifications code outil script plsql existants interfaces professionnelles',\n",
       " 'informatique parc licence complementaires information suite materiel institut industrielle connaissances',\n",
       " 'logistique stocks flux livraison reception amelioration international vente commerce materiel',\n",
       " 'programme langage visual extraction bureautique courant pointe acquisition acces industrie',\n",
       " 'learning machines python sciences competence diplome construction university sql tableaux',\n",
       " 'applications code normes intranet fonctionnelle oeuvre licence modes lignes existants',\n",
       " 'intelligence business decisionnel decision donnees tableaux information modelisation objectifs recueil',\n",
       " 'to new industrie contribution stocks evolutions complets global documentation process',\n",
       " 'design interfaces freelance architecture studio niveau lignes proposer edition information',\n",
       " 'c competence python langage complementaires visual information classes vba bureautique',\n",
       " 'entreprise internet industrie juniors diplome accompagnement personnel competence relations organisations',\n",
       " 'developpeur competence devis numerique freelance tant active python courant css',\n",
       " 'redaction dossiers entretien lignes fiche recueil documents procedure specifications proposition',\n",
       " 'algorithme classification valider implementation detecter probleme standardistes courant construction e',\n",
       " 'conseil vente defense expertise suite internet access identification entretien lignes',\n",
       " 'ecole superieur electronique sciences institut diplome commerce information classes genie',\n",
       " 'financiers financieres audit generale acquisition credit presentation banque business plans',\n",
       " 'support niveau migrations software outil procedure demandes materiel banque resolution',\n",
       " 'windows server vmware directory active os internet sauvegarde bureautique distance',\n",
       " 'coordination international plannings organisations interfaces budget cadre planification fournisseur evenements',\n",
       " 'unix plsql shell script systeme procedure progiciel superviser optimisation oracle',\n",
       " 'realisation conception intranet outil agence travaux numerique lignes evolutions encadrement',\n",
       " 'production recette mis caisse agence credit changement lignes unix anomalies',\n",
       " 'strategie veille international transformateur activite industrie information politique europe synthese',\n",
       " 'humaines ressources personnel direction dossiers relations profils bilan entretien generale',\n",
       " 'poste travail niveau metiers besoins atelier appels deploiements contact competence',\n",
       " 'risques credit defense banque generale audit portefeuille operationnel bancaires calcul',\n",
       " 'commande preparateur livraison reception facturation restauration demandes devis personnel contact',\n",
       " 'tests valider automatisation execution cartes anomalies electronique assurer cahiers intranet',\n",
       " 'directeur direction activite budget consulting oeuvre generale transformateur domaine encadrement',\n",
       " 'digital media agence new recommandations internet transformateur sociale poles business',\n",
       " 'groupes filiale international operationnel entites performances europe politique process cadre',\n",
       " 'comptes grand resultat annuel bnp business ensemble public portefeuille specifications',\n",
       " 'gerer assurer cree respect surveillance pilote proposer evenements etre plus',\n",
       " 'charge cahiers prise fr construction fiche banque entretien elaborer synthese',\n",
       " 'office microsoft pack competence complementaires active information suite certificationslicenses project',\n",
       " 'google analytics suite performances internet digital prix profils script resultat',\n",
       " 'equipe encadrement cadre membre delais agile principales plus activite documents',\n",
       " 'missions mesurer taches cadre contextes progiciel diplome appels anglais forme',\n",
       " 'accueil reception caisse stocks classes organisations physique vente appels taches',\n",
       " 'android maitrise studio software interets java agile secteurs stocks fichiers',\n",
       " 'mysql sciences access script os requetes xml restauration uml python',\n",
       " 'data big donnees leader sciences analytics membre ingenierie uml learning',\n",
       " 'solutions deploiements besoins partenaires proposition metiers externes evolutions cles recueil',\n",
       " 'definition accompagnement offres oeuvre process freelance plans cadre expert objectifs',\n",
       " 'vba excel reporting tableaux access bord automatisation interne outil rapports',\n",
       " 'moe accompagnement recette contextes assurer cahiers relations changement editeur generale',\n",
       " 'analyste data business certificationslicenses interne excel presentation proposer vi quotidien',\n",
       " 'controle mensuel reporting elaborer budget couts activite optimisation valider interne',\n",
       " 'centre version restauration messagerie documents interets bases dont compose calcul',\n",
       " 'techniques valider procedure acces mis leader refonte contextes documents referente',\n",
       " 'responsabilites competence prestataires probleme plus caisse animation comptabilite plsql organisations',\n",
       " 'responsable encadrement refonte pays membre europe leader progiciel access societes',\n",
       " 'technicien pc interventions materiel superieur prise distance electronique directory societes',\n",
       " 'langues anglais francais courant niveau international complementaires competence institut information',\n",
       " 'logiciel materiel professionnelles editeur adapter ingenierie maitrise domaine devis complementaires',\n",
       " 'pilotage comites animation direction budget prestataires interne organisations plannings activite',\n",
       " 'service etat global organisations defense pilote direction clients agence offres',\n",
       " 'collaborateurs entretien accompagnement interne organisations oeuvre plus relations international cabinet',\n",
       " 'etudes institut elaborer impacts synthese disposition conception travaux veille implementation',\n",
       " 'etudiant association animation vi membre anglais accompagnement poles encadrement evenements',\n",
       " 'it oeuvre cisco project deploiements offres software generale freelance parc',\n",
       " 'technologies veille activite outil connaissances numerique superieur objectifs modelisation uml',\n",
       " 'html css langage php sql caisse xml genie etudiant complementaires',\n",
       " 'biais decisionnel tableaux power modelisation taches data bureau juniors rapports',\n",
       " 'innovantes partenariat animation business contrat industrie transformateur organisations impacts atelier',\n",
       " 'suivi activite assurer reporting reunions outil demandes dossiers valider facturation',\n",
       " 'analyser performances donnees financieres rapports resultat besoins extraction outil opportunite',\n",
       " 'sociale bilan contrat politique accompagnement annuel cadre preparateur evenements poles',\n",
       " 'incidents resolution deploiements probleme niveau connaissances demandes changement prise outil',\n",
       " 'r langage analyser python learning association dont regles outil pack',\n",
       " 'recherche information synthese rapports performances veille master alternance specialisation industrie',\n",
       " 'graphiques conception freelance edition maitrise studio refonte pratiques generale agence',\n",
       " 'modeles modelisation implementation resultat pratiques conception fonctionnement type orange impacts',\n",
       " 'dba performances expertise requetes sauvegarde restauration sql optimisation audit surveillance',\n",
       " 'securite audit acces regles securisation vpn planification competence cisco architecture',\n",
       " 'crm outil reporting pilote leader access business consolider consulting deploiements',\n",
       " 'achats fournisseur negociation stocks collecte delais commerce europe generale principales',\n",
       " 'clients portefeuille appels relations prospection besoins reponses interne prise proposition',\n",
       " 'chef annees plannings agile objets juniors elaborer internet besoins fournisseur',\n",
       " 'photoshop alternance numerique os animation travaux bureautique css xml competence',\n",
       " 'clientele prospection relations collecte direction vente resultat appels specialisation expert',\n",
       " 'fonctionnelle specifications recette besoins metiers evolutions recueil atelier planification animation',\n",
       " 'ecommerce erp module travaille visual poles bases bureau appels domaine',\n",
       " 'processus amelioration optimisation changement rapports operationnel identification presentation conception modelisation',\n",
       " 'commercial vente prospection offres negociation business portefeuille poles devis proposition',\n",
       " 'finance banque deploiements metiers process structure bancaires comptabilite generale domaine',\n",
       " 'systeme information electronique erp plateforme microsoft domaine messagerie certification automatiques',\n",
       " 'referentiel courant metiers niveau audit reporting interventions relations bnp maitrise',\n",
       " 'exploitation superviser outil systeme sauvegarde filiale bureau automatisation fr procedure',\n",
       " 'gestionnaires comptabilite portefeuille etablissement personnel etat disposition travaux comptes expertise',\n",
       " 'methodes outil agile espace decision annees cycles classification principales proposer',\n",
       " 'architecte architecture methodologie plateforme migrations power expert conception outil audit',\n",
       " 'java conception objets uml ingenierie agile xml javascript langage code',\n",
       " 'e dispose importe fr francais competence travail html objets travaux',\n",
       " 'affaires offres europeen publications prospection public direction negociation politique proposition',\n",
       " 'installations pc distance poste prise type interventions surveillance parametrage bureau',\n",
       " 'produits vente prix lance outil fiche contribution marques veille industrie',\n",
       " 'emploi professionnelles animation licence numerique atelier caisse competence maitrise dynamique',\n",
       " 'operation operationnel evaluation locaux sante reception flux couts quotidien acquisition',\n",
       " 'marques plans elaborer pointe lance cles operationnel presentation budget vente',\n",
       " 'integrateur dynamique type contextes ecole compose refonte fonctionnement module personnel',\n",
       " 'utilisateurs parametrage distance prise fonctionnement plus objectifs interfaces module materiel',\n",
       " 'configuration cisco ip licence directory migrations vpn deploiements active superviser',\n",
       " 'image execution etablissement documents studio edition calcul implementation transformateur taches',\n",
       " 'consultant consulting cabinet prestation specialisation accompagnement audit secteurs conduite certification',\n",
       " 'mathematiques appliquees ingenierie licence sciences optimisation modelisation calcul publications objectifs',\n",
       " 'master licence sciences sante annees automatiques active modelisation etudiant software',\n",
       " 'statistiques modelisation classification donnees tableaux indicateurs decision decisionnel sql dynamique',\n",
       " 'droits juridiques contrat maitrise negociation cabinet relations acquisition dossiers identification',\n",
       " 'maintenance materiel corrective telephonie evolutions access parc progiciel deploiements automatiques',\n",
       " 'ibm expert bancaires analytics interne plateforme tant plannings big progiciel',\n",
       " 'saisie dossiers facturation classes comptabilite etablissement documents standardistes preparateur prise',\n",
       " 'qualite oeuvre organisations pilote normes animation process plans fournisseur mis',\n",
       " 'agent project electronique surveillance juniors travaille leader physique dynamique industrielle',\n",
       " 'traiter demandes information numerique donnees modelisation dossiers fichiers appels assurer',\n",
       " 'telecom orange diplome plateforme detecter python direction certificationslicenses ingenierie competence',\n",
       " 'business international university school sciences global commerce institut rapports juniors']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projets gestion management clients marketing suivi ',\n",
       " 'gestion controle suivi projets analyser reporting ',\n",
       " 'informatique informaticien reseaux technicien systeme administratif ',\n",
       " 'data scientist developpeur web donnees stage ',\n",
       " 'oracle bases dba donnees production administratif ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cluster_nmf_indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDEED SEMI-SUPERVISED AUTOMATIC LABELLING (Manual implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get observations cluster distrib\n",
    "X_texts = [liste_cv_indeed_no_stop[i] for i in buffer.index] #all textes sans doublons\n",
    "X_idf_reduced = bow_idf_reduced_lsa_indeed #all idf matrix sans doublons\n",
    "y_cluster_pca = labels_lsa_indeed #labels correspondants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_0': 202,\n",
       " 'label_1': 156,\n",
       " 'label_2': 146,\n",
       " 'label_3': 376,\n",
       " 'label_4': 313}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_res = dict()\n",
    "for i in np.unique(y_cluster_pca):\n",
    "    dict_res[\"label_\"+str(i)] = len(np.where(y_cluster_pca == i)[0])\n",
    "dict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons dans un premiers temps les x observations les plus proche du cluster centroid au sens de la cosine similarity et attribuons leur le label du cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_closest_points(nb_points,X,labels,cluster_centroids):\n",
    "    distance_idx = np.zeros((len(np.unique(labels)),nb_points))\n",
    "    for i in np.unique(labels):\n",
    "        buffer_2 = euclidean_distances(X,np.transpose(cluster_centroids[i].reshape(-1,1)))\n",
    "        distance_idx[i] = np.argsort(buffer_2,axis=0)[:nb_points].reshape(-1,)\n",
    "    return distance_idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 640, 1030, 1038,  994,  840, 1163, 1088,  855, 1045,  634,  989,\n",
       "         838,  458,  105,  532],\n",
       "       [ 879,  416,  439,  749,  506,    4, 1127,  127,  210,   18, 1159,\n",
       "         310,  222,  619,  169],\n",
       "       [ 673, 1061, 1190,  821,  444,  239,  549,  702, 1065,  211,  703,\n",
       "        1144,  907, 1027,  184],\n",
       "       [ 365,  228,  230,  845,  817,  173, 1035,  939,  569,  841,  727,\n",
       "         361,  155,  588, 1140],\n",
       "       [ 195,  912,  887,   54, 1184, 1132,   90, 1139,  811, 1110,   27,\n",
       "         900,  717, 1004, 1114]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_per_cluster = get_idx_closest_points(15,X_idf_reduced,y_cluster_pca,cluster_centroids_lsa_indeed)\n",
    "idx_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cluster_pca[496]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build first train set with these labelled data from the clustering + lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_semi_supervised_draft(idx,X,labels):\n",
    "    \"\"\"Method for the manual implementation of semi supervised learning, without sklearn\"\"\"\n",
    "    X_train = np.zeros((idx.shape[0]*idx.shape[1],X.shape[1])) #nb de cvs selectionnes * dim tf_idf\n",
    "    y_train = np.zeros(idx.shape[0]*idx.shape[1]) #nb de cvs_selectionnes\n",
    "    nb_points = idx.shape[1] #nb de points par label\n",
    "    #set train set\n",
    "    for i in range(idx.shape[0]): #pour chaque cluster/label\n",
    "        X_train[i*nb_points:(i+1)*nb_points,:] = X[idx[i]] #tous les points du labels\n",
    "        if(i>0):\n",
    "            y_train[i*nb_points:(i+1)*nb_points] = i #je mets leur label à i\n",
    "    #set test (toutes mes données)\n",
    "    X_test = np.delete(X,idx.ravel(),axis=0) #je supprime les point ajouté du test\n",
    "    y_test = np.delete(labels,idx.ravel(),axis=0)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 150)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = get_input_semi_supervised_draft(idx_per_cluster,X_idf_reduced,y_cluster_pca)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 3 3 1 3 1 2 4 3 3 4 0 0 3 4 2 3 0 0 3 4 3 2 2 0 4 2 3 1 2 1 1 4 0 1 4\n",
      " 3 2 3 2 3 4 1 4 0 3 4 0 4 4 4 2 4 3 3 0 3 3 3 4 1 3 3 3 4 0 3 4 3 3 4 2 1\n",
      " 4 4 3 2 3 3 3 4 1 4 4 2 1 1 3 3 0 4 0 1 3 0 3 0 4 0 0 2 4 3 3 3 4 3 3 4 4\n",
      " 0 4 2 3 3 1 4 3 3 3 0 4 0 3 4 4 1 3 3 0 3 2 3 0 0 4 3 4 4 3 4 1 0 4 2 2 0\n",
      " 4 0 2 4 4 1 0 0 3 0 3 4 4 3 4 4 4 3 3 3 2 4 3 3 4 0 4 4 0 3 2 3 2 3 4 3 3\n",
      " 2 4 3 1 2 2 1 1 2 3 4 4 0 3 4 3 3 3 4 4 3 1 4 3 3 2 2 3 0 3 4 2 3 4 0 0 3\n",
      " 3 3 2 3 4 3 4 1 4 3 4 4 3 1 2 4 1 0 4 1 1 3 0 3 3 0 3 0 4 4 2 2 2 1 4 4 3\n",
      " 4 1 3 4 3 1 3 2 3 2 3 3 4 4 4 0 0 3 4 0 3 2 4 2 3 3 1 3 1 2 4 4 3 0 4 4 3\n",
      " 3 2 4 4 3 4 4 0 4 1 4 0 3 4 3 2 4 3 4 4 1 4 1 2 0 0 3 2 2 3 4 2 2 4 0 3 0\n",
      " 3 3 3 3 1 4 4 2 2 3 2 4 3 4 2 3 3 4 3 1 4 0 4 0 0 4 4 0 3 2 4 4 0 0 2 3 4\n",
      " 3 3 3 3 2 4 4 4 3 1 0 3 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 1 3 0 3 4 2 1\n",
      " 4 3 4 0 0 2 3 1 3 0 3 4 3 3 1 2 1 3 4 1 3 2 2 3 4 3 1 4 4 3 3 3 3 3 3 4 4\n",
      " 4 2 4 3 4 3 4 1 4 3 3 2 3 1 3 1 3 0 4 2 2 2 2 3 4 4 0 4 0 4 4 3 4 3 3 2 4\n",
      " 3 2 0 3 4 3 0 3 3 4 2 2 0 4 2 4 3 4 3 3 4 4 4 2 2 3 3 4 3 0 4 4 3 3 3 4 1\n",
      " 3 1 3 3 4 3 3 4 0 3 1 2 3 1 3 3 0 4 3 0 3 1 2 1 4 4 1 3 4 1 1 3 4 3 3 3 1\n",
      " 3 2 4 0 3 3 3 4 3 0 0 3 3 0 1 4 2 3 3 3 0 1 1 3 3 4 3 0 2 0 0 4 4 1 0 3 4\n",
      " 4 0 3 2 1 4 3 3 3]\n",
      "[3 2 3 1 1 2 4 3 3 0 3 3 2 0 4 4 3 3 3 4 3 4 4 3 2 0 2 4 0 0 3 3 4 1 4 2 1\n",
      " 1 3 1 1 0 1 0 4 4 4 1 4 4 2 2 4 3 2 4 0 3 4 4 1 3 3 4 3 3 4 3 4 4 2 0 4 3\n",
      " 3 0 0 2 3 0 3 3 0 3 3 0 3 4 3 1 3 3 4 2 0 4 1 4 4 3 4 2 3 3 3 4 3 0 4 1 4\n",
      " 4 2 1 3 3 3 4 0 0 1 3 1 3 0 4 0 0 4 3 3 2 3 3 4 0 3 3 2 0 2 3 2 3 1 3 4 0\n",
      " 3 4 4 3 3 0 0 4 0 3 4 3 3 0 2 2 3 4 3 3 0 3 4 3 3 0 4 4 0 4 3 1 4 1 1 4 2\n",
      " 2 1 3 2 4 0 3 1 4 3 1 3 3 0 0 0 3 4 4 0 3 4 4 1 3 2 1 4 3 3 1 4 4 0 4 0 3\n",
      " 3 2 4 4 3 1 3 0 3 4 3 3 3 2 1 4 1 3 1 2 2 1 0 1 1 4 4 4 3 4 4 3 3 4 4 1 3\n",
      " 1 3 3 2 3 0 3 1 4 0 3 4 4 4 2 4 4 0 3 3 4 1 2 3 2 0 1 3 2 0 4 3 4 4 4 0 4\n",
      " 4 4 3 3 3 4 4 3 0 1 0 2 2 4 4 1 1 3 3 0 3 4 4 4 1 2 1 2 4 4 1 4 2 4 0 3 3\n",
      " 1 3 2 3 2 3 4 4 4 4 0 0 0]\n",
      "[3 1 4 3 3 3 4 0 4 2 3 0 0 2 3 4 4 0 3 0 1 4 2 1 4 2 1 0 4 3 4 2 4 4 1 3 3\n",
      " 4 3 0 4 0 4 4 4 3 4 3 0 2 3 3 4 3 0 1 3 4 0 0 0 4 3 4 3 3 3 3 4 2 3 3 3]\n",
      "[1 1 2 3 0 0 1 3 4 3 3 4 0 0 3 1 2 1 3 0 0 4]\n",
      "[3 3 2]\n",
      "[0 3 1]\n",
      "[4 2]\n",
      "[1 4 2 4]\n",
      "[4]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty='l2',C=10)\n",
    "res = np.zeros((X_train.shape[0]+X_test.shape[0],2)) -1\n",
    "\n",
    "for i in range(0,100):\n",
    "    log_reg.fit(X_train,y_train.reshape(-1,)) #fit sur mon train\n",
    "    #je predis sur mon test et je recupère la proba max pour chaque observation\n",
    "    pred_prob_max = np.max(log_reg.predict_proba(X_test),axis=1) \n",
    "    buffer_pred = log_reg.predict(X_test)\n",
    "    #je garde les indices correspondant à des proba supérieure à 0.65\n",
    "    idx = np.where(pred_prob_max>0.65)\n",
    "    \n",
    "    #store results\n",
    "    print(y_test[idx])\n",
    "    res[idx,0] = y_test[idx] #je stocke les resultats des clusters\n",
    "    res[idx,1] = buffer_pred[idx] #je stocke les resultats données par ma prediction\n",
    "    \n",
    "    #update datasets j'enlève mes observations du test et le rajoute au train\n",
    "    X_train = np.vstack((X_train,X_test[idx]))\n",
    "    y_train = np.vstack((y_train.reshape(-1,1),buffer_pred[idx].reshape(-1,1)))\n",
    "    X_test = np.delete(X_test,idx,axis=0)\n",
    "    \n",
    "    #if len(y_test)<10:\n",
    "     #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :0.6404639175257731\n",
      "proportion de donnée prédite : 0.9471919530595139\n"
     ]
    }
   ],
   "source": [
    "test = res[res[:,0]!=-1]\n",
    "print(\"accuracy :{}\".format(np.mean(test[:,0]==test[:,1])))\n",
    "print(\"proportion de donnée prédite : {}\".format(X_train.shape[0]/(X_train.shape[0]+X_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 150)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel augmenter C : risque d'overfitter, on priorise la minimisation de l'erreur sur la maximisation de la marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 1 0 0 2 4 4 4 0 4 0 1 4 4 1 3 2 1 4 0 4 0 0 3 0 0 2 0 2 0 4 3 2 0 2\n",
      " 2 1 1 4 4 4 2 1 1 3 0 0 0 1 0 1 3 2 1 3 2 1 4 1 3 3 3 2 1 0 0 0 0 2 2 2 0\n",
      " 3 2 1 1 2 0 0]\n",
      "[0 1 4 0 1 1 2 4 3 0 3 4 2 4 3 1 0 3 4 4 1 0 2 0 2 3 0 4]\n",
      "[1 3 3 0]\n",
      "[0 4 1]\n",
      "[1 1]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0 1]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[2]\n",
      "[1]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[4]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovr', probability=True,C=10)\n",
    "res = np.zeros((X_train.shape[0]+X_test.shape[0],2)) -1\n",
    "\n",
    "for i in range(0,150):\n",
    "    svm.fit(X_train,y_train.reshape(-1,))\n",
    "    pred_prob_max = np.max(svm.predict_proba(X_test),axis=1) \n",
    "    buffer_pred = log_reg.predict(X_test)\n",
    "    idx = np.where(pred_prob_max>0.6)\n",
    "    \n",
    "    #store results\n",
    "    print(y_test[idx])\n",
    "    res[idx,0] = y_test[idx]\n",
    "    res[idx,1] = buffer_pred[idx]\n",
    "    \n",
    "    #update datasets\n",
    "    X_train = np.vstack((X_train,X_test[idx]))\n",
    "    y_train = np.vstack((y_train.reshape(-1,1),buffer_pred[idx].reshape(-1,1)))\n",
    "    X_test = np.delete(X_test,idx,axis=0)\n",
    "    \n",
    "    if len(y_test)<10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19387755102040816"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = res[res[:,0]!=-1]\n",
    "np.mean(test[:,0]==test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEMI SUPERVISED WITH SEMI SUPERVISED METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d8bc6796bf16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mliste_files_talan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Commun/Data_talan/txt/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "#download talan CVs \n",
    "liste_cv_talan = []\n",
    "liste_files_talan = []\n",
    "path = '../Commun/Data_talan/txt/'\n",
    "filenames = sorted(glob(os.path.join(path,\"*.txt\")))\n",
    "print(len(filenames))\n",
    "for file in filenames:\n",
    "    liste_cv_talan.append(open(file).read())\n",
    "    liste_files_talan.append(file.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Secteurs Télécom & média Activités métier Avant-vente, Développement Intégration & validation. Compétences fonctionnelles CRM : Elaboration de réponses aux appels d’offres, conception des processus métiers, rédaction des spécifications fonctionnelles, préparations des maquettes. Compétences techniques Microsoft Dynamics CRM 2011,2013 Salesforce CRM Architecture et plan de migration (volumétrie importante) Service Director : solution de QOS Oblicore Guarantee : solution SLM Développement : J2EE (EJB3, JMS), Webservice, API, Javascript,C#. Base de données : SQL Server, Oracle, PostgreSQL, MySQL Méthodologie Agile: Scrum, Extreem programing, Sure Step , UML. Atos France Bull France CRM Dynamics 2013, Salesforce CRM Dynamics 2011 Avant-vente CRM : Elaboration de réponses aux appels d’offres, conception des processus métiers, rédaction des spécifications fonctionnelles, préparations des maquettes SLM : Gestion des contrats SLM (Service Level Management) Prise de commande Télécom (SI) Processus métiers transport de fret routier Processus métier collectivité territoriale citoyens 360° Métiers Télécom SI : Provisioning, Médiation, Activation Orange France SLA réseau mobile Gestion du contrat SLM (Service Level Management) sur le produit Oblicore (BSI) Mobistar Covage Service Quality Management évolution sur le modèle Mobistar SI : Interface de prise de commande Orange France Activation Des Terminaux SIP Phones 2015 2015 2013 2012 2012 2012 2011 2008 Formation CRM Salesforce Application Builder 401 Formation CRM Dynamics 2013 Formation Adobe Campaign (Neolane) Certification Microsoft Dynamics CRM 2011 Applications Certification Microsoft Dynamics CRM 2011 Customization and Configuration Certification Microsoft Dynamics CRM 2011 Installation and deployment Formation CRM (théorique et technique), CRM Dynamics 2011, Formation Marketing Formation Méthode de gestion de projet SCRUM Formation Microsoft SURE STEP Formation UML de 5 jours 2009 2008 Master 2 Télécom et Réseau (Orsay) Formation UML 5 jours 2007 Ingénieur Généraliste en Informatique (BAC+5) USTHB (Université des Sciences et de la Technologie HOUARI BOUMEDIENE) Français Bilingue Anglais Lu, Ecrit &Parlé Arabe Langue maternelle Avril 2016 ATOS – Société Générale ALD I -Consultante CRM –International Projet CRM Salesforce. Rôle Consultante Technico-fonctionnelle, Deployment Manager par Intérim, Référente Technique Déploiement Contexte & Mission Projet CRM Salesforce : CRM Salesforce remarketing automation projet en mode agile Réalisations Auditer les Paramétrages sur la solution existante Auditer le code Apex : vérifier l’application des bonnes pratiques Définir le RACI et les prérequis pour chaque étape avec le client, participer à définir le planning de déploiement et la Roadmap pour 13 pays Définir avec le client les documents à utiliser pour le déploiement : Config kit, les Templates, Outils de ticketing..ect Contribuer sur les différentes tâches d’initialisation du projet : Kick-off présentations, animer les workshops déploiements Participer à la récolte des besoins pays (Pre-study) : Slovaquie et république tchèque Animer les workshops pour récupérer les inputs techniques avec les responsables IT des pays Organiser le démarrage de déploiement pays : Chiffrage, Budget, vérifier les prérequis, donner l’OK pour le démarrage Paramétrer (Paramétrage Core) sur Salesforce pour déployer la Slovaquie et la république tchèque : Fields, profils, rôles, Outlook for Salesforce...ect Gérer la migration des données depuis les applications existantes Gérer l’équipe déploiement Environnement technique CRM salesforce,Eclipse, Outlook for salesforce, Migration tool Mars 2015 Mars 2016 ATOS– RENAULT en régie -Consultante CRM –France Consultante Technico-fonctionnelle Projet CRM Salesforce : CRM Salesforce (SFA Sales Force automation, LMT Lead Management tools) : projet en mode agile, Référentiel Prospect/Client déployé internationalement, pour les différents concessionnaires Renault. Interfaçages avec les applications métiers. Consultante technico-Fonctionnelle. Paramétrage sur SalesForce : Profil, Role , Record Type, page layout..ect Développer sur le module de gestion des Leads LMT-Salesforce : Développer un moteur de Fidélisation des clients Développer des Notifications Email en changeant le Template Développer des WebService de Synchronisation des Opportunités/commandes avec les applications métiers. Auditer le code Apex : vérifier l’application des bonnes pratiques Salesforce Participer à la rédaction des contrats d’interface, Implémentation de WebServices, Batch et trigger. Participer à la rédaction des jeux de tests. Qualifier fonctionnellement et effectuer les tests de validation. Support technique. CRM salesforce, Web Services (SOAP), Apex, SOQL,SOAPUI,Eclipse,OAuth2 Avril 2014 au Janvier 2015 ATOS -OBS/Véolia - M2M médiation- Responsable qualité/Recette/Intégration – France IDF M2M : médiation M2O, client OBS/Véolia Responsable qualité/Recette/Intégration Intégration projet M2O Médiation Participer à la rédaction des spécifications générales d’une très importante évolution (V4) (ajout de 13 flux de médiation). Coaching d’une équipe de test de 3 personnes durant les réalisations des évolutions. Préparer les livraisons : Releases, Procédure et manuel d’installation, manuel d’exploitation. Rédiger le cahier de recette. Participer à la rédaction des JEV Qualifier fonctionnellement et effectuer les tests de validation Garantir le support technique. Analyser technico-fonctionnellement les impacts des demandes d’évolution , analyser et auditer à la demande du client les problèmes de performances . Intégration : paramétrage. Effectuer la migration d’une partie de la BDD Oracle de la PF de production vers la PF de pré-production . Animer les instances et workshop du projet avec le client (COPROJ quotidien): présentation, synthèse, état d’avancement. Participer aux réunions quotidiennes d’exploitation point de suivi PRODUCTION animé par le client. Qualifications fonctionnelles et tests de validation. Automatiser les tests, en élaborant et implémentant des scripts Bash entièrement configurables. Participer aux tests de benchemarking. M2M, Scripting Bash, AIX, Platine (mediation), Administration BDD Oracle 11g, Middleware : Tuxedo oracle Mars 2014 au Mai 2014 BULL -INERIS - M2M-BigData– Ingénieur Développeur/testeur– France IDF GEOD’AIR , client INERIS Ingénieur Développeur/testeur Statistiques sur la pollution d’air avec les normes européennes Développement en Java des modules de calcul statistiques de la qualité d'air (collecte des données BD NoSQL). Participation à la rédaction des JEV. Qualifications fonctionnelles et tests de validation. M2M, BigData, MongoDB, BD NoSql, PostgreSQL,Java Déc. 2013 Au févr. 2014 3 mois Bull France –Avant- vente -France SI/CRM Dynamics 2013. Responsable Avant-vente Avant-vente Elaboration de réponses aux appels d’offres clients : Participation à la construction d’offres : CRM, Plate-forme de service ,architecture M2M, Tierce intégration. Etude des différentes solutions techniques pour une architecture SI et plate-forme de service. Elaboration de réponses : plans de migration et stratégie de reprise de données avec une volumétrie importante (opérateurs télécoms) Participation à la rédaction des spécifications fonctionnelles et techniques des propositions. CRM Dynamics 2013,ADFS2.0,OAuth2, BD NoSql, MOM : DDS , AMQP, JMS,Rest, OSGi,OSGi-Me , J2ME Embarquée. Depuis janv 2013 Mobinil Egypt –BULL TMA TMA Mobinil Ingénieur Développeur Support Provisioning pour l’opérateur Telecom Mobinil. Support technique. Différentes activités internes sur le projet : préparation de la migration vers la nouvelle version KPSA 3.7, synchronisation des données entre deux serveurs de développements KPSA3.5, KPSA3.7, SVN, Linux Red Hat, Oracle 10, Oracle11, Scripts shell. juin 2013 à fin juin 2013 Pôle Emploi - BULL – Avant-vente – France Pôle Emploi – Avant-vente – France Avant-vente SLM Pole Emploi Réalisation d’un POC SLM autour de la solution BSI. Mise en place : d’un adaptateur, des contrats, des rapports et un tableau de bord. Présentation du POC au client, (répartie sur deux workshops). BSI 8.1, Oracle 11, IIS7.. Mai 2012 à 2013 Avant-vente : CRM Dynamics 2011 Secteur Public et privé Ingénieur Développement Elaboration de réponses aux appels d’offres clients : Participation à la construction d’offres : CRM, Tierce intégration. Rédaction des spécifications fonctionnelles et techniques de la solution. Préparation de la plate-forme de développement : installation et configuration : Windows Server 2R, Active Directory, SQL Server 2008, SQL Server Reporting Service 2008, CRM Dynamics 2011. Développement de deux maquettes: personnalisation MS Dynamics, développement Java script, développement Web service, plugins c#. CRM Dynamics 2011 , Composants de liste (list component) pour SharePoint, Visual studio 2010, Windows Server 2K,Active Directory,SQL Server 2008, SQL Server Reporting Service 2008, ,IIS7 ,SharePoint. De Juillet 2011 à Avril 2012 Orange –BULL -France SLA réseau mobile Lot 1, Lot2 Gestion du contrat SLM (Service Level Management) sur le produit Oblicore Participation aux Workshops avec le client Intégration et développement sur l’outil de « Service Level management» BSI (anciennement Oblicore) : intégration des données, rapports Développements en .net : Modifications sur l’IHM de prétraitement de données Etude et rédaction de documentation techniques sur les APIs de la solution BSI. Rédaction des rapports associés, rédaction de guide d’utilisation de la solution. Support technique BSI , Visual Basic, Oracle 10, IIS7, Visual studio 2010 De Mars 2011 à Avr 2011 COVAGE –BULL -France COVAGE SI Ingénieur Développement J2EE Interface de prise de commande Covage SI. Développeur. : Évolution de l’interface graphique de l’application web « Prise de Commande ». Environnement technique Eclipse, JOnAS, MySQL ,Hibernate , J2EE (JSP, JSF), MAVEN, spring, SVN. De Juin 2011 à Iuil 2011 ORANGE CAMEROUN –BULL -France P2P ORANGE CAMEROUN Ingénieur Développement J2EE P2P ORANGE CAMEROUN Développeur. Évolution du « Mapping Externe » , en utilisant les bonnes pratiques de développement . Développement du parsing XMl , Servlet Développement des scripts de configuration en Groovy Tests unitaire avec Junit Eclipse, JOnAS, MySQL, J2EE , MAVEN, Spring, Groovy, SVN. De Janv 2011 à Mars 2011 Mobistar –BULL -France Service Quality Management(SQM) évolution sur le modèle Mobistar Projet d’évolution sur produit Service Director de gestion de la QOS Développement des schémas Modélisation Définition des plans de tests Validation de ces schémas Support technique Service Director ,Oracle,XML Scripts Pyton,Sripts Shell De Sept 2010 à Déc 2010 Orange –BULL –France ADT SIP Phones Projet de mise en place d’une plateforme d’activation des terminaux (téléphones VOIP) Développement et Tests des web services (J2EE, SOAP), pour s’interfacer avec des équipements: SIP Phones Validation des web services Conception et modélisation de la partie persistance : base de données J2EE, SOAP, Jonas4, PostgreSQL, SVN, Eclipse De Avr 2010 à Sept 2010 Bull télécom et Média France Stage Conception et Réalisation : Auto Configuration Server ACS Conception et Développement d'un ACS sur la base d'une architecture J2EE et des composants open source. Eclipse, JOnAS, PostgreSQL, J2EE (JSP,JSF, EJB3) SOAP,JMS, SVN. Norme :TR-069. De Fevr 2008 à juil 2009 SNTR Groupe - Algérie ERP Gestion de Fret routier Ingénieur Responsable ERP Responsable ERP Gestion de Fret routier chez le Leader du transport de marchandise et d’hydrocarbure en Algérie . Filiale : Logitrans Maintenance Plus..ect Mise en place et pilotage des évolutions sur la solution. Mise en place des Scripts oracle pour la gestion des recettes. Unification des bases de données des différents sites et unités, le déploiement sur les sites pour les 42 Wilayas de l’ Algérie . Etablir les Testes fonctionnelles 6 Sigma, Oracle,ITIL De Avr 2007 à Sept 2008 Askesis consulting - Algérie Ingénieur Recherche et Développement Etude de plusieurs ERP Open Source, Développement et personnalisation sur des solutions Open source. Etude des fonctionnalités de plusieurs logiciels open source. Conception et implémentation Plug-in d’authentification (c#) sur un projet pour la société Algérienne des Sacs Enduits : Spa (SASACE). Administration réseaux, mise en place serveur Proxy, serveur antiviral Kaspersky Server. OS Linux, JEE, Ajax : GWT, EJB, SOA, BPM, Eclipse, Netbeans, JBoss, C#.net, Scrum, Extreme Programming, ITIL . De Mars 2007 à Sept 2007 Algérie Télécom – Stage Sécurité Réseau – Algérie Stage de fin d’études Stage de Sécurité et réseau à Algérie Télécom (stage de fin d’études) PFE Contribution à la détection d’intrusions, application à Snort sous Linux. L’ajout de deux préprocesseurs de détection à Snort ( langage C ) . Optimisation de la structure des règles Snort (langage C ) . Conception et réalisation d’une interface graphique à Snort (langage JAVA ). Java, JCreator, AWT, Swing , C, Linux Fedora core 4, Snort ,TCP/IP ACH Consultante Senior 9 ans d’expérience Domaines Majeurs de Compétences Références Significatives Formations Langues Expériences professionnelles\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cv_talan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression des saut de lignes\n",
    "liste_cv_talan = [del_line_feed(text).lower() for text in liste_cv_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#suppression de la ponctuation\n",
    "liste_cv_talan_no_punc = [del_punct(text) for text in liste_cv_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion cv french : 0.9862385321100917\n"
     ]
    }
   ],
   "source": [
    "#selectionner seulement cvs fr\n",
    "liste_cv_talan_fr = get_cv_langue(liste_cv_talan_no_punc,'french')\n",
    "\n",
    "nb_cv = len(liste_cv_talan_no_punc)\n",
    "nb_cv_fr = len(liste_cv_talan_fr)\n",
    "\n",
    "print(\"proportion cv french :\",1- ((nb_cv-nb_cv_fr)/nb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On supprime les caractères étranges, accents et stop words\n",
    "liste_cv_treated_talan = [text_treatment(text) for text in liste_cv_talan_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove stop word\n",
    "liste_cv_talan_no_stop = [remove_stopwords(text,stop_words_main) for text in liste_cv_treated_talan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"competences sectorielles finance sante serveurs applications progiciels reuters powerplus pro methodologies xml langages outils developpement sql visual basic html materiel systemes exploitation windows nt bases donnees relationnelles oracle consultant junior formation ecole ingenieur ecole internationale sciences traitement information e s genie mathematique option ingenierie financiere competences experience personelle sejour linguistique famille ecossaise approfondissement anglais decouverte milieu equestre experience professionnelle stage pole bourse etrangere procapital - projet gestion execution operations financieres objet projet controle gestion execution transactions financieres controle trades etrangers depositaires marches rapprochement quotidien clients - marches etrangers collecte transactions passees fortis merrill lynch forme fichiers extraits ifac base donnees controle transactions passees fortis merrill lynch gestion anticipation achat vente cash devises extraction informations cash plates formes fortis custody merrill lynch integration informations comptes reflet representant operations devises controle prevision cash cash devise ajout comptes cash devises ordres achat vente action obligation routes systeme brokers externes anticipation cash devise gestion execution operations titres etrangers passees brokers cash ordre passe instructions reglement livraison depositaire depouillement operation comptes clients brokers reflets gestion execution transferts valeurs etrangeres entrants sortants environnement technique windows nt microsoft office excel vba stage assistant gerant quilvest banque privee - projet assistance equipe gestion actifs objet projet assistance gerants documentation presentation quilvest projet homogeneisation documentation presentation quilvest banque privee futurs investisseurs clients powerpoint preparation presentation morning suivi redaction clients realisation reportings fonds amelioration creation reportings presentations comptes resultats societes suivi synthese comptes resultats passage ordres billets tresorerie fonds analyse ponctuelle entreprises cotees definition limites introduction eventuelle liste valeurs extraction analyses reuters environnement technique windows nt microsoft office excel vba reuters powerplus pro powerpoint stage ministere sante - projet evolution systeme information travers portail web objet projet assistance evolution systeme information plans regionaux sante publique travers portail web briques extractions informations base donnees systeme information biais requetes sql presentation rapports extractions creation tableaux croises dynamiques reporting presentations powerpoint elaboration cahier charges fonctionnel version logiciel elaboration nomenclature version recette fonctionnelle environnement technique windows nt microsoft office excel sql powerpoint langues anglais courant espagnol niveau intermediaire centres interets sports champion volley ball voile planche voile velo equitation vie associative vice president voieisti course spi dauphine course edhec secretaire club investissement eisti'mat responsable volley ball bureau sports bds \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#facultatif add only for talan cv (delete numbers) -> could be use for the preprocessing in general !\n",
    "liste_cv_talan_clean = [re.sub('[0-9 ]+', ' ', text) for text in liste_cv_talan_no_stop]\n",
    "liste_cv_talan_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 112678 items in vocab_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>secteur</th>\n",
       "      <td>secteurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecom</th>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medi</th>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activit</th>\n",
       "      <td>activites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meti</th>\n",
       "      <td>metier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent</th>\n",
       "      <td>vente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>developp</th>\n",
       "      <td>developpement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integr</th>\n",
       "      <td>integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competent</th>\n",
       "      <td>competences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fonctionnel</th>\n",
       "      <td>fonctionnelles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crm</th>\n",
       "      <td>crm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elabor</th>\n",
       "      <td>elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repons</th>\n",
       "      <td>reponses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appel</th>\n",
       "      <td>appels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offre</th>\n",
       "      <td>offres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept</th>\n",
       "      <td>conception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processus</th>\n",
       "      <td>processus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meti</th>\n",
       "      <td>metiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redact</th>\n",
       "      <td>redaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specif</th>\n",
       "      <td>specifications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fonctionnel</th>\n",
       "      <td>fonctionnelles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepar</th>\n",
       "      <td>preparations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maquet</th>\n",
       "      <td>maquettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competent</th>\n",
       "      <td>competences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techniqu</th>\n",
       "      <td>techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic</th>\n",
       "      <td>dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crm</th>\n",
       "      <td>crm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salesforc</th>\n",
       "      <td>salesforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efluid</th>\n",
       "      <td>efluid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competent</th>\n",
       "      <td>competences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meti</th>\n",
       "      <td>metiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logist</th>\n",
       "      <td>logistique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dedouan</th>\n",
       "      <td>dedouanement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent</th>\n",
       "      <td>vente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comptabilit</th>\n",
       "      <td>comptabilite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financ</th>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march</th>\n",
       "      <td>marche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energ</th>\n",
       "      <td>energie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linguist</th>\n",
       "      <td>linguistique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anglais</th>\n",
       "      <td>anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moyen</th>\n",
       "      <td>moyen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arab</th>\n",
       "      <td>arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilingu</th>\n",
       "      <td>bilingue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kabyl</th>\n",
       "      <td>kabyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langu</th>\n",
       "      <td>langue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maternel</th>\n",
       "      <td>maternelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tre</th>\n",
       "      <td>tres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capacit</th>\n",
       "      <td>capacite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apprentissag</th>\n",
       "      <td>apprentissage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>element</th>\n",
       "      <td>element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serieux</th>\n",
       "      <td>serieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiti</th>\n",
       "      <td>ambitieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esprit</th>\n",
       "      <td>esprit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equip</th>\n",
       "      <td>equipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loisir</th>\n",
       "      <td>loisirs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cinem</th>\n",
       "      <td>cinema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112678 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       words\n",
       "secteur             secteurs\n",
       "telecom              telecom\n",
       "medi                   media\n",
       "activit            activites\n",
       "meti                  metier\n",
       "vent                   vente\n",
       "developp       developpement\n",
       "integr           integration\n",
       "valid             validation\n",
       "competent        competences\n",
       "fonctionnel   fonctionnelles\n",
       "crm                      crm\n",
       "elabor           elaboration\n",
       "repons              reponses\n",
       "appel                 appels\n",
       "offre                 offres\n",
       "concept           conception\n",
       "processus          processus\n",
       "meti                 metiers\n",
       "redact             redaction\n",
       "specif        specifications\n",
       "fonctionnel   fonctionnelles\n",
       "prepar          preparations\n",
       "maquet             maquettes\n",
       "competent        competences\n",
       "techniqu          techniques\n",
       "microsoft          microsoft\n",
       "dynamic             dynamics\n",
       "crm                      crm\n",
       "salesforc         salesforce\n",
       "...                      ...\n",
       "efluid                efluid\n",
       "competent        competences\n",
       "meti                 metiers\n",
       "logist            logistique\n",
       "dedouan         dedouanement\n",
       "vent                   vente\n",
       "comptabilit     comptabilite\n",
       "financ               finance\n",
       "march                 marche\n",
       "energ                energie\n",
       "linguist        linguistique\n",
       "anglais              anglais\n",
       "moyen                  moyen\n",
       "arab                   arabe\n",
       "bilingu             bilingue\n",
       "kabyl                 kabyle\n",
       "langu                 langue\n",
       "maternel          maternelle\n",
       "tre                     tres\n",
       "capacit             capacite\n",
       "apprentissag   apprentissage\n",
       "element              element\n",
       "serieux              serieux\n",
       "ambiti             ambitieux\n",
       "esprit                esprit\n",
       "equip                 equipe\n",
       "loisir               loisirs\n",
       "internet            internet\n",
       "sport                  sport\n",
       "cinem                 cinema\n",
       "\n",
       "[112678 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalvocab_stemmed_talan = []\n",
    "totalvocab_tokenized_talan = []\n",
    "for text in liste_cv_talan_no_stop:\n",
    "    allwords_stemmed = tokenize_and_stem(text) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed_talan.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    allwords_tokenized = tokenize_only(text)\n",
    "    totalvocab_tokenized_talan.extend(allwords_tokenized)\n",
    "\n",
    "vocab_frame_talan = pd.DataFrame({'words': totalvocab_tokenized_talan}, index = totalvocab_stemmed_talan)\n",
    "print('there are ' + str(vocab_frame_talan.shape[0]) + ' items in vocab_frame')\n",
    "vocab_frame_talan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehdiregina/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "#TF IDF BOW Representation\n",
    "tf_vect = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.1,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "bow_idf_talan = tf_vect.fit_transform(liste_cv_talan_clean)\n",
    "\n",
    "norm_l2 = make_pipeline(Normalizer(copy=False))\n",
    "bow_idf_talan = norm_l2.fit_transform(bow_idf_talan)\n",
    "\n",
    "vocab_liste_talan = tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ajout une étape pour supprimer les doublons\n",
    "buffer = pd.DataFrame(data=bow_idf_talan.toarray())\n",
    "buffer.drop_duplicates(inplace=True)\n",
    "bow_idf_talan = buffer.values\n",
    "bow_idf_talan = shuffle(bow_idf_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=5, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kmeans\n",
    "n_class = 5\n",
    "km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(bow_idf_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster centroid lsa\n",
    "cluster_centroids_talan = km.cluster_centers_\n",
    "liste_cluster_word=[]\n",
    "\n",
    "#ordre decroissant pour chaque cluster les indices des mots à plus forte corrélation\n",
    "idx_ordered_centroids = np.argsort(cluster_centroids_talan,axis=1)[:,::-1] \n",
    "\n",
    "for i in range(0,cluster_centroids_talan.shape[0]): #nombre de clusters\n",
    "    text=\"\"\n",
    "    for j in range(0,5): #nombre de mots\n",
    "        text+= vocab_frame_talan.loc[vocab_liste_talan[idx_ordered_centroids[i,j]]].values.tolist()[0][0]+ \" \"\n",
    "    liste_cluster_word.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    39\n",
       "1    59\n",
       "2    31\n",
       "3    66\n",
       "4    19\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(km.labels_,columns=[\"Label\"]).groupby([\"Label\"])[\"Label\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sas data r statistiques big ',\n",
       " 'biais decisionnel sap talend informatica ',\n",
       " 'objet erdf recette tests validation ',\n",
       " 'oracle service equipe tests assistant ',\n",
       " 'cognos datastage ibm decisionnel biais ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cluster_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACP X KMEANS TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acce',\n",
       " 'access',\n",
       " 'accompagn',\n",
       " 'achat',\n",
       " 'acteur',\n",
       " 'action',\n",
       " 'activit',\n",
       " 'adapt',\n",
       " 'administr',\n",
       " 'affair',\n",
       " 'agil',\n",
       " 'algorithm',\n",
       " 'aliment',\n",
       " 'amc',\n",
       " 'amelior',\n",
       " 'amo',\n",
       " 'analyst',\n",
       " 'analytic',\n",
       " 'anglais',\n",
       " 'anim',\n",
       " 'anne',\n",
       " 'anomal',\n",
       " 'appel',\n",
       " 'applique',\n",
       " 'apprentissag',\n",
       " 'arab',\n",
       " 'architect',\n",
       " 'architectur',\n",
       " 'aspect',\n",
       " 'assist',\n",
       " 'assur',\n",
       " 'ateli',\n",
       " 'audit',\n",
       " 'automat',\n",
       " 'automatis',\n",
       " 'avanc',\n",
       " 'axe',\n",
       " 'back',\n",
       " 'bancair',\n",
       " 'banqu',\n",
       " 'bas',\n",
       " 'basic',\n",
       " 'batch',\n",
       " 'besoin',\n",
       " 'bi',\n",
       " 'bien',\n",
       " 'big',\n",
       " 'bilan',\n",
       " 'bilingu',\n",
       " 'bnp',\n",
       " 'bo',\n",
       " 'bord',\n",
       " 'budget',\n",
       " 'budgetair',\n",
       " 'business',\n",
       " 'c',\n",
       " 'cabinet',\n",
       " 'cadr',\n",
       " 'cadrag',\n",
       " 'cahi',\n",
       " 'calcul',\n",
       " 'capacit',\n",
       " 'cartograph',\n",
       " 'cent',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'certif',\n",
       " 'chain',\n",
       " 'chang',\n",
       " 'chanti',\n",
       " 'charg',\n",
       " 'chef',\n",
       " 'chiffrag',\n",
       " 'cibl',\n",
       " 'class',\n",
       " 'cloud',\n",
       " 'cod',\n",
       " 'cognos',\n",
       " 'collabor',\n",
       " 'collect',\n",
       " 'comit',\n",
       " 'command',\n",
       " 'commerc',\n",
       " 'commercial',\n",
       " 'commun',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'compos',\n",
       " 'compt',\n",
       " 'comptabilit',\n",
       " 'comptabl',\n",
       " 'concept',\n",
       " 'conduit',\n",
       " 'configur',\n",
       " 'connaiss',\n",
       " 'conseil',\n",
       " 'consolid',\n",
       " 'consomm',\n",
       " 'construct',\n",
       " 'consulting',\n",
       " 'context',\n",
       " 'contrat',\n",
       " 'contribu',\n",
       " 'control',\n",
       " 'coordin',\n",
       " 'correct',\n",
       " 'couch',\n",
       " 'cour',\n",
       " 'cout',\n",
       " 'creation',\n",
       " 'cred',\n",
       " 'crm',\n",
       " 'css',\n",
       " 'cub',\n",
       " 'cycl',\n",
       " 'dashboard',\n",
       " 'dat',\n",
       " 'datamart',\n",
       " 'datastag',\n",
       " 'datawarehous',\n",
       " 'db',\n",
       " 'decis',\n",
       " 'decisionnel',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'del',\n",
       " 'demand',\n",
       " 'deploi',\n",
       " 'descript',\n",
       " 'design',\n",
       " 'destin',\n",
       " 'detaille',\n",
       " 'dev',\n",
       " 'develop',\n",
       " 'developpeur',\n",
       " 'diffus',\n",
       " 'diplom',\n",
       " 'direct',\n",
       " 'disposit',\n",
       " 'distribu',\n",
       " 'docu',\n",
       " 'document',\n",
       " 'domain',\n",
       " 'dossi',\n",
       " 'dsi',\n",
       " 'dut',\n",
       " 'dwh',\n",
       " 'e',\n",
       " 'echang',\n",
       " 'ecol',\n",
       " 'econom',\n",
       " 'ecrit',\n",
       " 'edf',\n",
       " 'edit',\n",
       " 'editeur',\n",
       " 'ee',\n",
       " 'effectu',\n",
       " 'eist',\n",
       " 'elabor',\n",
       " 'electricit',\n",
       " 'encadr',\n",
       " 'energ',\n",
       " 'enquet',\n",
       " 'ensembl',\n",
       " 'entit',\n",
       " 'entrepot',\n",
       " 'entrepris',\n",
       " 'equip',\n",
       " 'erdf',\n",
       " 'erp',\n",
       " 'espagnol',\n",
       " 'estim',\n",
       " 'etat',\n",
       " 'etl',\n",
       " 'etud',\n",
       " 'europ',\n",
       " 'evalu',\n",
       " 'evolu',\n",
       " 'evolut',\n",
       " 'excel',\n",
       " 'execu',\n",
       " 'exist',\n",
       " 'exl',\n",
       " 'expert',\n",
       " 'expertis',\n",
       " 'exploit',\n",
       " 'express',\n",
       " 'extern',\n",
       " 'extract',\n",
       " 'factur',\n",
       " 'faisabilit',\n",
       " 'fiabilis',\n",
       " 'fichi',\n",
       " 'filial',\n",
       " 'final',\n",
       " 'financ',\n",
       " 'financi',\n",
       " 'financier',\n",
       " 'flux',\n",
       " 'fonction',\n",
       " 'fonctionnalit',\n",
       " 'form',\n",
       " 'formalis',\n",
       " 'fort',\n",
       " 'fournisseur',\n",
       " 'framework',\n",
       " 'franc',\n",
       " 'garant',\n",
       " 'gen',\n",
       " 'gener',\n",
       " 'general',\n",
       " 'ger',\n",
       " 'global',\n",
       " 'grand',\n",
       " 'group',\n",
       " 'hadoop',\n",
       " 'hebdomadair',\n",
       " 'hiv',\n",
       " 'hortonwork',\n",
       " 'hp',\n",
       " 'html',\n",
       " 'humain',\n",
       " 'ibm',\n",
       " 'identif',\n",
       " 'impact',\n",
       " 'implement',\n",
       " 'incident',\n",
       " 'indiqu',\n",
       " 'industr',\n",
       " 'industrialis',\n",
       " 'industriel',\n",
       " 'infocentr',\n",
       " 'inform',\n",
       " 'informat',\n",
       " 'informatic',\n",
       " 'infrastructur',\n",
       " 'ingenier',\n",
       " 'ingenieur',\n",
       " 'install',\n",
       " 'institut',\n",
       " 'integr',\n",
       " 'intelligent',\n",
       " 'interet',\n",
       " 'interfac',\n",
       " 'intern',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'interven',\n",
       " 'intervent',\n",
       " 'it',\n",
       " 'jav',\n",
       " 'javascript',\n",
       " 'jeux',\n",
       " 'job',\n",
       " 'junior',\n",
       " 'lanc',\n",
       " 'langag',\n",
       " 'langu',\n",
       " 'lead',\n",
       " 'learning',\n",
       " 'lectur',\n",
       " 'licenc',\n",
       " 'lign',\n",
       " 'linux',\n",
       " 'livrabl',\n",
       " 'livraison',\n",
       " 'logiciel',\n",
       " 'logist',\n",
       " 'lot',\n",
       " 'machin',\n",
       " 'macro',\n",
       " 'mainten',\n",
       " 'maintien',\n",
       " 'maitris',\n",
       " 'manag',\n",
       " 'manuel',\n",
       " 'mapping',\n",
       " 'maquet',\n",
       " 'march',\n",
       " 'marketing',\n",
       " 'mast',\n",
       " 'materiel',\n",
       " 'mathemat',\n",
       " 'mensuel',\n",
       " 'meris',\n",
       " 'mesur',\n",
       " 'method',\n",
       " 'methodolog',\n",
       " 'microsoft',\n",
       " 'migrat',\n",
       " 'mis',\n",
       " 'mission',\n",
       " 'mo',\n",
       " 'mod',\n",
       " 'model',\n",
       " 'modelis',\n",
       " 'modif',\n",
       " 'modul',\n",
       " 'monte',\n",
       " 'mysql',\n",
       " 'net',\n",
       " 'niveau',\n",
       " 'norm',\n",
       " 'nouvel',\n",
       " 'nt',\n",
       " 'object',\n",
       " 'objet',\n",
       " 'oeuvr',\n",
       " 'offic',\n",
       " 'offre',\n",
       " 'open',\n",
       " 'oper',\n",
       " 'operationnel',\n",
       " 'optimis',\n",
       " 'option',\n",
       " 'oracl',\n",
       " 'organis',\n",
       " 'ouvertur',\n",
       " 'ouvrag',\n",
       " 'p',\n",
       " 'parametrag',\n",
       " 'parc',\n",
       " 'partenair',\n",
       " 'pay',\n",
       " 'perform',\n",
       " 'perimetr',\n",
       " 'permet',\n",
       " 'permettent',\n",
       " 'phas',\n",
       " 'php',\n",
       " 'pilot',\n",
       " 'pilotag',\n",
       " 'pl',\n",
       " 'plan',\n",
       " 'planif',\n",
       " 'planning',\n",
       " 'plat',\n",
       " 'plateform',\n",
       " 'plus',\n",
       " 'poc',\n",
       " 'point',\n",
       " 'pol',\n",
       " 'portail',\n",
       " 'post',\n",
       " 'postgresql',\n",
       " 'pow',\n",
       " 'pratiqu',\n",
       " 'pre',\n",
       " 'preconis',\n",
       " 'prepar',\n",
       " 'preparatoir',\n",
       " 'present',\n",
       " 'prestat',\n",
       " 'previs',\n",
       " 'principal',\n",
       " 'pris',\n",
       " 'problem',\n",
       " 'problemat',\n",
       " 'procedur',\n",
       " 'process',\n",
       " 'processus',\n",
       " 'product',\n",
       " 'produit',\n",
       " 'professionnel',\n",
       " 'profil',\n",
       " 'progiciel',\n",
       " 'programm',\n",
       " 'project',\n",
       " 'propos',\n",
       " 'proposit',\n",
       " 'public',\n",
       " 'publiqu',\n",
       " 'python',\n",
       " 'qlikview',\n",
       " 'qualif',\n",
       " 'qualit',\n",
       " 'quality',\n",
       " 'quotidien',\n",
       " 'r',\n",
       " 'rapport',\n",
       " 'realis',\n",
       " 'recet',\n",
       " 'recherch',\n",
       " 'recommand',\n",
       " 'recueil',\n",
       " 'referent',\n",
       " 'referentiel',\n",
       " 'refont',\n",
       " 'regl',\n",
       " 'regress',\n",
       " 'relat',\n",
       " 'relationnel',\n",
       " 'remonte',\n",
       " 'repons',\n",
       " 'report',\n",
       " 'reporting',\n",
       " 'repris',\n",
       " 'requet',\n",
       " 'reseau',\n",
       " 'resolu',\n",
       " 'respect',\n",
       " 'respons',\n",
       " 'ressourc',\n",
       " 'restitu',\n",
       " 'resultat',\n",
       " 'retail',\n",
       " 'reunion',\n",
       " 'revu',\n",
       " 'risqu',\n",
       " 'rol',\n",
       " 's',\n",
       " 'sais',\n",
       " 'sant',\n",
       " 'sap',\n",
       " 'sas',\n",
       " 'scenarios',\n",
       " 'schem',\n",
       " 'scienc',\n",
       " 'scientist',\n",
       " 'script',\n",
       " 'scrum',\n",
       " 'secteur',\n",
       " 'sectoriel',\n",
       " 'securit',\n",
       " 'segment',\n",
       " 'sein',\n",
       " 'senior',\n",
       " 'ser',\n",
       " 'serv',\n",
       " 'serveur',\n",
       " 'servic',\n",
       " 'sgbd',\n",
       " 'shel',\n",
       " 'simul',\n",
       " 'sncf',\n",
       " 'social',\n",
       " 'societ',\n",
       " 'socl',\n",
       " 'softwar',\n",
       " 'solut',\n",
       " 'spark',\n",
       " 'specialis',\n",
       " 'sport',\n",
       " 'ssis',\n",
       " 'stag',\n",
       " 'stagiair',\n",
       " 'statist',\n",
       " 'stock',\n",
       " 'strateg',\n",
       " 'structur',\n",
       " 'studio',\n",
       " 'suit',\n",
       " 'superieur',\n",
       " 'supervis',\n",
       " 'support',\n",
       " 'sybas',\n",
       " 'synthes',\n",
       " 'system',\n",
       " 'tabl',\n",
       " 'tableau',\n",
       " 'tach',\n",
       " 'talend',\n",
       " 'technico',\n",
       " 'technolog',\n",
       " 'telecom',\n",
       " 'telecommun',\n",
       " 'term',\n",
       " 'test',\n",
       " 'tma',\n",
       " 'toad',\n",
       " 'toeic',\n",
       " 'trafic',\n",
       " 'trait',\n",
       " 'transfert',\n",
       " 'transform',\n",
       " 'transvers',\n",
       " 'travail',\n",
       " 'traval',\n",
       " 'traver',\n",
       " 'typ',\n",
       " 'uml',\n",
       " 'unitair',\n",
       " 'univer',\n",
       " 'unix',\n",
       " 'valid',\n",
       " 'vba',\n",
       " 'vent',\n",
       " 'verif',\n",
       " 'version',\n",
       " 'vi',\n",
       " 'visual',\n",
       " 'visualis',\n",
       " 'voyag',\n",
       " 'web',\n",
       " 'window',\n",
       " 'workflow',\n",
       " 'xi',\n",
       " 'xml',\n",
       " 'xp']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_liste_talan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 70)\n",
      "Explained variance of the SVD step: 75%\n"
     ]
    }
   ],
   "source": [
    "#LSA\n",
    "svd = TruncatedSVD(70)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa_talan = make_pipeline(svd, normalizer)\n",
    "\n",
    "bow_idf_reduced_talan = lsa_talan.fit_transform(bow_idf_talan)\n",
    "print(bow_idf_reduced_talan.shape)\n",
    "\n",
    "#keep the same variance than for the the indeed data above\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=5, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kmeans\n",
    "n_class = 5\n",
    "km = KMeans(n_clusters=n_class, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(bow_idf_reduced_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 71%\n"
     ]
    }
   ],
   "source": [
    "bow_idf_reduced_lsa_talan, liste_cluster_word_lsa_talan, labels_lsa_talan,cluster_centroids_lsa_talan = get_kmeans_cluster_words_lsa(bow_idf_talan,60,5,5,vocab_frame_talan,vocab_liste_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    51\n",
       "1    71\n",
       "2    53\n",
       "3    18\n",
       "4    21\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labels_lsa_talan,columns=[\"Label\"]).groupby([\"Label\"])[\"Label\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['objet oracle tests windows unix ',\n",
       " 'biais decisionnel talend cognos datastage ',\n",
       " 'service management equipe assistant processus ',\n",
       " 'data r big python algorithmes ',\n",
       " 'sas statistiques data r etude ']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cluster_word_lsa_talan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_rand_word_label = dict()\n",
    "for label in np.unique(labels_lsa_talan):\n",
    "    idx_label = np.where(labels_lsa_talan==label)[0]\n",
    "    idx_rand = np.random.choice(idx_label,size=(12))\n",
    "    liste_cluster_word = []\n",
    "    for idx in idx_rand:\n",
    "        text = \" \"\n",
    "        idx_ordered = np.argsort(bow_idf_talan[idx])[::-1]\n",
    "        for j in range(0, 4):  # nombre de motss\n",
    "            text += vocab_frame_talan.loc[vocab_liste_talan[idx_ordered[j]]].values.tolist()[0][0] + \" \"\n",
    "        liste_cluster_word.append(text)\n",
    "    dict_rand_word_label[\"cluster\"+str(label)] = liste_cluster_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' crm corrective chiffrage recette ',\n",
       " ' support administration office marches ',\n",
       " ' evolutive amc bo documentation ',\n",
       " ' crm corrective chiffrage recette ',\n",
       " ' objet recette ouvrage charges ',\n",
       " ' reseau propositions etude architecture ',\n",
       " ' tests production installation creation ',\n",
       " ' parametrages java sante ee ',\n",
       " ' recette objet fonctions center ',\n",
       " ' crm corrective chiffrage recette ',\n",
       " ' oracle support oeuvre architecture ',\n",
       " ' tests recette quality jeux ']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_rand_word_label[\"cluster0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF X KMEANS TALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on part d'un bag of words tf-idf\n",
    "tf_vect_2 = TfidfVectorizer(stop_words=stop_words_main,max_df=0.8,min_df=0.05,\\\n",
    "                           preprocessor=text_treatment,tokenizer=tokenize_and_stem)\n",
    "\n",
    "test_idf_2_talan = tf_vect_2.fit_transform(liste_cv_talan_clean)\n",
    "\n",
    "vocab_liste_nmf_talan = tf_vect_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model on with n_samples = 1182 and n_features = 493\n"
     ]
    }
   ],
   "source": [
    "liste_topic, liste_cluster = get_kmens_cluster_words_nmf(test_idf_2_talan,20,5,5,vocab_frame_talan,vocab_liste_nmf_talan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datastage etl oracle px unix ibm shell conception decisionnelles interface',\n",
       " 'sas statistiques macro excel base enquetes directions analytics data visual',\n",
       " 'data modeler spark r science scientist prototype cas python plateformes',\n",
       " 'microstrategy grdf visualization dashboard semantique reporting couche exadata relatives documents',\n",
       " 'sap xi bo bi businessobjects migration objects univers business securite',\n",
       " 'talend java integration data realisation installation jobs plateformes big studio',\n",
       " 'qlikview qlik application conception decisionnelles sense realisation desktop bord evolutions',\n",
       " 'microsoft server conception ssrs net cubes c ssis ssas web',\n",
       " 'cognos tm ibm bi regles decisionnelles systemes certified besoin controler',\n",
       " 'statistiques formateur marketing data etude e excel consommations sas recommandations',\n",
       " 'google tensorflow data classification r python platforms api twitter science',\n",
       " 'mdm tma moe ibm data oeuvre pilotage assister referentiel corrective',\n",
       " 'obiee epm oracle planning cubes application reporting creation assister budgetaire',\n",
       " 'software tableau creation reseau reporting intelligence k business data identification',\n",
       " 'statistiques temporelles packs series etude sas r shiny office evenement',\n",
       " 'informatica bi oracle powercenter alimentation traitements production recette decisionnelles systemes',\n",
       " 'python data spark scala demandes mongodb big traitements calculation science',\n",
       " 'r digital learning detection aide scientist machine statistiques engineering tool',\n",
       " 'pilotage directions equipement chef moe marketing definition etude cadrage application',\n",
       " 'big data cluster algorithmes spark hive hortonworks talend cloudera infocentre']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cognos datastage oracle ibm tm ',\n",
       " 'sas data r big statistiques ',\n",
       " 'sap xi bi bo businessobjects ',\n",
       " 'microstrategy grdf visualization bi informatica ',\n",
       " 'sas data marketing python directions ']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
